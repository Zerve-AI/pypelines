{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.9'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "json.__version__\n",
    "\n",
    "#from pypelines.sklearn_pypeline import SklearnPipeline\n",
    "#from default_content import default_content\n",
    "\n",
    "#config = default_content = default_content(5)\n",
    "\n",
    "#config = json.loads(config) \n",
    "\n",
    "#settings = SklearnPipeline().get_settings(config)\n",
    "\n",
    "#print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'prefix': 'log_reg', 'model': 'LogisticRegression()', 'imports': 'from sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\\nimport plotly.express as px', 'model_type': 'Classification'}\n",
      "{'prefix': 'log_reg', 'model': 'LogisticRegression()', 'imports': 'from sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\\nimport plotly.express as px', 'model_type': 'Classification'}\n",
      "{}\n",
      "{'prefix': 'svc', 'model': 'SVC()', 'imports': 'from sklearn.svm import SVC\\nfrom sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\\nimport plotly.express as px', 'model_type': 'Classification'}\n",
      "{'prefix': 'svc', 'model': 'SVC()', 'imports': 'from sklearn.svm import SVC\\nfrom sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\\nimport plotly.express as px', 'model_type': 'Classification'}\n"
     ]
    }
   ],
   "source": [
    "blocks, requirements, imports  = SklearnPipeline().run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.metrics import accuracy_score\\n\\n\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.metrics import accuracy_score\\n\\n\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.impute import SimpleImputer\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: train.csv\n",
      "target = \"target\"\n",
      "features = list(train.csv.columns.drop(\"target\"))\n",
      "feature_df = train.csv[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "train.csv[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "# check categorical columns for high cardinality\n",
      "\n",
      "sample_size = np.min([10000, train.csv.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality\n",
      "for col in categorical_cols:\n",
      "    if train.csv[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        categorical_cols.remove(col)\n",
      "\n",
      "# check text columns for low cardinality\n",
      "for col in text_cols:\n",
      "    if train.csv[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        ('text', text_transformer, text_cols),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = train.csv[features]\n",
      "y = train.csv[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "svc_param_grid = {\n",
      "\"svc__C\": np.arange(0.1, 1.0, 0.1),\n",
      "\"svc__degree\": np.arange(2, 5, 1),\n",
      "\"svc__kernel\": ['linear', 'poly'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "svc_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('svc', SVC())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "svc_grid_search = GridSearchCV(estimator=svc_pipe, param_grid=svc_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "svc_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "svc_best_estimator = svc_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "svc_search_results = pd.DataFrame(svc_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "svc_predictions = pd.DataFrame(svc_best_estimator.predict(X_test))\n",
      "svc_predictions_prob = svc_best_estimator.predict_proba(X_test)\n",
      "svc_predictions_prob_df = pd.DataFrame()\n",
      "svc_predictions_prob_df[svc_grid_search.classes_[0]] = svc_predictions_prob[:,0]\n",
      "svc_predictions_prob_df[svc_grid_search.classes_[1]] = svc_predictions_prob[:,1] \n",
      "svc_accuracy = accuracy_score(y_test.iloc[:,0], svc_predictions.iloc[:,0])\n",
      "svc_f1_score = f1_score(y_test.iloc[:,0], svc_predictions.iloc[:,0])\n",
      "svc_precision = precision_score(y_test.iloc[:,0], svc_predictions.iloc[:,0])\n",
      "svc_recall = recall_score(y_test.iloc[:,0], svc_predictions.iloc[:,0])\n",
      "svc_roc_auc_score = roc_auc_score(y_test.iloc[:,0], svc_predictions_prob_df[svc_grid_search.classes_[1]])\n",
      "svc_performance_metrics = [['svc','accuracy',svc_accuracy], \n",
      "                                  ['svc','f1_score',svc_f1_score],\n",
      "                                  ['svc','precision', svc_precision],\n",
      "                                  ['svc','recall', svc_recall],\n",
      "                                  ['svc','roc_auc_score', svc_roc_auc_score]]\n",
      "svc_performance_metrics = pd.DataFrame(svc_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, svc_predictions_prob_df[svc_grid_search.classes_[1]])\n",
      "svc_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "svc_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "svc_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "svc_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "svc_roc_auc_plot.show()\n",
      "del df, target, features, feature_df, bool_cols, numerical_cols, categorical_cols, text_cols, col, numeric_transformer, categorical_transformer,text_transformer, preprocessor,X, X_train, X_test, y, y_train, y_test,accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "\n",
      "\n",
      "\n",
      "#comparison metrics - svc\n",
      "\n",
      "svc_performance_metrics\n",
      "svc_roc_auc_plot.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(blocks[1]['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
