{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from pypelines.sklearn_pypeline import SklearnPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code output\n",
    "skl_pypelines = SklearnPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'classification'\n",
    "                            , models = ['GaussianNB Classifier','Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5, output_format='code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GBT Classifier', 'Logistic Regression']\n"
     ]
    }
   ],
   "source": [
    "skl_pypelines.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "titanic = pd.read_csv(\"./titanic.csv\")\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "# check categorical columns for high cardinality\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        categorical_cols.remove(col)\n",
      "\n",
      "# check text columns for low cardinality\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        ('text', text_transformer, text_cols),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Logistic Regression #####\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "log_reg_param_grid = {\n",
      "\"log_reg__C\": np.arange(0.1, 1.0, 0.1),\n",
      "\"log_reg__penalty\": ['l2'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "log_reg_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('log_reg', LogisticRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "log_reg_grid_search = GridSearchCV(estimator=log_reg_pipe, param_grid=log_reg_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "log_reg_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "log_reg_best_estimator = log_reg_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "log_reg_search_results = pd.DataFrame(log_reg_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "log_reg_predictions = pd.DataFrame(log_reg_best_estimator.predict(X_test))\n",
      "log_reg_predictions_prob = log_reg_best_estimator.predict_proba(X_test)\n",
      "log_reg_predictions_prob_df = pd.DataFrame()\n",
      "log_reg_predictions_prob_df[log_reg_grid_search.classes_[0]] = log_reg_predictions_prob[:,0]\n",
      "log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]] = log_reg_predictions_prob[:,1] \n",
      "log_reg_accuracy = accuracy_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_f1_score = f1_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_precision = precision_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_recall = recall_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_roc_auc_score = roc_auc_score(y_test, log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]])\n",
      "log_reg_performance_metrics = [['log_reg','accuracy',log_reg_accuracy], \n",
      "                                  ['log_reg','f1_score',log_reg_f1_score],\n",
      "                                  ['log_reg','precision', log_reg_precision],\n",
      "                                  ['log_reg','recall', log_reg_recall],\n",
      "                                  ['log_reg','roc_auc_score', log_reg_roc_auc_score]]\n",
      "log_reg_performance_metrics = pd.DataFrame(log_reg_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]])\n",
      "log_reg_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "log_reg_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "log_reg_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "log_reg_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "log_reg_roc_auc_plot.show()\n",
      "del df, target, features, feature_df, bool_cols, numerical_cols, categorical_cols, text_cols, col, numeric_transformer, categorical_transformer,text_transformer, preprocessor,X, X_train, X_test, y, y_train, y_test,accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "\n",
      "\n",
      "\n",
      "#comparison metrics - log_reg\n",
      "\n",
      "log_reg_performance_metrics\n",
      "log_reg_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Logistic Regression #####\n",
      "\n",
      "##### Model Pipeline for GBT Classifier #####\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "gbt_classifier_param_grid = {\n",
      "\"gbt_classifier__learning_rate\": np.arange(0.0, 1.0, 0.1),\n",
      "\"gbt_classifier__n_estimators\": np.arange(100, 10000, 100),\n",
      "\"gbt_classifier__subsample\": np.arange(0.1, 1.0, 0.1),\n",
      "\"gbt_classifier__max_depth\": np.arange(1, 10000, 100),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gbt_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gbt_classifier', GradientBoostingClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gbt_classifier_grid_search = GridSearchCV(estimator=gbt_classifier_pipe, param_grid=gbt_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "gbt_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gbt_classifier_best_estimator = gbt_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gbt_classifier_search_results = pd.DataFrame(gbt_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gbt_classifier_predictions = pd.DataFrame(gbt_classifier_best_estimator.predict(X_test))\n",
      "gbt_classifier_predictions_prob = gbt_classifier_best_estimator.predict_proba(X_test)\n",
      "gbt_classifier_predictions_prob_df = pd.DataFrame()\n",
      "gbt_classifier_predictions_prob_df[gbt_classifier_grid_search.classes_[0]] = gbt_classifier_predictions_prob[:,0]\n",
      "gbt_classifier_predictions_prob_df[gbt_classifier_grid_search.classes_[1]] = gbt_classifier_predictions_prob[:,1] \n",
      "gbt_classifier_accuracy = accuracy_score(y_test, gbt_classifier_predictions.iloc[:,0])\n",
      "gbt_classifier_f1_score = f1_score(y_test, gbt_classifier_predictions.iloc[:,0])\n",
      "gbt_classifier_precision = precision_score(y_test, gbt_classifier_predictions.iloc[:,0])\n",
      "gbt_classifier_recall = recall_score(y_test, gbt_classifier_predictions.iloc[:,0])\n",
      "gbt_classifier_roc_auc_score = roc_auc_score(y_test, gbt_classifier_predictions_prob_df[gbt_classifier_grid_search.classes_[1]])\n",
      "gbt_classifier_performance_metrics = [['gbt_classifier','accuracy',gbt_classifier_accuracy], \n",
      "                                  ['gbt_classifier','f1_score',gbt_classifier_f1_score],\n",
      "                                  ['gbt_classifier','precision', gbt_classifier_precision],\n",
      "                                  ['gbt_classifier','recall', gbt_classifier_recall],\n",
      "                                  ['gbt_classifier','roc_auc_score', gbt_classifier_roc_auc_score]]\n",
      "gbt_classifier_performance_metrics = pd.DataFrame(gbt_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, gbt_classifier_predictions_prob_df[gbt_classifier_grid_search.classes_[1]])\n",
      "gbt_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "gbt_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "gbt_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "gbt_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "gbt_classifier_roc_auc_plot.show()\n",
      "del df, target, features, feature_df, bool_cols, numerical_cols, categorical_cols, text_cols, col, numeric_transformer, categorical_transformer,text_transformer, preprocessor,X, X_train, X_test, y, y_train, y_test,accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "\n",
      "\n",
      "\n",
      "#comparison metrics - gbt_classifier\n",
      "\n",
      "gbt_classifier_performance_metrics\n",
      "gbt_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for GBT Classifier #####\n"
     ]
    }
   ],
   "source": [
    "skl_pypelines.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script output\n",
    "skl_pypelines = SklearnPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'classification'\n",
    "                            , models = ['GaussianNB Classifier','Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5, output_format='script',\n",
    "                            output_folder = \"./code_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_pypelines.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_pypelines.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
