{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypelines.supervised_pipeline as pipe\n",
    "from pypelines import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Decision Tree Classifier',\n",
       " 'Logistic Regression',\n",
       " 'Random Forest Classifier',\n",
       " 'SVC Classifier',\n",
       " 'XGBoost Classifier',\n",
       " 'MLP Classifier',\n",
       " 'Ridge Classifier',\n",
       " 'Perceptron Classifier',\n",
       " 'SGD Classifier',\n",
       " 'GBT Classifier',\n",
       " 'ADABoost Classifier',\n",
       " 'ExtraTrees Classifier',\n",
       " 'PassiveAggressive Classifier',\n",
       " 'LDA Classifier',\n",
       " 'QDA Classifier',\n",
       " 'NuSVC Classifier',\n",
       " 'GaussianNB Classifier',\n",
       " 'MultinomialNB Classifier',\n",
       " 'ComplementNB Classifier',\n",
       " 'BernoulliNB Classifier',\n",
       " 'CategoricalNB Classifier']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.list_supported_models(model_type='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv(\"pypelines/datasets/classification/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code output\n",
    "clf_pypelines_all = pipe.SupervisedPipeline(data = titanic,target = 'Survived'\n",
    "                            , model_type = 'classification'\n",
    "                            ,models = ['Random Forest Classifier']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality and make it text column\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        text_cols.append(col)\n",
      "        categorical_cols.remove(col)\n",
      "        \n",
      "\n",
      "# check text columns for low cardinality and make it categorical columns\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "print(numerical_cols)\n",
      "print(categorical_cols)\n",
      "print(text_cols)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "        transformers=[('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        *[(f'text_{t_col}', text_transformer, t_col) for t_col in text_cols]]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Random Forest Classifier #####\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "random_forest_classifier_param_grid = {\n",
      "\"random_forest_classifier__n_estimators\": np.arange(10, 100, 20),\n",
      "\"random_forest_classifier__max_depth\": np.arange(2, 10, 2),\n",
      "\"random_forest_classifier__min_samples_split\": np.arange(0.5, 1.0, 0.1),\n",
      "\"random_forest_classifier__min_samples_leaf\": np.arange(1, 10, 2),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "random_forest_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('random_forest_classifier', RandomForestClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "random_forest_classifier_grid_search = GridSearchCV(estimator=random_forest_classifier_pipe, param_grid=random_forest_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "random_forest_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "random_forest_classifier_best_estimator = random_forest_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "random_forest_classifier_search_results = pd.DataFrame(random_forest_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "random_forest_classifier_predictions = pd.DataFrame(random_forest_classifier_best_estimator.predict(X_test))\n",
      "random_forest_classifier_predictions_prob = random_forest_classifier_best_estimator.predict_proba(X_test)\n",
      "random_forest_classifier_predictions_prob_df = pd.DataFrame()\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[0]] = random_forest_classifier_predictions_prob[:,0]\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]] = random_forest_classifier_predictions_prob[:,1] \n",
      "random_forest_classifier_accuracy = accuracy_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_f1_score = f1_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_precision = precision_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_recall = recall_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_roc_auc_score = roc_auc_score(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_performance_metrics = [['random_forest_classifier','accuracy',random_forest_classifier_accuracy], \n",
      "                                  ['random_forest_classifier','f1_score',random_forest_classifier_f1_score],\n",
      "                                  ['random_forest_classifier','precision', random_forest_classifier_precision],\n",
      "                                  ['random_forest_classifier','recall', random_forest_classifier_recall],\n",
      "                                  ['random_forest_classifier','roc_auc_score', random_forest_classifier_roc_auc_score]]\n",
      "random_forest_classifier_performance_metrics = pd.DataFrame(random_forest_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "random_forest_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Random Forest Classifier #####\n",
      "\n",
      "random_forest_classifier_performance_metrics\n",
      "random_forest_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Random Forest Classifier #####\n"
     ]
    }
   ],
   "source": [
    "clf_pypelines_all.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model files saved to ./code_output/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_all.code_to_file(path='./code_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest Classifier': {'numerical': [{'search': True,\n",
       "    'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 20},\n",
       "   {'search': True, 'name': 'max_depth', 'min': 2, 'max': 10, 'step': 2},\n",
       "   {'search': True,\n",
       "    'name': 'min_samples_split',\n",
       "    'min': 0.5,\n",
       "    'max': 1,\n",
       "    'step': 0.1},\n",
       "   {'search': True,\n",
       "    'name': 'min_samples_leaf',\n",
       "    'min': 1,\n",
       "    'max': 10,\n",
       "    'step': 2}],\n",
       "  'categorical': [{'search': False,\n",
       "    'name': 'criterion',\n",
       "    'selected': ['gini'],\n",
       "    'values': ['gini', 'entropy']},\n",
       "   {'search': False,\n",
       "    'name': 'max_features',\n",
       "    'selected': ['auto'],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'search': False,\n",
       "    'name': 'bootstrap',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'search': False,\n",
       "    'name': 'oob_score',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'search': False,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'search': False,\n",
       "    'name': 'class_weight',\n",
       "    'selected': ['balanced'],\n",
       "    'values': ['balanced', 'balanced_subsample']}]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_all.model_grid_search_settings(model_name = 'Random Forest Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dict = {'numerical': [{'search': True,'name': 'n_estimators','min': 10,'max': 1000000,'step': 20},\n",
    "   {'search': True, 'name': 'max_depth', 'min': 2, 'max': 10, 'step': 2},\n",
    "   {'search': True,\n",
    "    'name': 'min_samples_split',\n",
    "    'min': 0.5,\n",
    "    'max': 1,\n",
    "    'step': 0.1},\n",
    "   {'search': True,\n",
    "    'name': 'min_samples_leaf',\n",
    "    'min': 1,\n",
    "    'max': 10,\n",
    "    'step': 2}],\n",
    "  'categorical': [{'search': True,\n",
    "    'name': 'criterion',\n",
    "    'selected': ['gini'],\n",
    "    'values': ['gini', 'entropy']},\n",
    "   {'search': True,\n",
    "    'name': 'max_features',\n",
    "    'selected': ['auto'],\n",
    "    'values': ['auto', 'sqrt', 'log2']},\n",
    "   {'search': True,\n",
    "    'name': 'bootstrap',\n",
    "    'selected': [True],\n",
    "    'values': [True, False]},\n",
    "   {'search': False,\n",
    "    'name': 'oob_score',\n",
    "    'selected': [True],\n",
    "    'values': [True, False]},\n",
    "   {'search': True,\n",
    "    'name': 'warm_start',\n",
    "    'selected': [False],\n",
    "    'values': [True, False]},\n",
    "   {'search': False,\n",
    "    'name': 'class_weight',\n",
    "    'selected': ['balanced'],\n",
    "    'values': ['balanced', 'balanced_subsample']}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality and make it text column\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        text_cols.append(col)\n",
      "        categorical_cols.remove(col)\n",
      "        \n",
      "\n",
      "# check text columns for low cardinality and make it categorical columns\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "print(numerical_cols)\n",
      "print(categorical_cols)\n",
      "print(text_cols)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "        transformers=[('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        *[(f'text_{t_col}', text_transformer, t_col) for t_col in text_cols]]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Random Forest Classifier #####\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "random_forest_classifier_param_grid = {\n",
      "\"random_forest_classifier__n_estimators\": np.arange(10, 1000000, 20),\n",
      "\"random_forest_classifier__max_depth\": np.arange(2, 10, 2),\n",
      "\"random_forest_classifier__min_samples_split\": np.arange(0.5, 1.0, 0.1),\n",
      "\"random_forest_classifier__min_samples_leaf\": np.arange(1, 10, 2),\n",
      "\"random_forest_classifier__criterion\": ['gini'],\n",
      "\"random_forest_classifier__max_features\": ['auto'],\n",
      "\"random_forest_classifier__bootstrap\": [True],\n",
      "\"random_forest_classifier__warm_start\": [False],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "random_forest_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('random_forest_classifier', RandomForestClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "random_forest_classifier_grid_search = GridSearchCV(estimator=random_forest_classifier_pipe, param_grid=random_forest_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "random_forest_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "random_forest_classifier_best_estimator = random_forest_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "random_forest_classifier_search_results = pd.DataFrame(random_forest_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "random_forest_classifier_predictions = pd.DataFrame(random_forest_classifier_best_estimator.predict(X_test))\n",
      "random_forest_classifier_predictions_prob = random_forest_classifier_best_estimator.predict_proba(X_test)\n",
      "random_forest_classifier_predictions_prob_df = pd.DataFrame()\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[0]] = random_forest_classifier_predictions_prob[:,0]\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]] = random_forest_classifier_predictions_prob[:,1] \n",
      "random_forest_classifier_accuracy = accuracy_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_f1_score = f1_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_precision = precision_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_recall = recall_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_roc_auc_score = roc_auc_score(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_performance_metrics = [['random_forest_classifier','accuracy',random_forest_classifier_accuracy], \n",
      "                                  ['random_forest_classifier','f1_score',random_forest_classifier_f1_score],\n",
      "                                  ['random_forest_classifier','precision', random_forest_classifier_precision],\n",
      "                                  ['random_forest_classifier','recall', random_forest_classifier_recall],\n",
      "                                  ['random_forest_classifier','roc_auc_score', random_forest_classifier_roc_auc_score]]\n",
      "random_forest_classifier_performance_metrics = pd.DataFrame(random_forest_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "random_forest_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Random Forest Classifier #####\n",
      "\n",
      "random_forest_classifier_performance_metrics\n",
      "random_forest_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Random Forest Classifier #####\n"
     ]
    }
   ],
   "source": [
    "clf_pypelines_all.set_model_grid_search_settings(model_name = ['Random Forest'],hyperparam_dict = rf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
