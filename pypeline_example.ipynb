{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from pypelines.sklearn_pypeline import SklearnPipeline\n",
    "\n",
    "from pypelines.sklearn.classification import models_classification , model_comparison_classification\n",
    "from pypelines.sklearn.regression import models_regression, model_comparison_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypelines.sklearn import classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code output\n",
    "skl_pypelines = SklearnPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'classification'\n",
    "                            , models = ['GaussianNB Classifier','Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5, output_format='code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GaussianNB Classifier', 'Logistic Regression', 'Random Forest']\n"
     ]
    }
   ],
   "source": [
    "skl_pypelines.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "titanic = pd.read_csv(\"./titanic.csv\")\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "# check categorical columns for high cardinality\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        categorical_cols.remove(col)\n",
      "\n",
      "# check text columns for low cardinality\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        ('text', text_transformer, text_cols),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Logistic Regression #####\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "log_reg_param_grid = {\n",
      "\"log_reg__C\": np.arange(0.1, 1.0, 0.1),\n",
      "\"log_reg__penalty\": ['l2'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "log_reg_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('log_reg', LogisticRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "log_reg_grid_search = GridSearchCV(estimator=log_reg_pipe, param_grid=log_reg_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "log_reg_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "log_reg_best_estimator = log_reg_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "log_reg_search_results = pd.DataFrame(log_reg_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "log_reg_predictions = pd.DataFrame(log_reg_best_estimator.predict(X_test))\n",
      "log_reg_predictions_prob = log_reg_best_estimator.predict_proba(X_test)\n",
      "log_reg_predictions_prob_df = pd.DataFrame()\n",
      "log_reg_predictions_prob_df[log_reg_grid_search.classes_[0]] = log_reg_predictions_prob[:,0]\n",
      "log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]] = log_reg_predictions_prob[:,1] \n",
      "log_reg_accuracy = accuracy_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_f1_score = f1_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_precision = precision_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_recall = recall_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_roc_auc_score = roc_auc_score(y_test, log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]])\n",
      "log_reg_performance_metrics = [['log_reg','accuracy',log_reg_accuracy], \n",
      "                                  ['log_reg','f1_score',log_reg_f1_score],\n",
      "                                  ['log_reg','precision', log_reg_precision],\n",
      "                                  ['log_reg','recall', log_reg_recall],\n",
      "                                  ['log_reg','roc_auc_score', log_reg_roc_auc_score]]\n",
      "log_reg_performance_metrics = pd.DataFrame(log_reg_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]])\n",
      "log_reg_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "log_reg_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "log_reg_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "log_reg_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Logistic Regression #####\n",
      "\n",
      "log_reg_performance_metrics\n",
      "log_reg_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Logistic Regression #####\n",
      "\n",
      "##### Model Pipeline for Random Forest #####\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "random_forest_classifier_param_grid = {\n",
      "\"random_forest_classifier__n_estimators\": np.arange(10, 100, 20),\n",
      "\"random_forest_classifier__max_depth\": np.arange(2, 10, 2),\n",
      "\"random_forest_classifier__min_samples_split\": np.arange(0.5, 1.0, 0.1),\n",
      "\"random_forest_classifier__min_samples_leaf\": np.arange(1, 10, 2),\n",
      "\"random_forest_classifier__criterion\": ['gini'],\n",
      "\"random_forest_classifier__max_features\": ['auto'],\n",
      "\"random_forest_classifier__bootstrap\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "random_forest_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('random_forest_classifier', RandomForestClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "random_forest_classifier_grid_search = GridSearchCV(estimator=random_forest_classifier_pipe, param_grid=random_forest_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "random_forest_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "random_forest_classifier_best_estimator = random_forest_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "random_forest_classifier_search_results = pd.DataFrame(random_forest_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "random_forest_classifier_predictions = pd.DataFrame(random_forest_classifier_best_estimator.predict(X_test))\n",
      "random_forest_classifier_predictions_prob = random_forest_classifier_best_estimator.predict_proba(X_test)\n",
      "random_forest_classifier_predictions_prob_df = pd.DataFrame()\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[0]] = random_forest_classifier_predictions_prob[:,0]\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]] = random_forest_classifier_predictions_prob[:,1] \n",
      "random_forest_classifier_accuracy = accuracy_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_f1_score = f1_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_precision = precision_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_recall = recall_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_roc_auc_score = roc_auc_score(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_performance_metrics = [['random_forest_classifier','accuracy',random_forest_classifier_accuracy], \n",
      "                                  ['random_forest_classifier','f1_score',random_forest_classifier_f1_score],\n",
      "                                  ['random_forest_classifier','precision', random_forest_classifier_precision],\n",
      "                                  ['random_forest_classifier','recall', random_forest_classifier_recall],\n",
      "                                  ['random_forest_classifier','roc_auc_score', random_forest_classifier_roc_auc_score]]\n",
      "random_forest_classifier_performance_metrics = pd.DataFrame(random_forest_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "random_forest_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Random Forest #####\n",
      "\n",
      "random_forest_classifier_performance_metrics\n",
      "random_forest_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Random Forest #####\n",
      "\n",
      "##### Model Pipeline for GaussianNB Classifier #####\n",
      "\n",
      "from naive_bayes import GaussianNB\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "gaussian_nb_classifier_param_grid = {\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gaussian_nb_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gaussian_nb_classifier', GaussianNB())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gaussian_nb_classifier_grid_search = GridSearchCV(estimator=gaussian_nb_classifier_pipe, param_grid=gaussian_nb_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "gaussian_nb_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gaussian_nb_classifier_best_estimator = gaussian_nb_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gaussian_nb_classifier_search_results = pd.DataFrame(gaussian_nb_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gaussian_nb_classifier_predictions = pd.DataFrame(gaussian_nb_classifier_best_estimator.predict(X_test))\n",
      "gaussian_nb_classifier_predictions_prob = gaussian_nb_classifier_best_estimator.predict_proba(X_test)\n",
      "gaussian_nb_classifier_predictions_prob_df = pd.DataFrame()\n",
      "gaussian_nb_classifier_predictions_prob_df[gaussian_nb_classifier_grid_search.classes_[0]] = gaussian_nb_classifier_predictions_prob[:,0]\n",
      "gaussian_nb_classifier_predictions_prob_df[gaussian_nb_classifier_grid_search.classes_[1]] = gaussian_nb_classifier_predictions_prob[:,1] \n",
      "gaussian_nb_classifier_accuracy = accuracy_score(y_test, gaussian_nb_classifier_predictions.iloc[:,0])\n",
      "gaussian_nb_classifier_f1_score = f1_score(y_test, gaussian_nb_classifier_predictions.iloc[:,0])\n",
      "gaussian_nb_classifier_precision = precision_score(y_test, gaussian_nb_classifier_predictions.iloc[:,0])\n",
      "gaussian_nb_classifier_recall = recall_score(y_test, gaussian_nb_classifier_predictions.iloc[:,0])\n",
      "gaussian_nb_classifier_roc_auc_score = roc_auc_score(y_test, gaussian_nb_classifier_predictions_prob_df[gaussian_nb_classifier_grid_search.classes_[1]])\n",
      "gaussian_nb_classifier_performance_metrics = [['gaussian_nb_classifier','accuracy',gaussian_nb_classifier_accuracy], \n",
      "                                  ['gaussian_nb_classifier','f1_score',gaussian_nb_classifier_f1_score],\n",
      "                                  ['gaussian_nb_classifier','precision', gaussian_nb_classifier_precision],\n",
      "                                  ['gaussian_nb_classifier','recall', gaussian_nb_classifier_recall],\n",
      "                                  ['gaussian_nb_classifier','roc_auc_score', gaussian_nb_classifier_roc_auc_score]]\n",
      "gaussian_nb_classifier_performance_metrics = pd.DataFrame(gaussian_nb_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, gaussian_nb_classifier_predictions_prob_df[gaussian_nb_classifier_grid_search.classes_[1]])\n",
      "gaussian_nb_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "gaussian_nb_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "gaussian_nb_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "gaussian_nb_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics GaussianNB Classifier #####\n",
      "\n",
      "gaussian_nb_classifier_performance_metrics\n",
      "gaussian_nb_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for GaussianNB Classifier #####\n"
     ]
    }
   ],
   "source": [
    "skl_pypelines.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script output\n",
    "skl_pypelines = SklearnPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'regression'\n",
    "                            #, models = ['GaussianNB Classifier','Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5, output_format='script',\n",
    "                            output_folder = \"./code_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elastic Net', 'Linear Regression', 'Lasso', 'Ridge', 'SGD Regressor Regression', 'Histogram Gradient Boost Regression', 'Random Forest Regression', 'AdaBoost Regression', 'Poisson Regression', 'Decision Tree Regression', 'GBT Regression', 'ExtraTree Regression', 'GPR Regression', 'Bayesian ARD Regression', 'Bayesian Ridge Regression', 'Quantile Regression', 'Huber Regression', 'TheilSen Regression', 'Passive Aggressive Regression', 'Gamma Regression', 'Tweedie Regression', 'OMP Regression', 'LassoLars Regression', 'RANSAC Regression']\n"
     ]
    }
   ],
   "source": [
    "skl_pypelines.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_prep_pipeline': {'code': '\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.metrics import mean_squared_error\\n\\n\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.impute import SimpleImputer\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\n\\n\\n# target dataframe: titanic\\ntitanic = pd.read_csv(\"./titanic.csv\")\\ntarget = \"Survived\"\\nfeatures = list(titanic.columns.drop(\"Survived\"))\\nfeature_df = titanic[features]\\n\\n# get numerical and categorical columns\\nbool_cols = feature_df.select_dtypes(include=[\\'bool\\']).columns.tolist()\\ntitanic[bool_cols] = feature_df[bool_cols].astype(int)\\nnumerical_cols = feature_df.select_dtypes(include=[\\'int\\', \\'float\\']).columns.tolist()\\ncategorical_cols = feature_df.select_dtypes(include=[\\'object\\']).columns.tolist()\\ntext_cols = feature_df.select_dtypes(include=[\\'string\\']).columns.tolist()\\n# check categorical columns for high cardinality\\n\\nsample_size = np.min([10000, titanic.shape[0]])\\nunique_theshold = np.min([100, sample_size/10])\\n\\n# check categorical columns for high cardinality\\nfor col in categorical_cols:\\n    if titanic[col].sample(sample_size).nunique() > unique_theshold:\\n        categorical_cols.remove(col)\\n\\n# check text columns for low cardinality\\nfor col in text_cols:\\n    if titanic[col].sample(sample_size).nunique() < unique_theshold:\\n        categorical_cols.append(col)\\n        text_cols.remove(col)\\n\\n# define numeric transformer steps\\nnumeric_transformer = Pipeline(\\n    steps=[\\n        (\"imputer\", SimpleImputer(strategy=\"median\")), \\n        (\"scaler\", StandardScaler())]\\n)\\n\\n# define categorical transformer steps\\ncategorical_transformer = Pipeline(\\n    steps=[\\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \\n        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\\n    ]\\n)\\n\\n# define text transformer steps\\ntext_transformer = Pipeline(\\n    steps=[\\n        (\\'text\\', TfidfVectorizer())\\n    ]\\n)\\n\\n# create the preprocessing pipelines for both numeric and categorical data\\npreprocessor = ColumnTransformer(\\n    transformers=[\\n        (\\'num\\', numeric_transformer , numerical_cols),\\n        (\\'cat\\', categorical_transformer, categorical_cols),\\n        (\\'text\\', text_transformer, text_cols),\\n    ]\\n)\\n\\n# train test split\\nX = titanic[features]\\ny = titanic[target]\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n##### End of Data Processing Pipeline #####\\n\\n'}, 'Elastic Net': {'code': '\\n\\n##### Model Pipeline for Elastic Net #####\\n\\nfrom sklearn.linear_model import ElasticNet\\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nelastic_net_regression_param_grid = {\\n\"elastic_net_regression__alpha\": np.arange(0.1, 1.0, 0.5),\\n\"elastic_net_regression__l1_ratio\": np.arange(0.0, 1.0, 0.1),\\n\"elastic_net_regression__max_iter\": np.arange(500, 1000, 100),\\n\"elastic_net_regression__fit_intercept\": [True],\\n\"elastic_net_regression__precompute\": [False],\\n\"elastic_net_regression__selection\": [\\'cyclic\\'],\\n}\\n\\n\\n# Create the pipeline\\nelastic_net_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'elastic_net_regression\\', ElasticNet())\\n])\\n\\n# Create the grid search\\nelastic_net_regression_grid_search = GridSearchCV(estimator=elastic_net_regression_pipe, param_grid=elastic_net_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nelastic_net_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nelastic_net_regression_best_estimator = elastic_net_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nelastic_net_regression_search_results = pd.DataFrame(elastic_net_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nelastic_net_regression_predictions = pd.DataFrame(elastic_net_regression_best_estimator.predict(X_test))\\nelastic_net_regression_r2_score = r2_score(y_test, elastic_net_regression_predictions.iloc[:,0])\\nelastic_net_regression_mean_squared_error = mean_squared_error(y_test, elastic_net_regression_predictions.iloc[:,0])\\nelastic_net_regression_explained_variance_score = explained_variance_score(y_test, elastic_net_regression_predictions.iloc[:,0])\\nelastic_net_regression_performance_metrics = [[\\'elastic_net_regression\\',\\'r2_score\\', elastic_net_regression_r2_score], \\n                                  [\\'elastic_net_regression\\',\\'mean_squared_error\\',elastic_net_regression_mean_squared_error],\\n                                  [\\'elastic_net_regression\\',\\'explained_variance_score\\', elastic_net_regression_explained_variance_score]]\\nelastic_net_regression_performance_metrics = pd.DataFrame(elastic_net_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nelastic_net_regression_actual_predicted_plot = px.scatter(x=y_test, y=elastic_net_regression_predictions.iloc[:,0])\\nelastic_net_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nelastic_net_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Elastic Net #####\\n\\nelastic_net_regression_performance_metrics\\nelastic_net_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Elastic Net #####'}, 'Linear Regression': {'code': '\\n\\n##### Model Pipeline for Linear Regression #####\\n\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nlin_reg_param_grid = {\\n\"lin_reg__n_jobs\": np.arange(1, 10, 1),\\n\"lin_reg__fit_intercept\": [True],\\n}\\n\\n\\n# Create the pipeline\\nlin_reg_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'lin_reg\\', LinearRegression())\\n])\\n\\n# Create the grid search\\nlin_reg_grid_search = GridSearchCV(estimator=lin_reg_pipe, param_grid=lin_reg_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nlin_reg_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nlin_reg_best_estimator = lin_reg_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nlin_reg_search_results = pd.DataFrame(lin_reg_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nlin_reg_predictions = pd.DataFrame(lin_reg_best_estimator.predict(X_test))\\nlin_reg_r2_score = r2_score(y_test, lin_reg_predictions.iloc[:,0])\\nlin_reg_mean_squared_error = mean_squared_error(y_test, lin_reg_predictions.iloc[:,0])\\nlin_reg_explained_variance_score = explained_variance_score(y_test, lin_reg_predictions.iloc[:,0])\\nlin_reg_performance_metrics = [[\\'lin_reg\\',\\'r2_score\\', lin_reg_r2_score], \\n                                  [\\'lin_reg\\',\\'mean_squared_error\\',lin_reg_mean_squared_error],\\n                                  [\\'lin_reg\\',\\'explained_variance_score\\', lin_reg_explained_variance_score]]\\nlin_reg_performance_metrics = pd.DataFrame(lin_reg_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nlin_reg_actual_predicted_plot = px.scatter(x=y_test, y=lin_reg_predictions.iloc[:,0])\\nlin_reg_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nlin_reg_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Linear Regression #####\\n\\nlin_reg_performance_metrics\\nlin_reg_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Linear Regression #####'}, 'Lasso': {'code': '\\n\\n##### Model Pipeline for Lasso #####\\n\\nfrom sklearn.linear_model import Lasso\\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nlasso_regression_param_grid = {\\n\"lasso_regression__alpha\": np.arange(10, 100, 10),\\n\"lasso_regression__max_iter\": np.arange(100, 1000, 100),\\n\"lasso_regression__fit_intercept\": [True],\\n\"lasso_regression__precompute\": [False],\\n\"lasso_regression__positive\": [True],\\n\"lasso_regression__selection\": [\\'cyclic\\'],\\n}\\n\\n\\n# Create the pipeline\\nlasso_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'lasso_regression\\', Lasso())\\n])\\n\\n# Create the grid search\\nlasso_regression_grid_search = GridSearchCV(estimator=lasso_regression_pipe, param_grid=lasso_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nlasso_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nlasso_regression_best_estimator = lasso_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nlasso_regression_search_results = pd.DataFrame(lasso_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nlasso_regression_predictions = pd.DataFrame(lasso_regression_best_estimator.predict(X_test))\\nlasso_regression_r2_score = r2_score(y_test, lasso_regression_predictions.iloc[:,0])\\nlasso_regression_mean_squared_error = mean_squared_error(y_test, lasso_regression_predictions.iloc[:,0])\\nlasso_regression_explained_variance_score = explained_variance_score(y_test, lasso_regression_predictions.iloc[:,0])\\nlasso_regression_performance_metrics = [[\\'lasso_regression\\',\\'r2_score\\', lasso_regression_r2_score], \\n                                  [\\'lasso_regression\\',\\'mean_squared_error\\',lasso_regression_mean_squared_error],\\n                                  [\\'lasso_regression\\',\\'explained_variance_score\\', lasso_regression_explained_variance_score]]\\nlasso_regression_performance_metrics = pd.DataFrame(lasso_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nlasso_regression_actual_predicted_plot = px.scatter(x=y_test, y=lasso_regression_predictions.iloc[:,0])\\nlasso_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nlasso_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Lasso #####\\n\\nlasso_regression_performance_metrics\\nlasso_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Lasso #####'}, 'Ridge': {'code': '\\n\\n##### Model Pipeline for Ridge #####\\n\\nfrom sklearn.linear_model import Ridge \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nridge_regression_param_grid = {\\n\"ridge_regression__alpha\": np.arange(10, 100, 10),\\n\"ridge_regression__max_iter\": np.arange(100, 1000, 100),\\n\"ridge_regression__fit_intercept\": [True],\\n\"ridge_regression__positive\": [True],\\n}\\n\\n\\n# Create the pipeline\\nridge_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'ridge_regression\\', Ridge())\\n])\\n\\n# Create the grid search\\nridge_regression_grid_search = GridSearchCV(estimator=ridge_regression_pipe, param_grid=ridge_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nridge_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nridge_regression_best_estimator = ridge_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nridge_regression_search_results = pd.DataFrame(ridge_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nridge_regression_predictions = pd.DataFrame(ridge_regression_best_estimator.predict(X_test))\\nridge_regression_r2_score = r2_score(y_test, ridge_regression_predictions.iloc[:,0])\\nridge_regression_mean_squared_error = mean_squared_error(y_test, ridge_regression_predictions.iloc[:,0])\\nridge_regression_explained_variance_score = explained_variance_score(y_test, ridge_regression_predictions.iloc[:,0])\\nridge_regression_performance_metrics = [[\\'ridge_regression\\',\\'r2_score\\', ridge_regression_r2_score], \\n                                  [\\'ridge_regression\\',\\'mean_squared_error\\',ridge_regression_mean_squared_error],\\n                                  [\\'ridge_regression\\',\\'explained_variance_score\\', ridge_regression_explained_variance_score]]\\nridge_regression_performance_metrics = pd.DataFrame(ridge_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nridge_regression_actual_predicted_plot = px.scatter(x=y_test, y=ridge_regression_predictions.iloc[:,0])\\nridge_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nridge_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Ridge #####\\n\\nridge_regression_performance_metrics\\nridge_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Ridge #####'}, 'SGD Regressor Regression': {'code': '\\n\\n##### Model Pipeline for SGD Regressor Regression #####\\n\\nfrom sklearn.linear_model import SGDRegressor\\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nsgd_regressor_regression_param_grid = {\\n\"sgd_regressor_regression__alpha\": np.arange(0.1, 1.0, 0.5),\\n\"sgd_regressor_regression__l1_ratio\": np.arange(0.0, 1.0, 0.1),\\n\"sgd_regressor_regression__max_iter\": np.arange(500, 1000, 500),\\n\"sgd_regressor_regression__epsilon\": np.arange(0.001, 0.1, 0.05),\\n\"sgd_regressor_regression__fit_intercept\": [True],\\n\"sgd_regressor_regression__early_stopping\": [False],\\n\"sgd_regressor_regression__warm_start\": [False],\\n\"sgd_regressor_regression__shuffle\": [True],\\n}\\n\\n\\n# Create the pipeline\\nsgd_regressor_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'sgd_regressor_regression\\', SGDRegressor())\\n])\\n\\n# Create the grid search\\nsgd_regressor_regression_grid_search = GridSearchCV(estimator=sgd_regressor_regression_pipe, param_grid=sgd_regressor_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nsgd_regressor_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nsgd_regressor_regression_best_estimator = sgd_regressor_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nsgd_regressor_regression_search_results = pd.DataFrame(sgd_regressor_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nsgd_regressor_regression_predictions = pd.DataFrame(sgd_regressor_regression_best_estimator.predict(X_test))\\nsgd_regressor_regression_r2_score = r2_score(y_test, sgd_regressor_regression_predictions.iloc[:,0])\\nsgd_regressor_regression_mean_squared_error = mean_squared_error(y_test, sgd_regressor_regression_predictions.iloc[:,0])\\nsgd_regressor_regression_explained_variance_score = explained_variance_score(y_test, sgd_regressor_regression_predictions.iloc[:,0])\\nsgd_regressor_regression_performance_metrics = [[\\'sgd_regressor_regression\\',\\'r2_score\\', sgd_regressor_regression_r2_score], \\n                                  [\\'sgd_regressor_regression\\',\\'mean_squared_error\\',sgd_regressor_regression_mean_squared_error],\\n                                  [\\'sgd_regressor_regression\\',\\'explained_variance_score\\', sgd_regressor_regression_explained_variance_score]]\\nsgd_regressor_regression_performance_metrics = pd.DataFrame(sgd_regressor_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nsgd_regressor_regression_actual_predicted_plot = px.scatter(x=y_test, y=sgd_regressor_regression_predictions.iloc[:,0])\\nsgd_regressor_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nsgd_regressor_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics SGD Regressor Regression #####\\n\\nsgd_regressor_regression_performance_metrics\\nsgd_regressor_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for SGD Regressor Regression #####'}, 'Histogram Gradient Boost Regression': {'code': '\\n\\n##### Model Pipeline for Histogram Gradient Boost Regression #####\\n\\nfrom sklearn.ensemble import HistGradientBoostingRegressor\\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nhist_gbt_regression_param_grid = {\\n\"hist_gbt_regression__max_iter\": np.arange(10, 100, 5),\\n\"hist_gbt_regression__max_leaf_nodes\": np.arange(2, 31, 6),\\n\"hist_gbt_regression__min_samples_leaf\": np.arange(2, 20, 5),\\n\"hist_gbt_regression__max_bins\": np.arange(25, 255, 25),\\n\"hist_gbt_regression__early_stopping\": [False],\\n\"hist_gbt_regression__warm_start\": [False],\\n}\\n\\n\\n# Create the pipeline\\nhist_gbt_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'hist_gbt_regression\\', HistoGBTRegressor())\\n])\\n\\n# Create the grid search\\nhist_gbt_regression_grid_search = GridSearchCV(estimator=hist_gbt_regression_pipe, param_grid=hist_gbt_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nhist_gbt_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nhist_gbt_regression_best_estimator = hist_gbt_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nhist_gbt_regression_search_results = pd.DataFrame(hist_gbt_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nhist_gbt_regression_predictions = pd.DataFrame(hist_gbt_regression_best_estimator.predict(X_test))\\nhist_gbt_regression_r2_score = r2_score(y_test, hist_gbt_regression_predictions.iloc[:,0])\\nhist_gbt_regression_mean_squared_error = mean_squared_error(y_test, hist_gbt_regression_predictions.iloc[:,0])\\nhist_gbt_regression_explained_variance_score = explained_variance_score(y_test, hist_gbt_regression_predictions.iloc[:,0])\\nhist_gbt_regression_performance_metrics = [[\\'hist_gbt_regression\\',\\'r2_score\\', hist_gbt_regression_r2_score], \\n                                  [\\'hist_gbt_regression\\',\\'mean_squared_error\\',hist_gbt_regression_mean_squared_error],\\n                                  [\\'hist_gbt_regression\\',\\'explained_variance_score\\', hist_gbt_regression_explained_variance_score]]\\nhist_gbt_regression_performance_metrics = pd.DataFrame(hist_gbt_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nhist_gbt_regression_actual_predicted_plot = px.scatter(x=y_test, y=hist_gbt_regression_predictions.iloc[:,0])\\nhist_gbt_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nhist_gbt_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Histogram Gradient Boost Regression #####\\n\\nhist_gbt_regression_performance_metrics\\nhist_gbt_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Histogram Gradient Boost Regression #####'}, 'Random Forest Regression': {'code': '\\n\\n##### Model Pipeline for Random Forest Regression #####\\n\\nfrom sklearn.ensemble import RandomForestRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nrandom_forest_regression_param_grid = {\\n\"random_forest_regression__n_estimators\": np.arange(10, 100, 5),\\n\"random_forest_regression__bootstrap\": [True],\\n\"random_forest_regression__warm_start\": [False],\\n}\\n\\n\\n# Create the pipeline\\nrandom_forest_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'random_forest_regression\\', RandomForestRegressor())\\n])\\n\\n# Create the grid search\\nrandom_forest_regression_grid_search = GridSearchCV(estimator=random_forest_regression_pipe, param_grid=random_forest_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nrandom_forest_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nrandom_forest_regression_best_estimator = random_forest_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nrandom_forest_regression_search_results = pd.DataFrame(random_forest_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nrandom_forest_regression_predictions = pd.DataFrame(random_forest_regression_best_estimator.predict(X_test))\\nrandom_forest_regression_r2_score = r2_score(y_test, random_forest_regression_predictions.iloc[:,0])\\nrandom_forest_regression_mean_squared_error = mean_squared_error(y_test, random_forest_regression_predictions.iloc[:,0])\\nrandom_forest_regression_explained_variance_score = explained_variance_score(y_test, random_forest_regression_predictions.iloc[:,0])\\nrandom_forest_regression_performance_metrics = [[\\'random_forest_regression\\',\\'r2_score\\', random_forest_regression_r2_score], \\n                                  [\\'random_forest_regression\\',\\'mean_squared_error\\',random_forest_regression_mean_squared_error],\\n                                  [\\'random_forest_regression\\',\\'explained_variance_score\\', random_forest_regression_explained_variance_score]]\\nrandom_forest_regression_performance_metrics = pd.DataFrame(random_forest_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nrandom_forest_regression_actual_predicted_plot = px.scatter(x=y_test, y=random_forest_regression_predictions.iloc[:,0])\\nrandom_forest_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nrandom_forest_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Random Forest Regression #####\\n\\nrandom_forest_regression_performance_metrics\\nrandom_forest_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Random Forest Regression #####'}, 'AdaBoost Regression': {'code': '\\n\\n##### Model Pipeline for AdaBoost Regression #####\\n\\nfrom sklearn.ensemble import AdaBoostRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nadaboost_regression_param_grid = {\\n\"adaboost_regression__n_estimators\": np.arange(10, 50, 10),\\n\"adaboost_regression__loss\": [\\'linear\\'],\\n}\\n\\n\\n# Create the pipeline\\nadaboost_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'adaboost_regression\\', AdaBoostRegressor())\\n])\\n\\n# Create the grid search\\nadaboost_regression_grid_search = GridSearchCV(estimator=adaboost_regression_pipe, param_grid=adaboost_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nadaboost_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nadaboost_regression_best_estimator = adaboost_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nadaboost_regression_search_results = pd.DataFrame(adaboost_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nadaboost_regression_predictions = pd.DataFrame(adaboost_regression_best_estimator.predict(X_test))\\nadaboost_regression_r2_score = r2_score(y_test, adaboost_regression_predictions.iloc[:,0])\\nadaboost_regression_mean_squared_error = mean_squared_error(y_test, adaboost_regression_predictions.iloc[:,0])\\nadaboost_regression_explained_variance_score = explained_variance_score(y_test, adaboost_regression_predictions.iloc[:,0])\\nadaboost_regression_performance_metrics = [[\\'adaboost_regression\\',\\'r2_score\\', adaboost_regression_r2_score], \\n                                  [\\'adaboost_regression\\',\\'mean_squared_error\\',adaboost_regression_mean_squared_error],\\n                                  [\\'adaboost_regression\\',\\'explained_variance_score\\', adaboost_regression_explained_variance_score]]\\nadaboost_regression_performance_metrics = pd.DataFrame(adaboost_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nadaboost_regression_actual_predicted_plot = px.scatter(x=y_test, y=adaboost_regression_predictions.iloc[:,0])\\nadaboost_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nadaboost_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics AdaBoost Regression #####\\n\\nadaboost_regression_performance_metrics\\nadaboost_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for AdaBoost Regression #####'}, 'Poisson Regression': {'code': '\\n\\n##### Model Pipeline for Poisson Regression #####\\n\\nfrom sklearn.linear_model import PoissonRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\npoisson_regression_param_grid = {\\n\"poisson_regression__alpha\": np.arange(0.1, 1.0, 0.005),\\n\"poisson_regression__max_iter\": np.arange(100, 1000, 100),\\n\"poisson_regression__fit_intercept\": [True],\\n\"poisson_regression__solver\": [\\'lbfgs\\'],\\n\"poisson_regression__warm_start\": [True],\\n}\\n\\n\\n# Create the pipeline\\npoisson_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'poisson_regression\\', PoissonRegressor())\\n])\\n\\n# Create the grid search\\npoisson_regression_grid_search = GridSearchCV(estimator=poisson_regression_pipe, param_grid=poisson_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\npoisson_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\npoisson_regression_best_estimator = poisson_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\npoisson_regression_search_results = pd.DataFrame(poisson_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\npoisson_regression_predictions = pd.DataFrame(poisson_regression_best_estimator.predict(X_test))\\npoisson_regression_r2_score = r2_score(y_test, poisson_regression_predictions.iloc[:,0])\\npoisson_regression_mean_squared_error = mean_squared_error(y_test, poisson_regression_predictions.iloc[:,0])\\npoisson_regression_explained_variance_score = explained_variance_score(y_test, poisson_regression_predictions.iloc[:,0])\\npoisson_regression_performance_metrics = [[\\'poisson_regression\\',\\'r2_score\\', poisson_regression_r2_score], \\n                                  [\\'poisson_regression\\',\\'mean_squared_error\\',poisson_regression_mean_squared_error],\\n                                  [\\'poisson_regression\\',\\'explained_variance_score\\', poisson_regression_explained_variance_score]]\\npoisson_regression_performance_metrics = pd.DataFrame(poisson_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\npoisson_regression_actual_predicted_plot = px.scatter(x=y_test, y=poisson_regression_predictions.iloc[:,0])\\npoisson_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\npoisson_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Poisson Regression #####\\n\\npoisson_regression_performance_metrics\\npoisson_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Poisson Regression #####'}, 'Decision Tree Regression': {'code': '\\n\\n##### Model Pipeline for Decision Tree Regression #####\\n\\nfrom sklearn.tree import DecisionTreeRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\ndecision_tree_regression_param_grid = {\\n\"decision_tree_regression__max_depth\": np.arange(1, 100, 10),\\n\"decision_tree_regression__max_features\": [None],\\n\"decision_tree_regression__splitter\": [\\'best\\'],\\n}\\n\\n\\n# Create the pipeline\\ndecision_tree_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'decision_tree_regression\\', DecisionTreeRegressor())\\n])\\n\\n# Create the grid search\\ndecision_tree_regression_grid_search = GridSearchCV(estimator=decision_tree_regression_pipe, param_grid=decision_tree_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\ndecision_tree_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\ndecision_tree_regression_best_estimator = decision_tree_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\ndecision_tree_regression_search_results = pd.DataFrame(decision_tree_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\ndecision_tree_regression_predictions = pd.DataFrame(decision_tree_regression_best_estimator.predict(X_test))\\ndecision_tree_regression_r2_score = r2_score(y_test, decision_tree_regression_predictions.iloc[:,0])\\ndecision_tree_regression_mean_squared_error = mean_squared_error(y_test, decision_tree_regression_predictions.iloc[:,0])\\ndecision_tree_regression_explained_variance_score = explained_variance_score(y_test, decision_tree_regression_predictions.iloc[:,0])\\ndecision_tree_regression_performance_metrics = [[\\'decision_tree_regression\\',\\'r2_score\\', decision_tree_regression_r2_score], \\n                                  [\\'decision_tree_regression\\',\\'mean_squared_error\\',decision_tree_regression_mean_squared_error],\\n                                  [\\'decision_tree_regression\\',\\'explained_variance_score\\', decision_tree_regression_explained_variance_score]]\\ndecision_tree_regression_performance_metrics = pd.DataFrame(decision_tree_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\ndecision_tree_regression_actual_predicted_plot = px.scatter(x=y_test, y=decision_tree_regression_predictions.iloc[:,0])\\ndecision_tree_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\ndecision_tree_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Decision Tree Regression #####\\n\\ndecision_tree_regression_performance_metrics\\ndecision_tree_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Decision Tree Regression #####'}, 'GBT Regression': {'code': '\\n\\n##### Model Pipeline for GBT Regression #####\\n\\nfrom sklearn.ensemble import GradientBoostingRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\ngbt_regression_param_grid = {\\n\"gbt_regression__n_estimators\": np.arange(1, 100, 10),\\n\"gbt_regression__max_depth\": np.arange(1, 3, 1),\\n\"gbt_regression__alpha\": np.arange(0.1, 1.0, 0.5),\\n\"gbt_regression__max_features\": [None],\\n\"gbt_regression__warm_start\": [False],\\n}\\n\\n\\n# Create the pipeline\\ngbt_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'gbt_regression\\', GradientBoostingRegressor())\\n])\\n\\n# Create the grid search\\ngbt_regression_grid_search = GridSearchCV(estimator=gbt_regression_pipe, param_grid=gbt_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\ngbt_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\ngbt_regression_best_estimator = gbt_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\ngbt_regression_search_results = pd.DataFrame(gbt_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\ngbt_regression_predictions = pd.DataFrame(gbt_regression_best_estimator.predict(X_test))\\ngbt_regression_r2_score = r2_score(y_test, gbt_regression_predictions.iloc[:,0])\\ngbt_regression_mean_squared_error = mean_squared_error(y_test, gbt_regression_predictions.iloc[:,0])\\ngbt_regression_explained_variance_score = explained_variance_score(y_test, gbt_regression_predictions.iloc[:,0])\\ngbt_regression_performance_metrics = [[\\'gbt_regression\\',\\'r2_score\\', gbt_regression_r2_score], \\n                                  [\\'gbt_regression\\',\\'mean_squared_error\\',gbt_regression_mean_squared_error],\\n                                  [\\'gbt_regression\\',\\'explained_variance_score\\', gbt_regression_explained_variance_score]]\\ngbt_regression_performance_metrics = pd.DataFrame(gbt_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\ngbt_regression_actual_predicted_plot = px.scatter(x=y_test, y=gbt_regression_predictions.iloc[:,0])\\ngbt_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\ngbt_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics GBT Regression #####\\n\\ngbt_regression_performance_metrics\\ngbt_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for GBT Regression #####'}, 'ExtraTree Regression': {'code': '\\n\\n##### Model Pipeline for ExtraTree Regression #####\\n\\nfrom sklearn.ensemble import ExtraTreesRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nextra_tree_regression_param_grid = {\\n\"extra_tree_regression__n_estimators\": np.arange(10, 100, 10),\\n\"extra_tree_regression__max_features\": [None],\\n\"extra_tree_regression__warm_start\": [False],\\n\"extra_tree_regression__bootstrap\": [False],\\n}\\n\\n\\n# Create the pipeline\\nextra_tree_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'extra_tree_regression\\', ExtraTreesRegressor())\\n])\\n\\n# Create the grid search\\nextra_tree_regression_grid_search = GridSearchCV(estimator=extra_tree_regression_pipe, param_grid=extra_tree_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nextra_tree_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nextra_tree_regression_best_estimator = extra_tree_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nextra_tree_regression_search_results = pd.DataFrame(extra_tree_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nextra_tree_regression_predictions = pd.DataFrame(extra_tree_regression_best_estimator.predict(X_test))\\nextra_tree_regression_r2_score = r2_score(y_test, extra_tree_regression_predictions.iloc[:,0])\\nextra_tree_regression_mean_squared_error = mean_squared_error(y_test, extra_tree_regression_predictions.iloc[:,0])\\nextra_tree_regression_explained_variance_score = explained_variance_score(y_test, extra_tree_regression_predictions.iloc[:,0])\\nextra_tree_regression_performance_metrics = [[\\'extra_tree_regression\\',\\'r2_score\\', extra_tree_regression_r2_score], \\n                                  [\\'extra_tree_regression\\',\\'mean_squared_error\\',extra_tree_regression_mean_squared_error],\\n                                  [\\'extra_tree_regression\\',\\'explained_variance_score\\', extra_tree_regression_explained_variance_score]]\\nextra_tree_regression_performance_metrics = pd.DataFrame(extra_tree_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nextra_tree_regression_actual_predicted_plot = px.scatter(x=y_test, y=extra_tree_regression_predictions.iloc[:,0])\\nextra_tree_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nextra_tree_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics ExtraTree Regression #####\\n\\nextra_tree_regression_performance_metrics\\nextra_tree_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for ExtraTree Regression #####'}, 'GPR Regression': {'code': '\\n\\n##### Model Pipeline for GPR Regression #####\\n\\nfrom sklearn.gaussian_process import GaussianProcessRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\ngpr_regression_param_grid = {\\n\"gpr_regression__optimizer\": [None],\\n\"gpr_regression__normalize_y\": [False],\\n\"gpr_regression__copy_X_train\": [True],\\n}\\n\\n\\n# Create the pipeline\\ngpr_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'gpr_regression\\', GaussianProcessRegressor())\\n])\\n\\n# Create the grid search\\ngpr_regression_grid_search = GridSearchCV(estimator=gpr_regression_pipe, param_grid=gpr_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\ngpr_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\ngpr_regression_best_estimator = gpr_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\ngpr_regression_search_results = pd.DataFrame(gpr_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\ngpr_regression_predictions = pd.DataFrame(gpr_regression_best_estimator.predict(X_test))\\ngpr_regression_r2_score = r2_score(y_test, gpr_regression_predictions.iloc[:,0])\\ngpr_regression_mean_squared_error = mean_squared_error(y_test, gpr_regression_predictions.iloc[:,0])\\ngpr_regression_explained_variance_score = explained_variance_score(y_test, gpr_regression_predictions.iloc[:,0])\\ngpr_regression_performance_metrics = [[\\'gpr_regression\\',\\'r2_score\\', gpr_regression_r2_score], \\n                                  [\\'gpr_regression\\',\\'mean_squared_error\\',gpr_regression_mean_squared_error],\\n                                  [\\'gpr_regression\\',\\'explained_variance_score\\', gpr_regression_explained_variance_score]]\\ngpr_regression_performance_metrics = pd.DataFrame(gpr_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\ngpr_regression_actual_predicted_plot = px.scatter(x=y_test, y=gpr_regression_predictions.iloc[:,0])\\ngpr_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\ngpr_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics GPR Regression #####\\n\\ngpr_regression_performance_metrics\\ngpr_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for GPR Regression #####'}, 'Bayesian ARD Regression': {'code': '\\n\\n##### Model Pipeline for Bayesian ARD Regression #####\\n\\nfrom sklearn.linear_model import ARDRegression \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nbayesian_ard_regression_param_grid = {\\n\"bayesian_ard_regression__n_iter\": np.arange(10, 300, 50),\\n\"bayesian_ard_regression__fit_intercept\": [True],\\n\"bayesian_ard_regression__compute_score\": [False],\\n\"bayesian_ard_regression__copy_X\": [True],\\n}\\n\\n\\n# Create the pipeline\\nbayesian_ard_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'bayesian_ard_regression\\', ARDRegression())\\n])\\n\\n# Create the grid search\\nbayesian_ard_regression_grid_search = GridSearchCV(estimator=bayesian_ard_regression_pipe, param_grid=bayesian_ard_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nbayesian_ard_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nbayesian_ard_regression_best_estimator = bayesian_ard_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nbayesian_ard_regression_search_results = pd.DataFrame(bayesian_ard_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nbayesian_ard_regression_predictions = pd.DataFrame(bayesian_ard_regression_best_estimator.predict(X_test))\\nbayesian_ard_regression_r2_score = r2_score(y_test, bayesian_ard_regression_predictions.iloc[:,0])\\nbayesian_ard_regression_mean_squared_error = mean_squared_error(y_test, bayesian_ard_regression_predictions.iloc[:,0])\\nbayesian_ard_regression_explained_variance_score = explained_variance_score(y_test, bayesian_ard_regression_predictions.iloc[:,0])\\nbayesian_ard_regression_performance_metrics = [[\\'bayesian_ard_regression\\',\\'r2_score\\', bayesian_ard_regression_r2_score], \\n                                  [\\'bayesian_ard_regression\\',\\'mean_squared_error\\',bayesian_ard_regression_mean_squared_error],\\n                                  [\\'bayesian_ard_regression\\',\\'explained_variance_score\\', bayesian_ard_regression_explained_variance_score]]\\nbayesian_ard_regression_performance_metrics = pd.DataFrame(bayesian_ard_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nbayesian_ard_regression_actual_predicted_plot = px.scatter(x=y_test, y=bayesian_ard_regression_predictions.iloc[:,0])\\nbayesian_ard_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nbayesian_ard_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Bayesian ARD Regression #####\\n\\nbayesian_ard_regression_performance_metrics\\nbayesian_ard_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Bayesian ARD Regression #####'}, 'Bayesian Ridge Regression': {'code': '\\n\\n##### Model Pipeline for Bayesian Ridge Regression #####\\n\\nfrom sklearn.linear_model import BayesianRidge \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nbayesian_ridge_regression_param_grid = {\\n\"bayesian_ridge_regression__n_iter\": np.arange(10, 300, 50),\\n\"bayesian_ridge_regression__fit_intercept\": [True],\\n\"bayesian_ridge_regression__compute_score\": [False],\\n\"bayesian_ridge_regression__copy_X\": [True],\\n}\\n\\n\\n# Create the pipeline\\nbayesian_ridge_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'bayesian_ridge_regression\\', BayesianRidge())\\n])\\n\\n# Create the grid search\\nbayesian_ridge_regression_grid_search = GridSearchCV(estimator=bayesian_ridge_regression_pipe, param_grid=bayesian_ridge_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nbayesian_ridge_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nbayesian_ridge_regression_best_estimator = bayesian_ridge_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nbayesian_ridge_regression_search_results = pd.DataFrame(bayesian_ridge_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nbayesian_ridge_regression_predictions = pd.DataFrame(bayesian_ridge_regression_best_estimator.predict(X_test))\\nbayesian_ridge_regression_r2_score = r2_score(y_test, bayesian_ridge_regression_predictions.iloc[:,0])\\nbayesian_ridge_regression_mean_squared_error = mean_squared_error(y_test, bayesian_ridge_regression_predictions.iloc[:,0])\\nbayesian_ridge_regression_explained_variance_score = explained_variance_score(y_test, bayesian_ridge_regression_predictions.iloc[:,0])\\nbayesian_ridge_regression_performance_metrics = [[\\'bayesian_ridge_regression\\',\\'r2_score\\', bayesian_ridge_regression_r2_score], \\n                                  [\\'bayesian_ridge_regression\\',\\'mean_squared_error\\',bayesian_ridge_regression_mean_squared_error],\\n                                  [\\'bayesian_ridge_regression\\',\\'explained_variance_score\\', bayesian_ridge_regression_explained_variance_score]]\\nbayesian_ridge_regression_performance_metrics = pd.DataFrame(bayesian_ridge_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nbayesian_ridge_regression_actual_predicted_plot = px.scatter(x=y_test, y=bayesian_ridge_regression_predictions.iloc[:,0])\\nbayesian_ridge_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nbayesian_ridge_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Bayesian Ridge Regression #####\\n\\nbayesian_ridge_regression_performance_metrics\\nbayesian_ridge_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Bayesian Ridge Regression #####'}, 'Quantile Regression': {'code': '\\n\\n##### Model Pipeline for Quantile Regression #####\\n\\nfrom sklearn.linear_model import QuantileRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nquantile_regression_param_grid = {\\n\"quantile_regression__quantile\": np.arange(0.0, 1.0, 0.5),\\n\"quantile_regression__alpha\": np.arange(0.1, 1.0, 0.5),\\n\"quantile_regression__solver\": [\\'interior-point\\'],\\n}\\n\\n\\n# Create the pipeline\\nquantile_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'quantile_regression\\', QuantileRegressor())\\n])\\n\\n# Create the grid search\\nquantile_regression_grid_search = GridSearchCV(estimator=quantile_regression_pipe, param_grid=quantile_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nquantile_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nquantile_regression_best_estimator = quantile_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nquantile_regression_search_results = pd.DataFrame(quantile_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nquantile_regression_predictions = pd.DataFrame(quantile_regression_best_estimator.predict(X_test))\\nquantile_regression_r2_score = r2_score(y_test, quantile_regression_predictions.iloc[:,0])\\nquantile_regression_mean_squared_error = mean_squared_error(y_test, quantile_regression_predictions.iloc[:,0])\\nquantile_regression_explained_variance_score = explained_variance_score(y_test, quantile_regression_predictions.iloc[:,0])\\nquantile_regression_performance_metrics = [[\\'quantile_regression\\',\\'r2_score\\', quantile_regression_r2_score], \\n                                  [\\'quantile_regression\\',\\'mean_squared_error\\',quantile_regression_mean_squared_error],\\n                                  [\\'quantile_regression\\',\\'explained_variance_score\\', quantile_regression_explained_variance_score]]\\nquantile_regression_performance_metrics = pd.DataFrame(quantile_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nquantile_regression_actual_predicted_plot = px.scatter(x=y_test, y=quantile_regression_predictions.iloc[:,0])\\nquantile_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nquantile_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Quantile Regression #####\\n\\nquantile_regression_performance_metrics\\nquantile_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Quantile Regression #####'}, 'Huber Regression': {'code': '\\n\\n##### Model Pipeline for Huber Regression #####\\n\\nfrom sklearn.linear_model import HuberRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nhuber_regression_param_grid = {\\n\"huber_regression__max_iter\": np.arange(10, 100, 10),\\n\"huber_regression__warm_start\": [False],\\n\"huber_regression__fit_intercept\": [True],\\n}\\n\\n\\n# Create the pipeline\\nhuber_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'huber_regression\\', HuberRegressor())\\n])\\n\\n# Create the grid search\\nhuber_regression_grid_search = GridSearchCV(estimator=huber_regression_pipe, param_grid=huber_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nhuber_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nhuber_regression_best_estimator = huber_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nhuber_regression_search_results = pd.DataFrame(huber_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nhuber_regression_predictions = pd.DataFrame(huber_regression_best_estimator.predict(X_test))\\nhuber_regression_r2_score = r2_score(y_test, huber_regression_predictions.iloc[:,0])\\nhuber_regression_mean_squared_error = mean_squared_error(y_test, huber_regression_predictions.iloc[:,0])\\nhuber_regression_explained_variance_score = explained_variance_score(y_test, huber_regression_predictions.iloc[:,0])\\nhuber_regression_performance_metrics = [[\\'huber_regression\\',\\'r2_score\\', huber_regression_r2_score], \\n                                  [\\'huber_regression\\',\\'mean_squared_error\\',huber_regression_mean_squared_error],\\n                                  [\\'huber_regression\\',\\'explained_variance_score\\', huber_regression_explained_variance_score]]\\nhuber_regression_performance_metrics = pd.DataFrame(huber_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nhuber_regression_actual_predicted_plot = px.scatter(x=y_test, y=huber_regression_predictions.iloc[:,0])\\nhuber_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nhuber_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Huber Regression #####\\n\\nhuber_regression_performance_metrics\\nhuber_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Huber Regression #####'}, 'TheilSen Regression': {'code': '\\n\\n##### Model Pipeline for TheilSen Regression #####\\n\\nfrom sklearn.linear_model import TheilSenRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\ntheilsen_regression_param_grid = {\\n\"theilsen_regression__max_iter\": np.arange(10, 300, 50),\\n\"theilsen_regression__fit_intercept\": [True],\\n\"theilsen_regression__copy_X\": [True],\\n}\\n\\n\\n# Create the pipeline\\ntheilsen_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'theilsen_regression\\', TheilSenRegressor())\\n])\\n\\n# Create the grid search\\ntheilsen_regression_grid_search = GridSearchCV(estimator=theilsen_regression_pipe, param_grid=theilsen_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\ntheilsen_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\ntheilsen_regression_best_estimator = theilsen_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\ntheilsen_regression_search_results = pd.DataFrame(theilsen_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\ntheilsen_regression_predictions = pd.DataFrame(theilsen_regression_best_estimator.predict(X_test))\\ntheilsen_regression_r2_score = r2_score(y_test, theilsen_regression_predictions.iloc[:,0])\\ntheilsen_regression_mean_squared_error = mean_squared_error(y_test, theilsen_regression_predictions.iloc[:,0])\\ntheilsen_regression_explained_variance_score = explained_variance_score(y_test, theilsen_regression_predictions.iloc[:,0])\\ntheilsen_regression_performance_metrics = [[\\'theilsen_regression\\',\\'r2_score\\', theilsen_regression_r2_score], \\n                                  [\\'theilsen_regression\\',\\'mean_squared_error\\',theilsen_regression_mean_squared_error],\\n                                  [\\'theilsen_regression\\',\\'explained_variance_score\\', theilsen_regression_explained_variance_score]]\\ntheilsen_regression_performance_metrics = pd.DataFrame(theilsen_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\ntheilsen_regression_actual_predicted_plot = px.scatter(x=y_test, y=theilsen_regression_predictions.iloc[:,0])\\ntheilsen_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\ntheilsen_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics TheilSen Regression #####\\n\\ntheilsen_regression_performance_metrics\\ntheilsen_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for TheilSen Regression #####'}, 'Passive Aggressive Regression': {'code': '\\n\\n##### Model Pipeline for Passive Aggressive Regression #####\\n\\nfrom sklearn.linear_model import PassiveAggressiveRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\npassiveaggressive_regression_param_grid = {\\n\"passiveaggressive_regression__C\": np.arange(0.0, 1.0, 0.5),\\n\"passiveaggressive_regression__max_iter\": np.arange(100, 1000, 100),\\n\"passiveaggressive_regression__early_stopping\": [False],\\n\"passiveaggressive_regression__warm_start\": [False],\\n\"passiveaggressive_regression__early_stopping\": [False],\\n}\\n\\n\\n# Create the pipeline\\npassiveaggressive_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'passiveaggressive_regression\\', PassiveAggressiveRegressor())\\n])\\n\\n# Create the grid search\\npassiveaggressive_regression_grid_search = GridSearchCV(estimator=passiveaggressive_regression_pipe, param_grid=passiveaggressive_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\npassiveaggressive_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\npassiveaggressive_regression_best_estimator = passiveaggressive_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\npassiveaggressive_regression_search_results = pd.DataFrame(passiveaggressive_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\npassiveaggressive_regression_predictions = pd.DataFrame(passiveaggressive_regression_best_estimator.predict(X_test))\\npassiveaggressive_regression_r2_score = r2_score(y_test, passiveaggressive_regression_predictions.iloc[:,0])\\npassiveaggressive_regression_mean_squared_error = mean_squared_error(y_test, passiveaggressive_regression_predictions.iloc[:,0])\\npassiveaggressive_regression_explained_variance_score = explained_variance_score(y_test, passiveaggressive_regression_predictions.iloc[:,0])\\npassiveaggressive_regression_performance_metrics = [[\\'passiveaggressive_regression\\',\\'r2_score\\', passiveaggressive_regression_r2_score], \\n                                  [\\'passiveaggressive_regression\\',\\'mean_squared_error\\',passiveaggressive_regression_mean_squared_error],\\n                                  [\\'passiveaggressive_regression\\',\\'explained_variance_score\\', passiveaggressive_regression_explained_variance_score]]\\npassiveaggressive_regression_performance_metrics = pd.DataFrame(passiveaggressive_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\npassiveaggressive_regression_actual_predicted_plot = px.scatter(x=y_test, y=passiveaggressive_regression_predictions.iloc[:,0])\\npassiveaggressive_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\npassiveaggressive_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Passive Aggressive Regression #####\\n\\npassiveaggressive_regression_performance_metrics\\npassiveaggressive_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Passive Aggressive Regression #####'}, 'Gamma Regression': {'code': '\\n\\n##### Model Pipeline for Gamma Regression #####\\n\\nfrom sklearn.linear_model import GammaRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\ngamma_regression_param_grid = {\\n\"gamma_regression__max_iter\": np.arange(10, 100, 10),\\n\"gamma_regression__warm_start\": [False],\\n\"gamma_regression__fit_intercept\": [True],\\n}\\n\\n\\n# Create the pipeline\\ngamma_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'gamma_regression\\', GammaRegressor())\\n])\\n\\n# Create the grid search\\ngamma_regression_grid_search = GridSearchCV(estimator=gamma_regression_pipe, param_grid=gamma_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\ngamma_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\ngamma_regression_best_estimator = gamma_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\ngamma_regression_search_results = pd.DataFrame(gamma_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\ngamma_regression_predictions = pd.DataFrame(gamma_regression_best_estimator.predict(X_test))\\ngamma_regression_r2_score = r2_score(y_test, gamma_regression_predictions.iloc[:,0])\\ngamma_regression_mean_squared_error = mean_squared_error(y_test, gamma_regression_predictions.iloc[:,0])\\ngamma_regression_explained_variance_score = explained_variance_score(y_test, gamma_regression_predictions.iloc[:,0])\\ngamma_regression_performance_metrics = [[\\'gamma_regression\\',\\'r2_score\\', gamma_regression_r2_score], \\n                                  [\\'gamma_regression\\',\\'mean_squared_error\\',gamma_regression_mean_squared_error],\\n                                  [\\'gamma_regression\\',\\'explained_variance_score\\', gamma_regression_explained_variance_score]]\\ngamma_regression_performance_metrics = pd.DataFrame(gamma_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\ngamma_regression_actual_predicted_plot = px.scatter(x=y_test, y=gamma_regression_predictions.iloc[:,0])\\ngamma_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\ngamma_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Gamma Regression #####\\n\\ngamma_regression_performance_metrics\\ngamma_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Gamma Regression #####'}, 'Tweedie Regression': {'code': '\\n\\n##### Model Pipeline for Tweedie Regression #####\\n\\nfrom sklearn.linear_model import TweedieRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\ntweedie_regression_param_grid = {\\n\"tweedie_regression__max_iter\": np.arange(10, 100, 10),\\n\"tweedie_regression__power\": np.arange(0, 3, 1),\\n\"tweedie_regression__warm_start\": [False],\\n\"tweedie_regression__fit_intercept\": [True],\\n}\\n\\n\\n# Create the pipeline\\ntweedie_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'tweedie_regression\\', TweedieRegressor())\\n])\\n\\n# Create the grid search\\ntweedie_regression_grid_search = GridSearchCV(estimator=tweedie_regression_pipe, param_grid=tweedie_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\ntweedie_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\ntweedie_regression_best_estimator = tweedie_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\ntweedie_regression_search_results = pd.DataFrame(tweedie_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\ntweedie_regression_predictions = pd.DataFrame(tweedie_regression_best_estimator.predict(X_test))\\ntweedie_regression_r2_score = r2_score(y_test, tweedie_regression_predictions.iloc[:,0])\\ntweedie_regression_mean_squared_error = mean_squared_error(y_test, tweedie_regression_predictions.iloc[:,0])\\ntweedie_regression_explained_variance_score = explained_variance_score(y_test, tweedie_regression_predictions.iloc[:,0])\\ntweedie_regression_performance_metrics = [[\\'tweedie_regression\\',\\'r2_score\\', tweedie_regression_r2_score], \\n                                  [\\'tweedie_regression\\',\\'mean_squared_error\\',tweedie_regression_mean_squared_error],\\n                                  [\\'tweedie_regression\\',\\'explained_variance_score\\', tweedie_regression_explained_variance_score]]\\ntweedie_regression_performance_metrics = pd.DataFrame(tweedie_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\ntweedie_regression_actual_predicted_plot = px.scatter(x=y_test, y=tweedie_regression_predictions.iloc[:,0])\\ntweedie_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\ntweedie_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics Tweedie Regression #####\\n\\ntweedie_regression_performance_metrics\\ntweedie_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for Tweedie Regression #####'}, 'OMP Regression': {'code': '\\n\\n##### Model Pipeline for OMP Regression #####\\n\\nfrom sklearn.linear_model import OrthogonalMatchingPursuit \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nomp_regression_param_grid = {\\n\"omp_regression__fit_intercept\": [True],\\n\"omp_regression__normalize\": [False],\\n}\\n\\n\\n# Create the pipeline\\nomp_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'omp_regression\\', OrthogonalMatchingPursuit())\\n])\\n\\n# Create the grid search\\nomp_regression_grid_search = GridSearchCV(estimator=omp_regression_pipe, param_grid=omp_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nomp_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nomp_regression_best_estimator = omp_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nomp_regression_search_results = pd.DataFrame(omp_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nomp_regression_predictions = pd.DataFrame(omp_regression_best_estimator.predict(X_test))\\nomp_regression_r2_score = r2_score(y_test, omp_regression_predictions.iloc[:,0])\\nomp_regression_mean_squared_error = mean_squared_error(y_test, omp_regression_predictions.iloc[:,0])\\nomp_regression_explained_variance_score = explained_variance_score(y_test, omp_regression_predictions.iloc[:,0])\\nomp_regression_performance_metrics = [[\\'omp_regression\\',\\'r2_score\\', omp_regression_r2_score], \\n                                  [\\'omp_regression\\',\\'mean_squared_error\\',omp_regression_mean_squared_error],\\n                                  [\\'omp_regression\\',\\'explained_variance_score\\', omp_regression_explained_variance_score]]\\nomp_regression_performance_metrics = pd.DataFrame(omp_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nomp_regression_actual_predicted_plot = px.scatter(x=y_test, y=omp_regression_predictions.iloc[:,0])\\nomp_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nomp_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics OMP Regression #####\\n\\nomp_regression_performance_metrics\\nomp_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for OMP Regression #####'}, 'LassoLars Regression': {'code': '\\n\\n##### Model Pipeline for LassoLars Regression #####\\n\\nfrom sklearn.linear_model import Lasso\\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nlasso_regression_param_grid = {\\n\"lasso_regression__alpha\": np.arange(10, 100, 10),\\n\"lasso_regression__max_iter\": np.arange(100, 1000, 100),\\n\"lasso_regression__fit_intercept\": [True],\\n\"lasso_regression__precompute\": [False],\\n\"lasso_regression__positive\": [True],\\n\"lasso_regression__selection\": [\\'cyclic\\'],\\n}\\n\\n\\n# Create the pipeline\\nlasso_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'lasso_regression\\', Lasso())\\n])\\n\\n# Create the grid search\\nlasso_regression_grid_search = GridSearchCV(estimator=lasso_regression_pipe, param_grid=lasso_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nlasso_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nlasso_regression_best_estimator = lasso_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nlasso_regression_search_results = pd.DataFrame(lasso_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nlasso_regression_predictions = pd.DataFrame(lasso_regression_best_estimator.predict(X_test))\\nlasso_regression_r2_score = r2_score(y_test, lasso_regression_predictions.iloc[:,0])\\nlasso_regression_mean_squared_error = mean_squared_error(y_test, lasso_regression_predictions.iloc[:,0])\\nlasso_regression_explained_variance_score = explained_variance_score(y_test, lasso_regression_predictions.iloc[:,0])\\nlasso_regression_performance_metrics = [[\\'lasso_regression\\',\\'r2_score\\', lasso_regression_r2_score], \\n                                  [\\'lasso_regression\\',\\'mean_squared_error\\',lasso_regression_mean_squared_error],\\n                                  [\\'lasso_regression\\',\\'explained_variance_score\\', lasso_regression_explained_variance_score]]\\nlasso_regression_performance_metrics = pd.DataFrame(lasso_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nlasso_regression_actual_predicted_plot = px.scatter(x=y_test, y=lasso_regression_predictions.iloc[:,0])\\nlasso_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nlasso_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics LassoLars Regression #####\\n\\nlasso_regression_performance_metrics\\nlasso_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for LassoLars Regression #####'}, 'RANSAC Regression': {'code': '\\n\\n##### Model Pipeline for RANSAC Regression #####\\n\\nfrom sklearn.linear_model import RANSACRegressor \\nfrom sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nransac_regression_param_grid = {\\n\"ransac_regression__max_trials\": np.arange(10, 100, 10),\\n}\\n\\n\\n# Create the pipeline\\nransac_regression_pipe = Pipeline([\\n    (\\'preprocessor\\', preprocessor),\\n    (\\'ransac_regression\\', RANSACRegressor())\\n])\\n\\n# Create the grid search\\nransac_regression_grid_search = GridSearchCV(estimator=ransac_regression_pipe, param_grid=ransac_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\\nransac_regression_grid_search.fit(X_train, y_train)\\n\\n# Get the best hyperparameters\\nransac_regression_best_estimator = ransac_regression_grid_search.best_estimator_\\n\\n# Store results as a dataframe  \\nransac_regression_search_results = pd.DataFrame(ransac_regression_grid_search.cv_results_)\\n\\n# Model metrics\\n\\nransac_regression_predictions = pd.DataFrame(ransac_regression_best_estimator.predict(X_test))\\nransac_regression_r2_score = r2_score(y_test, ransac_regression_predictions.iloc[:,0])\\nransac_regression_mean_squared_error = mean_squared_error(y_test, ransac_regression_predictions.iloc[:,0])\\nransac_regression_explained_variance_score = explained_variance_score(y_test, ransac_regression_predictions.iloc[:,0])\\nransac_regression_performance_metrics = [[\\'ransac_regression\\',\\'r2_score\\', ransac_regression_r2_score], \\n                                  [\\'ransac_regression\\',\\'mean_squared_error\\',ransac_regression_mean_squared_error],\\n                                  [\\'ransac_regression\\',\\'explained_variance_score\\', ransac_regression_explained_variance_score]]\\nransac_regression_performance_metrics = pd.DataFrame(ransac_regression_performance_metrics, columns=[\\'model\\',\\'metric\\', \\'value\\'])\\nransac_regression_actual_predicted_plot = px.scatter(x=y_test, y=ransac_regression_predictions.iloc[:,0])\\nransac_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash=\\'dash\\'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\\nransac_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\\n\\n\\n##### Model Metrics RANSAC Regression #####\\n\\nransac_regression_performance_metrics\\nransac_regression_actual_predicted_plot.show()\\n\\n##### End of Model Pipeline for RANSAC Regression #####'}}\n"
     ]
    }
   ],
   "source": [
    "skl_pypelines.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Elastic Net': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.5},\n",
       "   {'checked': True, 'name': 'l1_ratio', 'min': 0.0, 'max': 1.0, 'step': 0.1},\n",
       "   {'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 500,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'precompute',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'selection',\n",
       "    'selected': ['cyclic'],\n",
       "    'values': ['cyclic', 'random']}]},\n",
       " 'Linear Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_jobs',\n",
       "    'min': 1,\n",
       "    'max': 10,\n",
       "    'step': 1}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': False,\n",
       "    'name': 'normalize',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Lasso': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 100,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'precompute',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'positive',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'selection',\n",
       "    'selected': ['cyclic'],\n",
       "    'values': ['cyclic', 'random']}]},\n",
       " 'Ridge': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 100,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'positive',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'SGD Regressor Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.5},\n",
       "   {'checked': True, 'name': 'l1_ratio', 'min': 0.0, 'max': 1.0, 'step': 0.1},\n",
       "   {'checked': True, 'name': 'max_iter', 'min': 500, 'max': 1000, 'step': 500},\n",
       "   {'checked': True,\n",
       "    'name': 'epsilon',\n",
       "    'min': 0.001,\n",
       "    'max': 0.1,\n",
       "    'step': 0.05}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'early_stopping',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'shuffle',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Histogram Gradient Boost Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 5},\n",
       "   {'checked': True, 'name': 'max_leaf_nodes', 'min': 2, 'max': 31, 'step': 6},\n",
       "   {'checked': True,\n",
       "    'name': 'min_samples_leaf',\n",
       "    'min': 2,\n",
       "    'max': 20,\n",
       "    'step': 5},\n",
       "   {'checked': True, 'name': 'max_bins', 'min': 25, 'max': 255, 'step': 25}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'early_stopping',\n",
       "    'selected': [False],\n",
       "    'values': ['auto', True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'Random Forest Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 5}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'bootstrap',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'AdaBoost Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 50,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'loss',\n",
       "    'selected': ['linear'],\n",
       "    'values': ['linear', 'square', 'exponential']}]},\n",
       " 'Poisson Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.005},\n",
       "   {'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 100,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'solver',\n",
       "    'selected': ['lbfgs'],\n",
       "    'values': ['lbfgs', 'newton-cholesky']},\n",
       "   {'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Decision Tree Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'max_depth',\n",
       "    'min': 1,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'max_features',\n",
       "    'selected': [None],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'checked': True,\n",
       "    'name': 'splitter',\n",
       "    'selected': ['best'],\n",
       "    'values': ['best', 'random']}]},\n",
       " 'GBT Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_estimators',\n",
       "    'min': 1,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'checked': True, 'name': 'max_depth', 'min': 1, 'max': 3, 'step': 1},\n",
       "   {'checked': True, 'name': 'alpha', 'min': 0.1, 'max': 1, 'step': 0.5}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'max_features',\n",
       "    'selected': [None],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'ExtraTree Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'max_features',\n",
       "    'selected': [None],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'bootstrap',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'GPR Regression': {'categorical': [{'checked': True,\n",
       "    'name': 'optimizer',\n",
       "    'selected': [None],\n",
       "    'values': [None, 'fmin_l_bfgs_b']},\n",
       "   {'checked': True,\n",
       "    'name': 'normalize_y',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'copy_X_train',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Bayesian ARD Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_iter',\n",
       "    'min': 10,\n",
       "    'max': 300,\n",
       "    'step': 50}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'compute_score',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'copy_X',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Bayesian Ridge Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_iter',\n",
       "    'min': 10,\n",
       "    'max': 300,\n",
       "    'step': 50}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'compute_score',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'copy_X',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Quantile Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'quantile',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.5},\n",
       "   {'checked': True, 'name': 'alpha', 'min': 0.1, 'max': 1, 'step': 0.5}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'solver',\n",
       "    'selected': ['interior-point'],\n",
       "    'values': ['highs-ds',\n",
       "     'highs-ipm',\n",
       "     'highs',\n",
       "     'interior-point',\n",
       "     'revised simplex']}]},\n",
       " 'Huber Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'TheilSen Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 300,\n",
       "    'step': 50}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'copy_X',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Passive Aggressive Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'C',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.5},\n",
       "   {'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 100,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'early_stopping',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'early_stopping',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'Gamma Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Tweedie Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'checked': True, 'name': 'power', 'min': 0, 'max': 3, 'step': 1}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'OMP Regression': {'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'normalize',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'LassoLars Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'checked': True,\n",
       "    'name': 'max_iter',\n",
       "    'min': 100,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'precompute',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'positive',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': True,\n",
       "    'name': 'selection',\n",
       "    'selected': ['cyclic'],\n",
       "    'values': ['cyclic', 'random']}]},\n",
       " 'RANSAC Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'max_trials',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10}]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_pypelines.grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
