{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypelines.supervised_pipeline as pipe\n",
    "from pypelines import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Decision Tree',\n",
       " 'Logistic Regression',\n",
       " 'Random Forest',\n",
       " 'SVC',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'Ridge Classifier',\n",
       " 'HistGBT Classifier',\n",
       " 'Perceptron Classifier',\n",
       " 'SGD Classifier',\n",
       " 'GBT Classifier',\n",
       " 'ADABoost Classifier',\n",
       " 'ExtraTrees Classifier',\n",
       " 'PassiveAggressive Classifier',\n",
       " 'LDA Classifier',\n",
       " 'QDA Classifier',\n",
       " 'NuSVC Classifier',\n",
       " 'GaussianNB Classifier',\n",
       " 'MultinomialNB Classifier',\n",
       " 'ComplementNB Classifier',\n",
       " 'BernoulliNB Classifier',\n",
       " 'CategoricalNB Classifier']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.list_supported_models(model_type='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic = pd.read_csv(\"pypelines/datasets/classification/titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression - all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code output\n",
    "reg_pypelines_all = pipe.SupervisedPipeline(data = titanic,target = 'Survived'\n",
    "                            , model_type = 'regression'\n",
    "#                            , models = ['Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Elastic Net Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 2,\n",
       "    'step': 0.5},\n",
       "   {'checked': True, 'name': 'l1_ratio', 'min': 0.0, 'max': 1.0, 'step': 0.3},\n",
       "   {'checked': False,\n",
       "    'name': 'max_iter',\n",
       "    'min': 500,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': False,\n",
       "    'name': 'selection',\n",
       "    'selected': ['cyclic'],\n",
       "    'values': ['cyclic', 'random']}]},\n",
       " 'Linear Regression': {'numerical': [],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Lasso Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 2,\n",
       "    'step': 0.5},\n",
       "   {'checked': False,\n",
       "    'name': 'max_iter',\n",
       "    'min': 100,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Ridge Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 2,\n",
       "    'step': 0.5},\n",
       "   {'checked': False,\n",
       "    'name': 'max_iter',\n",
       "    'min': 100,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': False,\n",
       "    'name': 'positive',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'SGD Regressor Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0.0001,\n",
       "    'max': 2,\n",
       "    'step': 0.5},\n",
       "   {'checked': True, 'name': 'l1_ratio', 'min': 0.0, 'max': 1.0, 'step': 0.5},\n",
       "   {'checked': False,\n",
       "    'name': 'max_iter',\n",
       "    'min': 500,\n",
       "    'max': 1000,\n",
       "    'step': 500},\n",
       "   {'checked': False,\n",
       "    'name': 'epsilon',\n",
       "    'min': 0.001,\n",
       "    'max': 0.1,\n",
       "    'step': 0.05},\n",
       "   {'checked': False,\n",
       "    'name': 'power_t',\n",
       "    'min': 0.01,\n",
       "    'max': 0.1,\n",
       "    'step': 0.04}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'penalty',\n",
       "    'selected': ['l2'],\n",
       "    'values': ['l2', 'l1', 'elasticnet']},\n",
       "   {'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': False,\n",
       "    'name': 'early_stopping',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': False,\n",
       "    'name': 'learning_rate',\n",
       "    'selected': ['invscaling'],\n",
       "    'values': ['invscaling', 'constant', 'optimal', 'adaptive']},\n",
       "   {'checked': False,\n",
       "    'name': 'shuffle',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Histogram Gradient Boost Regression': {'numerical': [{'checked': False,\n",
       "    'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 5},\n",
       "   {'checked': True,\n",
       "    'name': 'max_leaf_nodes',\n",
       "    'min': 2,\n",
       "    'max': 100,\n",
       "    'step': 35},\n",
       "   {'checked': True,\n",
       "    'name': 'min_samples_leaf',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 40},\n",
       "   {'checked': False, 'name': 'max_depth', 'min': 1, 'max': 10, 'step': 3},\n",
       "   {'checked': False,\n",
       "    'name': 'l2_regularization',\n",
       "    'min': 0,\n",
       "    'max': 2,\n",
       "    'step': 0.5},\n",
       "   {'checked': True, 'name': 'max_bins', 'min': 25, 'max': 255, 'step': 100},\n",
       "   {'checked': False,\n",
       "    'name': 'learning_rate',\n",
       "    'min': 0.1,\n",
       "    'max': 0.5,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'early_stopping',\n",
       "    'selected': [True],\n",
       "    'values': ['auto', True, False]}]},\n",
       " 'Random Forest Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_estimators',\n",
       "    'min': 50,\n",
       "    'max': 150,\n",
       "    'step': 35},\n",
       "   {'checked': True, 'name': 'max_depth', 'min': 5, 'max': 50, 'step': 10},\n",
       "   {'checked': True,\n",
       "    'name': 'min_samples_leaf',\n",
       "    'min': 1,\n",
       "    'max': 50,\n",
       "    'step': 20}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'bootstrap',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'AdaBoost Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 20}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'loss',\n",
       "    'selected': ['linear'],\n",
       "    'values': ['linear', 'square', 'exponential']}]},\n",
       " 'Poisson Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 2,\n",
       "    'step': 0.5},\n",
       "   {'checked': False,\n",
       "    'name': 'max_iter',\n",
       "    'min': 100,\n",
       "    'max': 1000,\n",
       "    'step': 100}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Decision Tree Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'max_depth',\n",
       "    'min': 1,\n",
       "    'max': 10,\n",
       "    'step': 3},\n",
       "   {'checked': False,\n",
       "    'name': 'min_samples_split',\n",
       "    'min': 0.1,\n",
       "    'max': 0.5,\n",
       "    'step': 0.2},\n",
       "   {'checked': False,\n",
       "    'name': 'min_samples_leaf',\n",
       "    'min': 2,\n",
       "    'max': 10,\n",
       "    'step': 3}],\n",
       "  'categorical': [{'checked': True,\n",
       "    'name': 'max_features',\n",
       "    'selected': [None],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'checked': False,\n",
       "    'name': 'splitter',\n",
       "    'selected': ['best'],\n",
       "    'values': ['best', 'random']}]},\n",
       " 'GBT Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_estimators',\n",
       "    'min': 25,\n",
       "    'max': 200,\n",
       "    'step': 50},\n",
       "   {'checked': True, 'name': 'max_depth', 'min': 1, 'max': 10, 'step': 3},\n",
       "   {'checked': True, 'name': 'alpha', 'min': 0.1, 'max': 2, 'step': 0.5},\n",
       "   {'checked': False,\n",
       "    'name': 'min_samples_split',\n",
       "    'min': 2,\n",
       "    'max': 200,\n",
       "    'step': 50},\n",
       "   {'checked': False,\n",
       "    'name': 'min_samples_leaf',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.5}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'max_features',\n",
       "    'selected': [None],\n",
       "    'values': ['auto', 'sqrt', 'log2']}]},\n",
       " 'ExtraTree Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 200,\n",
       "    'step': 50},\n",
       "   {'checked': True, 'name': 'max_depth', 'min': 10, 'max': 200, 'step': 50},\n",
       "   {'checked': False,\n",
       "    'name': 'min_samples_split',\n",
       "    'min': 2,\n",
       "    'max': 200,\n",
       "    'step': 50},\n",
       "   {'checked': False,\n",
       "    'name': 'min_samples_leaf',\n",
       "    'min': 0.1,\n",
       "    'max': 0.5,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'max_features',\n",
       "    'selected': [None],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'checked': False,\n",
       "    'name': 'bootstrap',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'GPR Regression': {'numerical': [],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'optimizer',\n",
       "    'selected': [None],\n",
       "    'values': [None, 'fmin_l_bfgs_b']},\n",
       "   {'checked': False,\n",
       "    'name': 'normalize_y',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'Bayesian ARD Regression': {'numerical': [{'checked': False,\n",
       "    'name': 'n_iter',\n",
       "    'min': 10,\n",
       "    'max': 300,\n",
       "    'step': 50}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': False,\n",
       "    'name': 'compute_score',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'Bayesian Ridge Regression': {'numerical': [{'checked': False,\n",
       "    'name': 'n_iter',\n",
       "    'min': 10,\n",
       "    'max': 300,\n",
       "    'step': 50},\n",
       "   {'checked': False,\n",
       "    'name': 'alpha_1',\n",
       "    'min': 1e-06,\n",
       "    'max': 0.1,\n",
       "    'step': 0.005},\n",
       "   {'checked': False,\n",
       "    'name': 'alpha_2',\n",
       "    'min': 1e-06,\n",
       "    'max': 0.1,\n",
       "    'step': 0.005},\n",
       "   {'checked': False,\n",
       "    'name': 'lambda_1',\n",
       "    'min': 1e-06,\n",
       "    'max': 0.1,\n",
       "    'step': 0.005},\n",
       "   {'checked': False,\n",
       "    'name': 'lambda_2',\n",
       "    'min': 1e-06,\n",
       "    'max': 0.1,\n",
       "    'step': 0.005}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': False,\n",
       "    'name': 'compute_score',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'Quantile Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 2,\n",
       "    'step': 0.5}],\n",
       "  'categorical': []},\n",
       " 'Huber Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'epsilon',\n",
       "    'min': 1,\n",
       "    'max': 10,\n",
       "    'step': 2},\n",
       "   {'checked': True, 'name': 'alpha', 'min': 0, 'max': 3, 'step': 0.5}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'TheilSen Regression': {'numerical': [{'checked': False,\n",
       "    'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 300,\n",
       "    'step': 50},\n",
       "   {'checked': False,\n",
       "    'name': 'max_subpopulation',\n",
       "    'min': 5000,\n",
       "    'max': 20000,\n",
       "    'step': 5000},\n",
       "   {'checked': False,\n",
       "    'name': 'n_subsamples',\n",
       "    'min': 100,\n",
       "    'max': 200,\n",
       "    'step': 50}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Passive Aggressive Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'C',\n",
       "    'min': 0,\n",
       "    'max': 2,\n",
       "    'step': 0.5}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'early_stopping',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': False,\n",
       "    'name': 'shuffle',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Gamma Regression': {'numerical': [{'checked': False,\n",
       "    'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'checked': True, 'name': 'alpha', 'min': 0, 'max': 2, 'step': 1}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Tweedie Regression': {'numerical': [{'checked': False,\n",
       "    'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'checked': True, 'name': 'power', 'min': 0, 'max': 3, 'step': 1},\n",
       "   {'checked': True, 'name': 'alpha', 'min': 0, 'max': 5, 'step': 1}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'link',\n",
       "    'selected': [False],\n",
       "    'values': ['auto', 'log', 'identity']},\n",
       "   {'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'OMP Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'n_nonzero_coefs',\n",
       "    'min': 0,\n",
       "    'max': 10,\n",
       "    'step': 2}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'checked': False,\n",
       "    'name': 'normalize',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]}]},\n",
       " 'LassoLars Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 2,\n",
       "    'step': 0.5},\n",
       "   {'checked': False, 'name': 'max_iter', 'min': 10, 'max': 500, 'step': 50}],\n",
       "  'categorical': [{'checked': False,\n",
       "    'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'RANSAC Regression': {'numerical': [{'checked': True,\n",
       "    'name': 'max_trials',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': []}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pypelines_all.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elastic Net Regression', 'Linear Regression', 'Lasso Regression', 'Ridge Regression', 'SGD Regressor Regression', 'Histogram Gradient Boost Regression', 'Random Forest Regression', 'AdaBoost Regression', 'Poisson Regression', 'Decision Tree Regression', 'GBT Regression', 'ExtraTree Regression', 'GPR Regression', 'Bayesian ARD Regression', 'Bayesian Ridge Regression', 'Quantile Regression', 'Huber Regression', 'TheilSen Regression', 'Passive Aggressive Regression', 'Gamma Regression', 'Tweedie Regression', 'OMP Regression', 'LassoLars Regression', 'RANSAC Regression']\n"
     ]
    }
   ],
   "source": [
    "reg_pypelines_all.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality and make it text column\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        text_cols.append(col)\n",
      "        categorical_cols.remove(col)\n",
      "        \n",
      "\n",
      "# check text columns for low cardinality and make it categorical columns\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "print(numerical_cols)\n",
      "print(categorical_cols)\n",
      "print(text_cols)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "        transformers=[('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        *[(f'text_{t_col}', text_transformer, t_col) for t_col in text_cols]]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Elastic Net Regression #####\n",
      "\n",
      "from sklearn.linear_model import ElasticNet\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "elastic_net_regression_param_grid = {\n",
      "\"elastic_net_regression__alpha\": np.arange(0.1, 2.0, 0.5),\n",
      "\"elastic_net_regression__l1_ratio\": np.arange(0.0, 1.0, 0.3),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "elastic_net_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('elastic_net_regression', ElasticNet())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "elastic_net_regression_grid_search = GridSearchCV(estimator=elastic_net_regression_pipe, param_grid=elastic_net_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "elastic_net_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "elastic_net_regression_best_estimator = elastic_net_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "elastic_net_regression_search_results = pd.DataFrame(elastic_net_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "elastic_net_regression_predictions = pd.DataFrame(elastic_net_regression_best_estimator.predict(X_test))\n",
      "elastic_net_regression_r2_score = r2_score(y_test, elastic_net_regression_predictions.iloc[:,0])\n",
      "elastic_net_regression_mean_squared_error = mean_squared_error(y_test, elastic_net_regression_predictions.iloc[:,0])\n",
      "elastic_net_regression_explained_variance_score = explained_variance_score(y_test, elastic_net_regression_predictions.iloc[:,0])\n",
      "elastic_net_regression_performance_metrics = [['elastic_net_regression','r2_score', elastic_net_regression_r2_score], \n",
      "                                  ['elastic_net_regression','mean_squared_error',elastic_net_regression_mean_squared_error],\n",
      "                                  ['elastic_net_regression','explained_variance_score', elastic_net_regression_explained_variance_score]]\n",
      "elastic_net_regression_performance_metrics = pd.DataFrame(elastic_net_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "elastic_net_regression_actual_predicted_plot = px.scatter(x=y_test, y=elastic_net_regression_predictions.iloc[:,0])\n",
      "elastic_net_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "elastic_net_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Elastic Net Regression #####\n",
      "\n",
      "elastic_net_regression_performance_metrics\n",
      "elastic_net_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Elastic Net Regression #####\n",
      "\n",
      "##### Model Pipeline for Linear Regression #####\n",
      "\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "lin_reg_param_grid = {\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "lin_reg_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('lin_reg', LinearRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "lin_reg_grid_search = GridSearchCV(estimator=lin_reg_pipe, param_grid=lin_reg_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "lin_reg_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "lin_reg_best_estimator = lin_reg_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "lin_reg_search_results = pd.DataFrame(lin_reg_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "lin_reg_predictions = pd.DataFrame(lin_reg_best_estimator.predict(X_test))\n",
      "lin_reg_r2_score = r2_score(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_mean_squared_error = mean_squared_error(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_explained_variance_score = explained_variance_score(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_performance_metrics = [['lin_reg','r2_score', lin_reg_r2_score], \n",
      "                                  ['lin_reg','mean_squared_error',lin_reg_mean_squared_error],\n",
      "                                  ['lin_reg','explained_variance_score', lin_reg_explained_variance_score]]\n",
      "lin_reg_performance_metrics = pd.DataFrame(lin_reg_performance_metrics, columns=['model','metric', 'value'])\n",
      "lin_reg_actual_predicted_plot = px.scatter(x=y_test, y=lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "lin_reg_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Linear Regression #####\n",
      "\n",
      "lin_reg_performance_metrics\n",
      "lin_reg_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Linear Regression #####\n",
      "\n",
      "##### Model Pipeline for Lasso Regression #####\n",
      "\n",
      "from sklearn.linear_model import Lasso\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "lasso_regression_param_grid = {\n",
      "\"lasso_regression__alpha\": np.arange(0.0, 2.0, 0.5),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "lasso_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('lasso_regression', Lasso())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "lasso_regression_grid_search = GridSearchCV(estimator=lasso_regression_pipe, param_grid=lasso_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "lasso_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "lasso_regression_best_estimator = lasso_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "lasso_regression_search_results = pd.DataFrame(lasso_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "lasso_regression_predictions = pd.DataFrame(lasso_regression_best_estimator.predict(X_test))\n",
      "lasso_regression_r2_score = r2_score(y_test, lasso_regression_predictions.iloc[:,0])\n",
      "lasso_regression_mean_squared_error = mean_squared_error(y_test, lasso_regression_predictions.iloc[:,0])\n",
      "lasso_regression_explained_variance_score = explained_variance_score(y_test, lasso_regression_predictions.iloc[:,0])\n",
      "lasso_regression_performance_metrics = [['lasso_regression','r2_score', lasso_regression_r2_score], \n",
      "                                  ['lasso_regression','mean_squared_error',lasso_regression_mean_squared_error],\n",
      "                                  ['lasso_regression','explained_variance_score', lasso_regression_explained_variance_score]]\n",
      "lasso_regression_performance_metrics = pd.DataFrame(lasso_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "lasso_regression_actual_predicted_plot = px.scatter(x=y_test, y=lasso_regression_predictions.iloc[:,0])\n",
      "lasso_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "lasso_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Lasso Regression #####\n",
      "\n",
      "lasso_regression_performance_metrics\n",
      "lasso_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Lasso Regression #####\n",
      "\n",
      "##### Model Pipeline for Ridge Regression #####\n",
      "\n",
      "from sklearn.linear_model import Ridge \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "ridge_regression_param_grid = {\n",
      "\"ridge_regression__alpha\": np.arange(0.1, 2.0, 0.5),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "ridge_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('ridge_regression', Ridge())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "ridge_regression_grid_search = GridSearchCV(estimator=ridge_regression_pipe, param_grid=ridge_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "ridge_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "ridge_regression_best_estimator = ridge_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "ridge_regression_search_results = pd.DataFrame(ridge_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "ridge_regression_predictions = pd.DataFrame(ridge_regression_best_estimator.predict(X_test))\n",
      "ridge_regression_r2_score = r2_score(y_test, ridge_regression_predictions.iloc[:,0])\n",
      "ridge_regression_mean_squared_error = mean_squared_error(y_test, ridge_regression_predictions.iloc[:,0])\n",
      "ridge_regression_explained_variance_score = explained_variance_score(y_test, ridge_regression_predictions.iloc[:,0])\n",
      "ridge_regression_performance_metrics = [['ridge_regression','r2_score', ridge_regression_r2_score], \n",
      "                                  ['ridge_regression','mean_squared_error',ridge_regression_mean_squared_error],\n",
      "                                  ['ridge_regression','explained_variance_score', ridge_regression_explained_variance_score]]\n",
      "ridge_regression_performance_metrics = pd.DataFrame(ridge_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "ridge_regression_actual_predicted_plot = px.scatter(x=y_test, y=ridge_regression_predictions.iloc[:,0])\n",
      "ridge_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "ridge_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Ridge Regression #####\n",
      "\n",
      "ridge_regression_performance_metrics\n",
      "ridge_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Ridge Regression #####\n",
      "\n",
      "##### Model Pipeline for SGD Regressor Regression #####\n",
      "\n",
      "from sklearn.linear_model import SGDRegressor\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "sgd_regressor_regression_param_grid = {\n",
      "\"sgd_regressor_regression__alpha\": np.arange(0.0001, 2.0, 0.5),\n",
      "\"sgd_regressor_regression__l1_ratio\": np.arange(0.0, 1.0, 0.5),\n",
      "\"sgd_regressor_regression__penalty\": ['l2'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "sgd_regressor_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('sgd_regressor_regression', SGDRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "sgd_regressor_regression_grid_search = GridSearchCV(estimator=sgd_regressor_regression_pipe, param_grid=sgd_regressor_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "sgd_regressor_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "sgd_regressor_regression_best_estimator = sgd_regressor_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "sgd_regressor_regression_search_results = pd.DataFrame(sgd_regressor_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "sgd_regressor_regression_predictions = pd.DataFrame(sgd_regressor_regression_best_estimator.predict(X_test))\n",
      "sgd_regressor_regression_r2_score = r2_score(y_test, sgd_regressor_regression_predictions.iloc[:,0])\n",
      "sgd_regressor_regression_mean_squared_error = mean_squared_error(y_test, sgd_regressor_regression_predictions.iloc[:,0])\n",
      "sgd_regressor_regression_explained_variance_score = explained_variance_score(y_test, sgd_regressor_regression_predictions.iloc[:,0])\n",
      "sgd_regressor_regression_performance_metrics = [['sgd_regressor_regression','r2_score', sgd_regressor_regression_r2_score], \n",
      "                                  ['sgd_regressor_regression','mean_squared_error',sgd_regressor_regression_mean_squared_error],\n",
      "                                  ['sgd_regressor_regression','explained_variance_score', sgd_regressor_regression_explained_variance_score]]\n",
      "sgd_regressor_regression_performance_metrics = pd.DataFrame(sgd_regressor_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "sgd_regressor_regression_actual_predicted_plot = px.scatter(x=y_test, y=sgd_regressor_regression_predictions.iloc[:,0])\n",
      "sgd_regressor_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "sgd_regressor_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics SGD Regressor Regression #####\n",
      "\n",
      "sgd_regressor_regression_performance_metrics\n",
      "sgd_regressor_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for SGD Regressor Regression #####\n",
      "\n",
      "##### Model Pipeline for Histogram Gradient Boost Regression #####\n",
      "\n",
      "from sklearn.ensemble import HistGradientBoostingRegressor\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "hist_gbt_regression_param_grid = {\n",
      "\"hist_gbt_regression__max_leaf_nodes\": np.arange(2, 100, 35),\n",
      "\"hist_gbt_regression__min_samples_leaf\": np.arange(10, 100, 40),\n",
      "\"hist_gbt_regression__max_bins\": np.arange(25, 255, 100),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "hist_gbt_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('hist_gbt_regression', HistGradientBoostingRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "hist_gbt_regression_grid_search = GridSearchCV(estimator=hist_gbt_regression_pipe, param_grid=hist_gbt_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "hist_gbt_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "hist_gbt_regression_best_estimator = hist_gbt_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "hist_gbt_regression_search_results = pd.DataFrame(hist_gbt_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "hist_gbt_regression_predictions = pd.DataFrame(hist_gbt_regression_best_estimator.predict(X_test))\n",
      "hist_gbt_regression_r2_score = r2_score(y_test, hist_gbt_regression_predictions.iloc[:,0])\n",
      "hist_gbt_regression_mean_squared_error = mean_squared_error(y_test, hist_gbt_regression_predictions.iloc[:,0])\n",
      "hist_gbt_regression_explained_variance_score = explained_variance_score(y_test, hist_gbt_regression_predictions.iloc[:,0])\n",
      "hist_gbt_regression_performance_metrics = [['hist_gbt_regression','r2_score', hist_gbt_regression_r2_score], \n",
      "                                  ['hist_gbt_regression','mean_squared_error',hist_gbt_regression_mean_squared_error],\n",
      "                                  ['hist_gbt_regression','explained_variance_score', hist_gbt_regression_explained_variance_score]]\n",
      "hist_gbt_regression_performance_metrics = pd.DataFrame(hist_gbt_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "hist_gbt_regression_actual_predicted_plot = px.scatter(x=y_test, y=hist_gbt_regression_predictions.iloc[:,0])\n",
      "hist_gbt_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "hist_gbt_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Histogram Gradient Boost Regression #####\n",
      "\n",
      "hist_gbt_regression_performance_metrics\n",
      "hist_gbt_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Histogram Gradient Boost Regression #####\n",
      "\n",
      "##### Model Pipeline for Random Forest Regression #####\n",
      "\n",
      "from sklearn.ensemble import RandomForestRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "random_forest_regression_param_grid = {\n",
      "\"random_forest_regression__n_estimators\": np.arange(50, 150, 35),\n",
      "\"random_forest_regression__max_depth\": np.arange(5, 50, 10),\n",
      "\"random_forest_regression__min_samples_leaf\": np.arange(1, 50, 20),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "random_forest_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('random_forest_regression', RandomForestRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "random_forest_regression_grid_search = GridSearchCV(estimator=random_forest_regression_pipe, param_grid=random_forest_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "random_forest_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "random_forest_regression_best_estimator = random_forest_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "random_forest_regression_search_results = pd.DataFrame(random_forest_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "random_forest_regression_predictions = pd.DataFrame(random_forest_regression_best_estimator.predict(X_test))\n",
      "random_forest_regression_r2_score = r2_score(y_test, random_forest_regression_predictions.iloc[:,0])\n",
      "random_forest_regression_mean_squared_error = mean_squared_error(y_test, random_forest_regression_predictions.iloc[:,0])\n",
      "random_forest_regression_explained_variance_score = explained_variance_score(y_test, random_forest_regression_predictions.iloc[:,0])\n",
      "random_forest_regression_performance_metrics = [['random_forest_regression','r2_score', random_forest_regression_r2_score], \n",
      "                                  ['random_forest_regression','mean_squared_error',random_forest_regression_mean_squared_error],\n",
      "                                  ['random_forest_regression','explained_variance_score', random_forest_regression_explained_variance_score]]\n",
      "random_forest_regression_performance_metrics = pd.DataFrame(random_forest_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "random_forest_regression_actual_predicted_plot = px.scatter(x=y_test, y=random_forest_regression_predictions.iloc[:,0])\n",
      "random_forest_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "random_forest_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Random Forest Regression #####\n",
      "\n",
      "random_forest_regression_performance_metrics\n",
      "random_forest_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Random Forest Regression #####\n",
      "\n",
      "##### Model Pipeline for AdaBoost Regression #####\n",
      "\n",
      "from sklearn.ensemble import AdaBoostRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "adaboost_regression_param_grid = {\n",
      "\"adaboost_regression__n_estimators\": np.arange(10, 100, 20),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "adaboost_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('adaboost_regression', AdaBoostRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "adaboost_regression_grid_search = GridSearchCV(estimator=adaboost_regression_pipe, param_grid=adaboost_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "adaboost_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "adaboost_regression_best_estimator = adaboost_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "adaboost_regression_search_results = pd.DataFrame(adaboost_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "adaboost_regression_predictions = pd.DataFrame(adaboost_regression_best_estimator.predict(X_test))\n",
      "adaboost_regression_r2_score = r2_score(y_test, adaboost_regression_predictions.iloc[:,0])\n",
      "adaboost_regression_mean_squared_error = mean_squared_error(y_test, adaboost_regression_predictions.iloc[:,0])\n",
      "adaboost_regression_explained_variance_score = explained_variance_score(y_test, adaboost_regression_predictions.iloc[:,0])\n",
      "adaboost_regression_performance_metrics = [['adaboost_regression','r2_score', adaboost_regression_r2_score], \n",
      "                                  ['adaboost_regression','mean_squared_error',adaboost_regression_mean_squared_error],\n",
      "                                  ['adaboost_regression','explained_variance_score', adaboost_regression_explained_variance_score]]\n",
      "adaboost_regression_performance_metrics = pd.DataFrame(adaboost_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "adaboost_regression_actual_predicted_plot = px.scatter(x=y_test, y=adaboost_regression_predictions.iloc[:,0])\n",
      "adaboost_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "adaboost_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics AdaBoost Regression #####\n",
      "\n",
      "adaboost_regression_performance_metrics\n",
      "adaboost_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for AdaBoost Regression #####\n",
      "\n",
      "##### Model Pipeline for Poisson Regression #####\n",
      "\n",
      "from sklearn.linear_model import PoissonRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "poisson_regression_param_grid = {\n",
      "\"poisson_regression__alpha\": np.arange(0.1, 2.0, 0.5),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "poisson_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('poisson_regression', PoissonRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "poisson_regression_grid_search = GridSearchCV(estimator=poisson_regression_pipe, param_grid=poisson_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "poisson_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "poisson_regression_best_estimator = poisson_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "poisson_regression_search_results = pd.DataFrame(poisson_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "poisson_regression_predictions = pd.DataFrame(poisson_regression_best_estimator.predict(X_test))\n",
      "poisson_regression_r2_score = r2_score(y_test, poisson_regression_predictions.iloc[:,0])\n",
      "poisson_regression_mean_squared_error = mean_squared_error(y_test, poisson_regression_predictions.iloc[:,0])\n",
      "poisson_regression_explained_variance_score = explained_variance_score(y_test, poisson_regression_predictions.iloc[:,0])\n",
      "poisson_regression_performance_metrics = [['poisson_regression','r2_score', poisson_regression_r2_score], \n",
      "                                  ['poisson_regression','mean_squared_error',poisson_regression_mean_squared_error],\n",
      "                                  ['poisson_regression','explained_variance_score', poisson_regression_explained_variance_score]]\n",
      "poisson_regression_performance_metrics = pd.DataFrame(poisson_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "poisson_regression_actual_predicted_plot = px.scatter(x=y_test, y=poisson_regression_predictions.iloc[:,0])\n",
      "poisson_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "poisson_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Poisson Regression #####\n",
      "\n",
      "poisson_regression_performance_metrics\n",
      "poisson_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Poisson Regression #####\n",
      "\n",
      "##### Model Pipeline for Decision Tree Regression #####\n",
      "\n",
      "from sklearn.tree import DecisionTreeRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "decision_tree_regression_param_grid = {\n",
      "\"decision_tree_regression__max_depth\": np.arange(1, 10, 3),\n",
      "\"decision_tree_regression__max_features\": [None],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "decision_tree_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('decision_tree_regression', DecisionTreeRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "decision_tree_regression_grid_search = GridSearchCV(estimator=decision_tree_regression_pipe, param_grid=decision_tree_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "decision_tree_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "decision_tree_regression_best_estimator = decision_tree_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "decision_tree_regression_search_results = pd.DataFrame(decision_tree_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "decision_tree_regression_predictions = pd.DataFrame(decision_tree_regression_best_estimator.predict(X_test))\n",
      "decision_tree_regression_r2_score = r2_score(y_test, decision_tree_regression_predictions.iloc[:,0])\n",
      "decision_tree_regression_mean_squared_error = mean_squared_error(y_test, decision_tree_regression_predictions.iloc[:,0])\n",
      "decision_tree_regression_explained_variance_score = explained_variance_score(y_test, decision_tree_regression_predictions.iloc[:,0])\n",
      "decision_tree_regression_performance_metrics = [['decision_tree_regression','r2_score', decision_tree_regression_r2_score], \n",
      "                                  ['decision_tree_regression','mean_squared_error',decision_tree_regression_mean_squared_error],\n",
      "                                  ['decision_tree_regression','explained_variance_score', decision_tree_regression_explained_variance_score]]\n",
      "decision_tree_regression_performance_metrics = pd.DataFrame(decision_tree_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "decision_tree_regression_actual_predicted_plot = px.scatter(x=y_test, y=decision_tree_regression_predictions.iloc[:,0])\n",
      "decision_tree_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "decision_tree_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Decision Tree Regression #####\n",
      "\n",
      "decision_tree_regression_performance_metrics\n",
      "decision_tree_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Decision Tree Regression #####\n",
      "\n",
      "##### Model Pipeline for GBT Regression #####\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "gbt_regression_param_grid = {\n",
      "\"gbt_regression__n_estimators\": np.arange(25, 200, 50),\n",
      "\"gbt_regression__max_depth\": np.arange(1, 10, 3),\n",
      "\"gbt_regression__alpha\": np.arange(0.1, 2.0, 0.5),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gbt_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gbt_regression', GradientBoostingRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gbt_regression_grid_search = GridSearchCV(estimator=gbt_regression_pipe, param_grid=gbt_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "gbt_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gbt_regression_best_estimator = gbt_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gbt_regression_search_results = pd.DataFrame(gbt_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gbt_regression_predictions = pd.DataFrame(gbt_regression_best_estimator.predict(X_test))\n",
      "gbt_regression_r2_score = r2_score(y_test, gbt_regression_predictions.iloc[:,0])\n",
      "gbt_regression_mean_squared_error = mean_squared_error(y_test, gbt_regression_predictions.iloc[:,0])\n",
      "gbt_regression_explained_variance_score = explained_variance_score(y_test, gbt_regression_predictions.iloc[:,0])\n",
      "gbt_regression_performance_metrics = [['gbt_regression','r2_score', gbt_regression_r2_score], \n",
      "                                  ['gbt_regression','mean_squared_error',gbt_regression_mean_squared_error],\n",
      "                                  ['gbt_regression','explained_variance_score', gbt_regression_explained_variance_score]]\n",
      "gbt_regression_performance_metrics = pd.DataFrame(gbt_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "gbt_regression_actual_predicted_plot = px.scatter(x=y_test, y=gbt_regression_predictions.iloc[:,0])\n",
      "gbt_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "gbt_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics GBT Regression #####\n",
      "\n",
      "gbt_regression_performance_metrics\n",
      "gbt_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for GBT Regression #####\n",
      "\n",
      "##### Model Pipeline for ExtraTree Regression #####\n",
      "\n",
      "from sklearn.ensemble import ExtraTreesRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "extra_tree_regression_param_grid = {\n",
      "\"extra_tree_regression__n_estimators\": np.arange(10, 200, 50),\n",
      "\"extra_tree_regression__max_depth\": np.arange(10, 200, 50),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "extra_tree_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('extra_tree_regression', ExtraTreesRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "extra_tree_regression_grid_search = GridSearchCV(estimator=extra_tree_regression_pipe, param_grid=extra_tree_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "extra_tree_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "extra_tree_regression_best_estimator = extra_tree_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "extra_tree_regression_search_results = pd.DataFrame(extra_tree_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "extra_tree_regression_predictions = pd.DataFrame(extra_tree_regression_best_estimator.predict(X_test))\n",
      "extra_tree_regression_r2_score = r2_score(y_test, extra_tree_regression_predictions.iloc[:,0])\n",
      "extra_tree_regression_mean_squared_error = mean_squared_error(y_test, extra_tree_regression_predictions.iloc[:,0])\n",
      "extra_tree_regression_explained_variance_score = explained_variance_score(y_test, extra_tree_regression_predictions.iloc[:,0])\n",
      "extra_tree_regression_performance_metrics = [['extra_tree_regression','r2_score', extra_tree_regression_r2_score], \n",
      "                                  ['extra_tree_regression','mean_squared_error',extra_tree_regression_mean_squared_error],\n",
      "                                  ['extra_tree_regression','explained_variance_score', extra_tree_regression_explained_variance_score]]\n",
      "extra_tree_regression_performance_metrics = pd.DataFrame(extra_tree_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "extra_tree_regression_actual_predicted_plot = px.scatter(x=y_test, y=extra_tree_regression_predictions.iloc[:,0])\n",
      "extra_tree_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "extra_tree_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics ExtraTree Regression #####\n",
      "\n",
      "extra_tree_regression_performance_metrics\n",
      "extra_tree_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for ExtraTree Regression #####\n",
      "\n",
      "##### Model Pipeline for GPR Regression #####\n",
      "\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "gpr_regression_param_grid = {\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gpr_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gpr_regression', GaussianProcessRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gpr_regression_grid_search = GridSearchCV(estimator=gpr_regression_pipe, param_grid=gpr_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "gpr_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gpr_regression_best_estimator = gpr_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gpr_regression_search_results = pd.DataFrame(gpr_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gpr_regression_predictions = pd.DataFrame(gpr_regression_best_estimator.predict(X_test))\n",
      "gpr_regression_r2_score = r2_score(y_test, gpr_regression_predictions.iloc[:,0])\n",
      "gpr_regression_mean_squared_error = mean_squared_error(y_test, gpr_regression_predictions.iloc[:,0])\n",
      "gpr_regression_explained_variance_score = explained_variance_score(y_test, gpr_regression_predictions.iloc[:,0])\n",
      "gpr_regression_performance_metrics = [['gpr_regression','r2_score', gpr_regression_r2_score], \n",
      "                                  ['gpr_regression','mean_squared_error',gpr_regression_mean_squared_error],\n",
      "                                  ['gpr_regression','explained_variance_score', gpr_regression_explained_variance_score]]\n",
      "gpr_regression_performance_metrics = pd.DataFrame(gpr_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "gpr_regression_actual_predicted_plot = px.scatter(x=y_test, y=gpr_regression_predictions.iloc[:,0])\n",
      "gpr_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "gpr_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics GPR Regression #####\n",
      "\n",
      "gpr_regression_performance_metrics\n",
      "gpr_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for GPR Regression #####\n",
      "\n",
      "##### Model Pipeline for Bayesian ARD Regression #####\n",
      "\n",
      "from sklearn.linear_model import ARDRegression \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "bayesian_ard_regression_param_grid = {\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "bayesian_ard_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('bayesian_ard_regression', ARDRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "bayesian_ard_regression_grid_search = GridSearchCV(estimator=bayesian_ard_regression_pipe, param_grid=bayesian_ard_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "bayesian_ard_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "bayesian_ard_regression_best_estimator = bayesian_ard_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "bayesian_ard_regression_search_results = pd.DataFrame(bayesian_ard_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "bayesian_ard_regression_predictions = pd.DataFrame(bayesian_ard_regression_best_estimator.predict(X_test))\n",
      "bayesian_ard_regression_r2_score = r2_score(y_test, bayesian_ard_regression_predictions.iloc[:,0])\n",
      "bayesian_ard_regression_mean_squared_error = mean_squared_error(y_test, bayesian_ard_regression_predictions.iloc[:,0])\n",
      "bayesian_ard_regression_explained_variance_score = explained_variance_score(y_test, bayesian_ard_regression_predictions.iloc[:,0])\n",
      "bayesian_ard_regression_performance_metrics = [['bayesian_ard_regression','r2_score', bayesian_ard_regression_r2_score], \n",
      "                                  ['bayesian_ard_regression','mean_squared_error',bayesian_ard_regression_mean_squared_error],\n",
      "                                  ['bayesian_ard_regression','explained_variance_score', bayesian_ard_regression_explained_variance_score]]\n",
      "bayesian_ard_regression_performance_metrics = pd.DataFrame(bayesian_ard_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "bayesian_ard_regression_actual_predicted_plot = px.scatter(x=y_test, y=bayesian_ard_regression_predictions.iloc[:,0])\n",
      "bayesian_ard_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "bayesian_ard_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Bayesian ARD Regression #####\n",
      "\n",
      "bayesian_ard_regression_performance_metrics\n",
      "bayesian_ard_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Bayesian ARD Regression #####\n",
      "\n",
      "##### Model Pipeline for Bayesian Ridge Regression #####\n",
      "\n",
      "from sklearn.linear_model import BayesianRidge \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "bayesian_ridge_regression_param_grid = {\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "bayesian_ridge_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('bayesian_ridge_regression', BayesianRidge())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "bayesian_ridge_regression_grid_search = GridSearchCV(estimator=bayesian_ridge_regression_pipe, param_grid=bayesian_ridge_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "bayesian_ridge_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "bayesian_ridge_regression_best_estimator = bayesian_ridge_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "bayesian_ridge_regression_search_results = pd.DataFrame(bayesian_ridge_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "bayesian_ridge_regression_predictions = pd.DataFrame(bayesian_ridge_regression_best_estimator.predict(X_test))\n",
      "bayesian_ridge_regression_r2_score = r2_score(y_test, bayesian_ridge_regression_predictions.iloc[:,0])\n",
      "bayesian_ridge_regression_mean_squared_error = mean_squared_error(y_test, bayesian_ridge_regression_predictions.iloc[:,0])\n",
      "bayesian_ridge_regression_explained_variance_score = explained_variance_score(y_test, bayesian_ridge_regression_predictions.iloc[:,0])\n",
      "bayesian_ridge_regression_performance_metrics = [['bayesian_ridge_regression','r2_score', bayesian_ridge_regression_r2_score], \n",
      "                                  ['bayesian_ridge_regression','mean_squared_error',bayesian_ridge_regression_mean_squared_error],\n",
      "                                  ['bayesian_ridge_regression','explained_variance_score', bayesian_ridge_regression_explained_variance_score]]\n",
      "bayesian_ridge_regression_performance_metrics = pd.DataFrame(bayesian_ridge_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "bayesian_ridge_regression_actual_predicted_plot = px.scatter(x=y_test, y=bayesian_ridge_regression_predictions.iloc[:,0])\n",
      "bayesian_ridge_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "bayesian_ridge_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Bayesian Ridge Regression #####\n",
      "\n",
      "bayesian_ridge_regression_performance_metrics\n",
      "bayesian_ridge_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Bayesian Ridge Regression #####\n",
      "\n",
      "##### Model Pipeline for Quantile Regression #####\n",
      "\n",
      "from sklearn.linear_model import QuantileRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "quantile_regression_param_grid = {\n",
      "\"quantile_regression__alpha\": np.arange(0.1, 2.0, 0.5),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "quantile_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('quantile_regression', QuantileRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "quantile_regression_grid_search = GridSearchCV(estimator=quantile_regression_pipe, param_grid=quantile_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "quantile_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "quantile_regression_best_estimator = quantile_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "quantile_regression_search_results = pd.DataFrame(quantile_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "quantile_regression_predictions = pd.DataFrame(quantile_regression_best_estimator.predict(X_test))\n",
      "quantile_regression_r2_score = r2_score(y_test, quantile_regression_predictions.iloc[:,0])\n",
      "quantile_regression_mean_squared_error = mean_squared_error(y_test, quantile_regression_predictions.iloc[:,0])\n",
      "quantile_regression_explained_variance_score = explained_variance_score(y_test, quantile_regression_predictions.iloc[:,0])\n",
      "quantile_regression_performance_metrics = [['quantile_regression','r2_score', quantile_regression_r2_score], \n",
      "                                  ['quantile_regression','mean_squared_error',quantile_regression_mean_squared_error],\n",
      "                                  ['quantile_regression','explained_variance_score', quantile_regression_explained_variance_score]]\n",
      "quantile_regression_performance_metrics = pd.DataFrame(quantile_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "quantile_regression_actual_predicted_plot = px.scatter(x=y_test, y=quantile_regression_predictions.iloc[:,0])\n",
      "quantile_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "quantile_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Quantile Regression #####\n",
      "\n",
      "quantile_regression_performance_metrics\n",
      "quantile_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Quantile Regression #####\n",
      "\n",
      "##### Model Pipeline for Huber Regression #####\n",
      "\n",
      "from sklearn.linear_model import HuberRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "huber_regression_param_grid = {\n",
      "\"huber_regression__epsilon\": np.arange(1, 10, 2),\n",
      "\"huber_regression__alpha\": np.arange(0.0, 3.0, 0.5),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "huber_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('huber_regression', HuberRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "huber_regression_grid_search = GridSearchCV(estimator=huber_regression_pipe, param_grid=huber_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "huber_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "huber_regression_best_estimator = huber_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "huber_regression_search_results = pd.DataFrame(huber_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "huber_regression_predictions = pd.DataFrame(huber_regression_best_estimator.predict(X_test))\n",
      "huber_regression_r2_score = r2_score(y_test, huber_regression_predictions.iloc[:,0])\n",
      "huber_regression_mean_squared_error = mean_squared_error(y_test, huber_regression_predictions.iloc[:,0])\n",
      "huber_regression_explained_variance_score = explained_variance_score(y_test, huber_regression_predictions.iloc[:,0])\n",
      "huber_regression_performance_metrics = [['huber_regression','r2_score', huber_regression_r2_score], \n",
      "                                  ['huber_regression','mean_squared_error',huber_regression_mean_squared_error],\n",
      "                                  ['huber_regression','explained_variance_score', huber_regression_explained_variance_score]]\n",
      "huber_regression_performance_metrics = pd.DataFrame(huber_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "huber_regression_actual_predicted_plot = px.scatter(x=y_test, y=huber_regression_predictions.iloc[:,0])\n",
      "huber_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "huber_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Huber Regression #####\n",
      "\n",
      "huber_regression_performance_metrics\n",
      "huber_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Huber Regression #####\n",
      "\n",
      "##### Model Pipeline for TheilSen Regression #####\n",
      "\n",
      "from sklearn.linear_model import TheilSenRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "theilsen_regression_param_grid = {\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "theilsen_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('theilsen_regression', TheilSenRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "theilsen_regression_grid_search = GridSearchCV(estimator=theilsen_regression_pipe, param_grid=theilsen_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "theilsen_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "theilsen_regression_best_estimator = theilsen_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "theilsen_regression_search_results = pd.DataFrame(theilsen_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "theilsen_regression_predictions = pd.DataFrame(theilsen_regression_best_estimator.predict(X_test))\n",
      "theilsen_regression_r2_score = r2_score(y_test, theilsen_regression_predictions.iloc[:,0])\n",
      "theilsen_regression_mean_squared_error = mean_squared_error(y_test, theilsen_regression_predictions.iloc[:,0])\n",
      "theilsen_regression_explained_variance_score = explained_variance_score(y_test, theilsen_regression_predictions.iloc[:,0])\n",
      "theilsen_regression_performance_metrics = [['theilsen_regression','r2_score', theilsen_regression_r2_score], \n",
      "                                  ['theilsen_regression','mean_squared_error',theilsen_regression_mean_squared_error],\n",
      "                                  ['theilsen_regression','explained_variance_score', theilsen_regression_explained_variance_score]]\n",
      "theilsen_regression_performance_metrics = pd.DataFrame(theilsen_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "theilsen_regression_actual_predicted_plot = px.scatter(x=y_test, y=theilsen_regression_predictions.iloc[:,0])\n",
      "theilsen_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "theilsen_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics TheilSen Regression #####\n",
      "\n",
      "theilsen_regression_performance_metrics\n",
      "theilsen_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for TheilSen Regression #####\n",
      "\n",
      "##### Model Pipeline for Passive Aggressive Regression #####\n",
      "\n",
      "from sklearn.linear_model import PassiveAggressiveRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "passiveaggressive_regression_param_grid = {\n",
      "\"passiveaggressive_regression__C\": np.arange(0.0, 2.0, 0.5),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "passiveaggressive_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('passiveaggressive_regression', PassiveAggressiveRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "passiveaggressive_regression_grid_search = GridSearchCV(estimator=passiveaggressive_regression_pipe, param_grid=passiveaggressive_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "passiveaggressive_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "passiveaggressive_regression_best_estimator = passiveaggressive_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "passiveaggressive_regression_search_results = pd.DataFrame(passiveaggressive_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "passiveaggressive_regression_predictions = pd.DataFrame(passiveaggressive_regression_best_estimator.predict(X_test))\n",
      "passiveaggressive_regression_r2_score = r2_score(y_test, passiveaggressive_regression_predictions.iloc[:,0])\n",
      "passiveaggressive_regression_mean_squared_error = mean_squared_error(y_test, passiveaggressive_regression_predictions.iloc[:,0])\n",
      "passiveaggressive_regression_explained_variance_score = explained_variance_score(y_test, passiveaggressive_regression_predictions.iloc[:,0])\n",
      "passiveaggressive_regression_performance_metrics = [['passiveaggressive_regression','r2_score', passiveaggressive_regression_r2_score], \n",
      "                                  ['passiveaggressive_regression','mean_squared_error',passiveaggressive_regression_mean_squared_error],\n",
      "                                  ['passiveaggressive_regression','explained_variance_score', passiveaggressive_regression_explained_variance_score]]\n",
      "passiveaggressive_regression_performance_metrics = pd.DataFrame(passiveaggressive_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "passiveaggressive_regression_actual_predicted_plot = px.scatter(x=y_test, y=passiveaggressive_regression_predictions.iloc[:,0])\n",
      "passiveaggressive_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "passiveaggressive_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Passive Aggressive Regression #####\n",
      "\n",
      "passiveaggressive_regression_performance_metrics\n",
      "passiveaggressive_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Passive Aggressive Regression #####\n",
      "\n",
      "##### Model Pipeline for Gamma Regression #####\n",
      "\n",
      "from sklearn.linear_model import GammaRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "gamma_regression_param_grid = {\n",
      "\"gamma_regression__alpha\": np.arange(0, 2, 1),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gamma_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gamma_regression', GammaRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gamma_regression_grid_search = GridSearchCV(estimator=gamma_regression_pipe, param_grid=gamma_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "gamma_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gamma_regression_best_estimator = gamma_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gamma_regression_search_results = pd.DataFrame(gamma_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gamma_regression_predictions = pd.DataFrame(gamma_regression_best_estimator.predict(X_test))\n",
      "gamma_regression_r2_score = r2_score(y_test, gamma_regression_predictions.iloc[:,0])\n",
      "gamma_regression_mean_squared_error = mean_squared_error(y_test, gamma_regression_predictions.iloc[:,0])\n",
      "gamma_regression_explained_variance_score = explained_variance_score(y_test, gamma_regression_predictions.iloc[:,0])\n",
      "gamma_regression_performance_metrics = [['gamma_regression','r2_score', gamma_regression_r2_score], \n",
      "                                  ['gamma_regression','mean_squared_error',gamma_regression_mean_squared_error],\n",
      "                                  ['gamma_regression','explained_variance_score', gamma_regression_explained_variance_score]]\n",
      "gamma_regression_performance_metrics = pd.DataFrame(gamma_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "gamma_regression_actual_predicted_plot = px.scatter(x=y_test, y=gamma_regression_predictions.iloc[:,0])\n",
      "gamma_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "gamma_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Gamma Regression #####\n",
      "\n",
      "gamma_regression_performance_metrics\n",
      "gamma_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Gamma Regression #####\n",
      "\n",
      "##### Model Pipeline for Tweedie Regression #####\n",
      "\n",
      "from sklearn.linear_model import TweedieRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "tweedie_regression_param_grid = {\n",
      "\"tweedie_regression__power\": np.arange(0, 3, 1),\n",
      "\"tweedie_regression__alpha\": np.arange(0, 5, 1),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "tweedie_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('tweedie_regression', TweedieRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "tweedie_regression_grid_search = GridSearchCV(estimator=tweedie_regression_pipe, param_grid=tweedie_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "tweedie_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "tweedie_regression_best_estimator = tweedie_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "tweedie_regression_search_results = pd.DataFrame(tweedie_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "tweedie_regression_predictions = pd.DataFrame(tweedie_regression_best_estimator.predict(X_test))\n",
      "tweedie_regression_r2_score = r2_score(y_test, tweedie_regression_predictions.iloc[:,0])\n",
      "tweedie_regression_mean_squared_error = mean_squared_error(y_test, tweedie_regression_predictions.iloc[:,0])\n",
      "tweedie_regression_explained_variance_score = explained_variance_score(y_test, tweedie_regression_predictions.iloc[:,0])\n",
      "tweedie_regression_performance_metrics = [['tweedie_regression','r2_score', tweedie_regression_r2_score], \n",
      "                                  ['tweedie_regression','mean_squared_error',tweedie_regression_mean_squared_error],\n",
      "                                  ['tweedie_regression','explained_variance_score', tweedie_regression_explained_variance_score]]\n",
      "tweedie_regression_performance_metrics = pd.DataFrame(tweedie_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "tweedie_regression_actual_predicted_plot = px.scatter(x=y_test, y=tweedie_regression_predictions.iloc[:,0])\n",
      "tweedie_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "tweedie_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Tweedie Regression #####\n",
      "\n",
      "tweedie_regression_performance_metrics\n",
      "tweedie_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Tweedie Regression #####\n",
      "\n",
      "##### Model Pipeline for OMP Regression #####\n",
      "\n",
      "from sklearn.linear_model import OrthogonalMatchingPursuit \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "omp_regression_param_grid = {\n",
      "\"omp_regression__n_nonzero_coefs\": np.arange(0, 10, 2),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "omp_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('omp_regression', OrthogonalMatchingPursuit())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "omp_regression_grid_search = GridSearchCV(estimator=omp_regression_pipe, param_grid=omp_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "omp_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "omp_regression_best_estimator = omp_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "omp_regression_search_results = pd.DataFrame(omp_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "omp_regression_predictions = pd.DataFrame(omp_regression_best_estimator.predict(X_test))\n",
      "omp_regression_r2_score = r2_score(y_test, omp_regression_predictions.iloc[:,0])\n",
      "omp_regression_mean_squared_error = mean_squared_error(y_test, omp_regression_predictions.iloc[:,0])\n",
      "omp_regression_explained_variance_score = explained_variance_score(y_test, omp_regression_predictions.iloc[:,0])\n",
      "omp_regression_performance_metrics = [['omp_regression','r2_score', omp_regression_r2_score], \n",
      "                                  ['omp_regression','mean_squared_error',omp_regression_mean_squared_error],\n",
      "                                  ['omp_regression','explained_variance_score', omp_regression_explained_variance_score]]\n",
      "omp_regression_performance_metrics = pd.DataFrame(omp_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "omp_regression_actual_predicted_plot = px.scatter(x=y_test, y=omp_regression_predictions.iloc[:,0])\n",
      "omp_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "omp_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics OMP Regression #####\n",
      "\n",
      "omp_regression_performance_metrics\n",
      "omp_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for OMP Regression #####\n",
      "\n",
      "##### Model Pipeline for LassoLars Regression #####\n",
      "\n",
      "from sklearn.linear_model import LassoLars \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "lassolars_regression_param_grid = {\n",
      "\"lassolars_regression__alpha\": np.arange(0.0, 2.0, 0.5),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "lassolars_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('lassolars_regression', LassoLars())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "lassolars_regression_grid_search = GridSearchCV(estimator=lassolars_regression_pipe, param_grid=lassolars_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "lassolars_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "lassolars_regression_best_estimator = lassolars_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "lassolars_regression_search_results = pd.DataFrame(lassolars_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "lassolars_regression_predictions = pd.DataFrame(lassolars_regression_best_estimator.predict(X_test))\n",
      "lassolars_regression_r2_score = r2_score(y_test, lassolars_regression_predictions.iloc[:,0])\n",
      "lassolars_regression_mean_squared_error = mean_squared_error(y_test, lassolars_regression_predictions.iloc[:,0])\n",
      "lassolars_regression_explained_variance_score = explained_variance_score(y_test, lassolars_regression_predictions.iloc[:,0])\n",
      "lassolars_regression_performance_metrics = [['lassolars_regression','r2_score', lassolars_regression_r2_score], \n",
      "                                  ['lassolars_regression','mean_squared_error',lassolars_regression_mean_squared_error],\n",
      "                                  ['lassolars_regression','explained_variance_score', lassolars_regression_explained_variance_score]]\n",
      "lassolars_regression_performance_metrics = pd.DataFrame(lassolars_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "lassolars_regression_actual_predicted_plot = px.scatter(x=y_test, y=lassolars_regression_predictions.iloc[:,0])\n",
      "lassolars_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "lassolars_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics LassoLars Regression #####\n",
      "\n",
      "lassolars_regression_performance_metrics\n",
      "lassolars_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for LassoLars Regression #####\n",
      "\n",
      "##### Model Pipeline for RANSAC Regression #####\n",
      "\n",
      "from sklearn.linear_model import RANSACRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "ransac_regression_param_grid = {\n",
      "\"ransac_regression__max_trials\": np.arange(10, 100, 10),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "ransac_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('ransac_regression', RANSACRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "ransac_regression_grid_search = GridSearchCV(estimator=ransac_regression_pipe, param_grid=ransac_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "ransac_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "ransac_regression_best_estimator = ransac_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "ransac_regression_search_results = pd.DataFrame(ransac_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "ransac_regression_predictions = pd.DataFrame(ransac_regression_best_estimator.predict(X_test))\n",
      "ransac_regression_r2_score = r2_score(y_test, ransac_regression_predictions.iloc[:,0])\n",
      "ransac_regression_mean_squared_error = mean_squared_error(y_test, ransac_regression_predictions.iloc[:,0])\n",
      "ransac_regression_explained_variance_score = explained_variance_score(y_test, ransac_regression_predictions.iloc[:,0])\n",
      "ransac_regression_performance_metrics = [['ransac_regression','r2_score', ransac_regression_r2_score], \n",
      "                                  ['ransac_regression','mean_squared_error',ransac_regression_mean_squared_error],\n",
      "                                  ['ransac_regression','explained_variance_score', ransac_regression_explained_variance_score]]\n",
      "ransac_regression_performance_metrics = pd.DataFrame(ransac_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "ransac_regression_actual_predicted_plot = px.scatter(x=y_test, y=ransac_regression_predictions.iloc[:,0])\n",
      "ransac_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "ransac_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics RANSAC Regression #####\n",
      "\n",
      "ransac_regression_performance_metrics\n",
      "ransac_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for RANSAC Regression #####\n"
     ]
    }
   ],
   "source": [
    "reg_pypelines_all.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model files saved to ./code_output/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pypelines_all.code_to_file(path='./code_output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression - selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_sel = pipe.SupervisedPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'regression'\n",
    "                            , models = ['Linear Regression','Elastic Net']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'numerical': [{'name': 'n_jobs',\n",
       "    'min': 1,\n",
       "    'max': 10,\n",
       "    'step': 1}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'normalize', 'selected': [True], 'values': [True, False]}]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pypelines_sel.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear Regression', 'Elastic Net']\n"
     ]
    }
   ],
   "source": [
    "reg_pypelines_sel.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "titanic = pd.read_csv(\"./titanic.csv\")\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "# check categorical columns for high cardinality\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        categorical_cols.remove(col)\n",
      "\n",
      "# check text columns for low cardinality\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        ('text', text_transformer, text_cols),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Linear Regression #####\n",
      "\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "lin_reg_param_grid = {\n",
      "\"lin_reg__n_jobs\": np.arange(1, 10, 1),\n",
      "\"lin_reg__fit_intercept\": [True],\n",
      "\"lin_reg__normalize\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "lin_reg_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('lin_reg', LinearRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "lin_reg_grid_search = GridSearchCV(estimator=lin_reg_pipe, param_grid=lin_reg_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "lin_reg_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "lin_reg_best_estimator = lin_reg_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "lin_reg_search_results = pd.DataFrame(lin_reg_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "lin_reg_predictions = pd.DataFrame(lin_reg_best_estimator.predict(X_test))\n",
      "lin_reg_r2_score = r2_score(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_mean_squared_error = mean_squared_error(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_explained_variance_score = explained_variance_score(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_performance_metrics = [['lin_reg','r2_score', lin_reg_r2_score], \n",
      "                                  ['lin_reg','mean_squared_error',lin_reg_mean_squared_error],\n",
      "                                  ['lin_reg','explained_variance_score', lin_reg_explained_variance_score]]\n",
      "lin_reg_performance_metrics = pd.DataFrame(lin_reg_performance_metrics, columns=['model','metric', 'value'])\n",
      "lin_reg_actual_predicted_plot = px.scatter(x=y_test, y=lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "lin_reg_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Linear Regression #####\n",
      "\n",
      "lin_reg_performance_metrics\n",
      "lin_reg_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Linear Regression #####\n"
     ]
    }
   ],
   "source": [
    "reg_pypelines_sel.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_sel.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model files saved to ./code_output/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pypelines_sel.code_to_file(path='./code_output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification - all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pypelines_all = pipe.SupervisedPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'classification'\n",
    "                           , models = ['Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'numerical': [{'name': 'C',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'penalty',\n",
       "    'selected': ['l2'],\n",
       "    'values': ['l2', 'elasticnet', 'none']}]},\n",
       " 'Random Forest': {'numerical': [{'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 20},\n",
       "   {'name': 'max_depth', 'min': 2, 'max': 10, 'step': 2},\n",
       "   {'name': 'min_samples_split', 'min': 0.5, 'max': 1, 'step': 0.1},\n",
       "   {'name': 'min_samples_leaf', 'min': 1, 'max': 10, 'step': 2}],\n",
       "  'categorical': [{'name': 'criterion',\n",
       "    'selected': ['gini'],\n",
       "    'values': ['gini', 'entropy']},\n",
       "   {'name': 'max_features',\n",
       "    'selected': ['auto'],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'name': 'bootstrap', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'oob_score', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'class_weight',\n",
       "    'selected': ['balanced'],\n",
       "    'values': ['balanced', 'balanced_subsample']}]}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_all.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Logistic Regression', 'Random Forest']\n"
     ]
    }
   ],
   "source": [
    "clf_pypelines_all.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "titanic = pd.read_csv(\"./titanic.csv\")\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "# check categorical columns for high cardinality\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        categorical_cols.remove(col)\n",
      "\n",
      "# check text columns for low cardinality\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        ('text', text_transformer, text_cols),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Logistic Regression #####\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "log_reg_param_grid = {\n",
      "\"log_reg__C\": np.arange(0.1, 1.0, 0.1),\n",
      "\"log_reg__penalty\": ['l2'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "log_reg_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('log_reg', LogisticRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "log_reg_grid_search = GridSearchCV(estimator=log_reg_pipe, param_grid=log_reg_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "log_reg_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "log_reg_best_estimator = log_reg_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "log_reg_search_results = pd.DataFrame(log_reg_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "log_reg_predictions = pd.DataFrame(log_reg_best_estimator.predict(X_test))\n",
      "log_reg_predictions_prob = log_reg_best_estimator.predict_proba(X_test)\n",
      "log_reg_predictions_prob_df = pd.DataFrame()\n",
      "log_reg_predictions_prob_df[log_reg_grid_search.classes_[0]] = log_reg_predictions_prob[:,0]\n",
      "log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]] = log_reg_predictions_prob[:,1] \n",
      "log_reg_accuracy = accuracy_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_f1_score = f1_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_precision = precision_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_recall = recall_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_roc_auc_score = roc_auc_score(y_test, log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]])\n",
      "log_reg_performance_metrics = [['log_reg','accuracy',log_reg_accuracy], \n",
      "                                  ['log_reg','f1_score',log_reg_f1_score],\n",
      "                                  ['log_reg','precision', log_reg_precision],\n",
      "                                  ['log_reg','recall', log_reg_recall],\n",
      "                                  ['log_reg','roc_auc_score', log_reg_roc_auc_score]]\n",
      "log_reg_performance_metrics = pd.DataFrame(log_reg_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]])\n",
      "log_reg_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "log_reg_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "log_reg_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "log_reg_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Logistic Regression #####\n",
      "\n",
      "log_reg_performance_metrics\n",
      "log_reg_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Logistic Regression #####\n",
      "\n",
      "##### Model Pipeline for Random Forest #####\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "random_forest_classifier_param_grid = {\n",
      "\"random_forest_classifier__n_estimators\": np.arange(10, 100, 20),\n",
      "\"random_forest_classifier__max_depth\": np.arange(2, 10, 2),\n",
      "\"random_forest_classifier__min_samples_split\": np.arange(0.5, 1.0, 0.1),\n",
      "\"random_forest_classifier__min_samples_leaf\": np.arange(1, 10, 2),\n",
      "\"random_forest_classifier__criterion\": ['gini'],\n",
      "\"random_forest_classifier__max_features\": ['auto'],\n",
      "\"random_forest_classifier__bootstrap\": [True],\n",
      "\"random_forest_classifier__oob_score\": [True],\n",
      "\"random_forest_classifier__warm_start\": [False],\n",
      "\"random_forest_classifier__class_weight\": ['balanced'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "random_forest_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('random_forest_classifier', RandomForestClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "random_forest_classifier_grid_search = GridSearchCV(estimator=random_forest_classifier_pipe, param_grid=random_forest_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "random_forest_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "random_forest_classifier_best_estimator = random_forest_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "random_forest_classifier_search_results = pd.DataFrame(random_forest_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "random_forest_classifier_predictions = pd.DataFrame(random_forest_classifier_best_estimator.predict(X_test))\n",
      "random_forest_classifier_predictions_prob = random_forest_classifier_best_estimator.predict_proba(X_test)\n",
      "random_forest_classifier_predictions_prob_df = pd.DataFrame()\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[0]] = random_forest_classifier_predictions_prob[:,0]\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]] = random_forest_classifier_predictions_prob[:,1] \n",
      "random_forest_classifier_accuracy = accuracy_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_f1_score = f1_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_precision = precision_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_recall = recall_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_roc_auc_score = roc_auc_score(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_performance_metrics = [['random_forest_classifier','accuracy',random_forest_classifier_accuracy], \n",
      "                                  ['random_forest_classifier','f1_score',random_forest_classifier_f1_score],\n",
      "                                  ['random_forest_classifier','precision', random_forest_classifier_precision],\n",
      "                                  ['random_forest_classifier','recall', random_forest_classifier_recall],\n",
      "                                  ['random_forest_classifier','roc_auc_score', random_forest_classifier_roc_auc_score]]\n",
      "random_forest_classifier_performance_metrics = pd.DataFrame(random_forest_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "random_forest_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Random Forest #####\n",
      "\n",
      "random_forest_classifier_performance_metrics\n",
      "random_forest_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Random Forest #####\n"
     ]
    }
   ],
   "source": [
    "clf_pypelines_all.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model files saved to ./code_output/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_all.code_to_file(path='./code_output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification - selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf_pypelines_sel = pipe.SupervisedPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'classification'\n",
    "                            , models = ['Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'numerical': [{'name': 'C',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'penalty',\n",
       "    'selected': ['l2'],\n",
       "    'values': ['l2', 'elasticnet', 'none']}]},\n",
       " 'Random Forest': {'numerical': [{'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 20},\n",
       "   {'name': 'max_depth', 'min': 2, 'max': 10, 'step': 2},\n",
       "   {'name': 'min_samples_split', 'min': 0.5, 'max': 1, 'step': 0.1},\n",
       "   {'name': 'min_samples_leaf', 'min': 1, 'max': 10, 'step': 2}],\n",
       "  'categorical': [{'name': 'criterion',\n",
       "    'selected': ['gini'],\n",
       "    'values': ['gini', 'entropy']},\n",
       "   {'name': 'max_features',\n",
       "    'selected': ['auto'],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'name': 'bootstrap', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'oob_score', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'class_weight',\n",
       "    'selected': ['balanced'],\n",
       "    'values': ['balanced', 'balanced_subsample']}]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_sel.get_hyperparameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Logistic Regression', 'Random Forest']\n"
     ]
    }
   ],
   "source": [
    "clf_pypelines_sel.model_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pypelines_sel.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model files saved to ./code_output/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_sel.code_to_file(path='./code_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'numerical': [{'name': 'C',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'penalty',\n",
       "    'selected': ['l2'],\n",
       "    'values': ['l2', 'elasticnet', 'none']}]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_sel.grid_search_for_model('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# target dataframe: titanic\n",
    "#titanic = pd.read_csv(\"./titanic.csv\")\n",
    "target = \"Survived\"\n",
    "features = list(titanic.columns.drop(\"Survived\"))\n",
    "feature_df = titanic[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get numerical and categorical columns\n",
    "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
    "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
    "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
    "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
    "# check categorical columns for high cardinality\n",
    "\n",
    "sample_size = np.min([10000, titanic.shape[0]])\n",
    "unique_theshold = np.min([100, sample_size/10])\n",
    "\n",
    "# check categorical columns for high cardinality\n",
    "for col in categorical_cols:\n",
    "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
    "        categorical_cols.remove(col)\n",
    "        text_cols.append(col)\n",
    "\n",
    "# check text columns for low cardinality\n",
    "for col in text_cols:\n",
    "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
    "        categorical_cols.append(col)\n",
    "        text_cols.remove(col)\n",
    "\n",
    "# define numeric transformer steps\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "# define categorical transformer steps\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define text transformer steps\n",
    "text_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('text', TfidfVectorizer())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
