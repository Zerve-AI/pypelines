{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from pypelines.SupervisedPipeline import SupervisedPipeline\n",
    "\n",
    "from pypelines.sklearn.classification import models_classification , model_comparison_classification\n",
    "from pypelines.sklearn.regression import models_regression, model_comparison_regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression - all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code output\n",
    "reg_pypelines_all = SupervisedPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'regression'\n",
    "#                            , models = ['Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Elastic Net Regression': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.5},\n",
       "   {'name': 'l1_ratio', 'min': 0.0, 'max': 1.0, 'step': 0.1},\n",
       "   {'name': 'max_iter', 'min': 500, 'max': 1000, 'step': 100}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'precompute', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'selection',\n",
       "    'selected': ['cyclic'],\n",
       "    'values': ['cyclic', 'random']}]},\n",
       " 'Linear Regression': {'numerical': [{'name': 'n_jobs',\n",
       "    'min': 1,\n",
       "    'max': 10,\n",
       "    'step': 1}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'normalize', 'selected': [True], 'values': [True, False]}]},\n",
       " 'Lasso Regression': {'numerical': [{'name': 'alpha',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'name': 'max_iter', 'min': 100, 'max': 1000, 'step': 100}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'precompute', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'positive', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'selection',\n",
       "    'selected': ['cyclic'],\n",
       "    'values': ['cyclic', 'random']}]},\n",
       " 'Ridge Regression': {'numerical': [{'name': 'alpha',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'name': 'max_iter', 'min': 100, 'max': 1000, 'step': 100}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'positive', 'selected': [True], 'values': [True, False]}]},\n",
       " 'SGD Regressor Regression': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.5},\n",
       "   {'name': 'l1_ratio', 'min': 0.0, 'max': 1.0, 'step': 0.1},\n",
       "   {'name': 'max_iter', 'min': 500, 'max': 1000, 'step': 500},\n",
       "   {'name': 'epsilon', 'min': 0.001, 'max': 0.1, 'step': 0.05}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'early_stopping', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'shuffle', 'selected': [True], 'values': [True, False]}]},\n",
       " 'Histogram Gradient Boost Regression': {'numerical': [{'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 5},\n",
       "   {'name': 'max_leaf_nodes', 'min': 2, 'max': 31, 'step': 6},\n",
       "   {'name': 'min_samples_leaf', 'min': 2, 'max': 20, 'step': 5},\n",
       "   {'name': 'max_bins', 'min': 25, 'max': 255, 'step': 25}],\n",
       "  'categorical': [{'name': 'early_stopping',\n",
       "    'selected': [False],\n",
       "    'values': ['auto', True, False]},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]}]},\n",
       " 'Random Forest Regression': {'numerical': [{'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 5}],\n",
       "  'categorical': [{'name': 'bootstrap',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]}]},\n",
       " 'AdaBoost Regression': {'numerical': [{'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 50,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'name': 'loss',\n",
       "    'selected': ['linear'],\n",
       "    'values': ['linear', 'square', 'exponential']}]},\n",
       " 'Poisson Regression': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.005},\n",
       "   {'name': 'max_iter', 'min': 100, 'max': 1000, 'step': 100}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'solver',\n",
       "    'selected': ['lbfgs'],\n",
       "    'values': ['lbfgs', 'newton-cholesky']},\n",
       "   {'name': 'warm_start', 'selected': [True], 'values': [True, False]}]},\n",
       " 'Decision Tree Regression': {'numerical': [{'name': 'max_depth',\n",
       "    'min': 1,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'name': 'max_features',\n",
       "    'selected': [None],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'name': 'splitter', 'selected': ['best'], 'values': ['best', 'random']}]},\n",
       " 'GBT Regression': {'numerical': [{'name': 'n_estimators',\n",
       "    'min': 1,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'name': 'max_depth', 'min': 1, 'max': 3, 'step': 1},\n",
       "   {'name': 'alpha', 'min': 0.1, 'max': 1, 'step': 0.5}],\n",
       "  'categorical': [{'name': 'max_features',\n",
       "    'selected': [None],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]}]},\n",
       " 'ExtraTree Regression': {'numerical': [{'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'name': 'max_features',\n",
       "    'selected': [None],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'bootstrap', 'selected': [False], 'values': [True, False]}]},\n",
       " 'GPR Regression': {'numerical': [],\n",
       "  'categorical': [{'name': 'optimizer',\n",
       "    'selected': [None],\n",
       "    'values': [None, 'fmin_l_bfgs_b']},\n",
       "   {'name': 'normalize_y', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'copy_X_train', 'selected': [True], 'values': [True, False]}]},\n",
       " 'Bayesian ARD Regression': {'numerical': [{'name': 'n_iter',\n",
       "    'min': 10,\n",
       "    'max': 300,\n",
       "    'step': 50}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'compute_score', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'copy_X', 'selected': [True], 'values': [True, False]}]},\n",
       " 'Bayesian Ridge Regression': {'numerical': [{'name': 'n_iter',\n",
       "    'min': 10,\n",
       "    'max': 300,\n",
       "    'step': 50}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'compute_score', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'copy_X', 'selected': [True], 'values': [True, False]}]},\n",
       " 'Quantile Regression': {'numerical': [{'name': 'quantile',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.5},\n",
       "   {'name': 'alpha', 'min': 0.1, 'max': 1, 'step': 0.5}],\n",
       "  'categorical': [{'name': 'solver',\n",
       "    'selected': ['interior-point'],\n",
       "    'values': ['highs-ds',\n",
       "     'highs-ipm',\n",
       "     'highs',\n",
       "     'interior-point',\n",
       "     'revised simplex']}]},\n",
       " 'Huber Regression': {'numerical': [{'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'fit_intercept', 'selected': [True], 'values': [True, False]}]},\n",
       " 'TheilSen Regression': {'numerical': [{'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 300,\n",
       "    'step': 50}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'copy_X', 'selected': [True], 'values': [True, False]}]},\n",
       " 'Passive Aggressive Regression': {'numerical': [{'name': 'C',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.5},\n",
       "   {'name': 'max_iter', 'min': 100, 'max': 1000, 'step': 100}],\n",
       "  'categorical': [{'name': 'early_stopping',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'early_stopping', 'selected': [False], 'values': [True, False]}]},\n",
       " 'Gamma Regression': {'numerical': [{'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': [{'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'fit_intercept', 'selected': [True], 'values': [True, False]}]},\n",
       " 'Tweedie Regression': {'numerical': [{'name': 'max_iter',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'name': 'power', 'min': 0, 'max': 3, 'step': 1}],\n",
       "  'categorical': [{'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'fit_intercept', 'selected': [True], 'values': [True, False]}]},\n",
       " 'OMP Regression': {'numerical': [],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'normalize', 'selected': [False], 'values': [True, False]}]},\n",
       " 'LassoLars Regression': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.5},\n",
       "   {'name': 'max_iter', 'min': 10, 'max': 500, 'step': 50}],\n",
       "  'categorical': [{'name': 'warm_start',\n",
       "    'selected': [False],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'fit_intercept', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'positive', 'selected': [False], 'values': [True, False]}]},\n",
       " 'RANSAC Regression': {'numerical': [{'name': 'max_trials',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10}],\n",
       "  'categorical': []}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pypelines_all.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elastic Net Regression', 'Linear Regression', 'Lasso Regression', 'Ridge Regression', 'SGD Regressor Regression', 'Histogram Gradient Boost Regression', 'Random Forest Regression', 'AdaBoost Regression', 'Poisson Regression', 'Decision Tree Regression', 'GBT Regression', 'ExtraTree Regression', 'GPR Regression', 'Bayesian ARD Regression', 'Bayesian Ridge Regression', 'Quantile Regression', 'Huber Regression', 'TheilSen Regression', 'Passive Aggressive Regression', 'Gamma Regression', 'Tweedie Regression', 'OMP Regression', 'LassoLars Regression', 'RANSAC Regression']\n"
     ]
    }
   ],
   "source": [
    "reg_pypelines_all.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "titanic = pd.read_csv(\"./titanic.csv\")\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "# check categorical columns for high cardinality\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        categorical_cols.remove(col)\n",
      "\n",
      "# check text columns for low cardinality\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        ('text', text_transformer, text_cols),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Elastic Net Regression #####\n",
      "\n",
      "from sklearn.linear_model import ElasticNet\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "elastic_net_regression_param_grid = {\n",
      "\"elastic_net_regression__alpha\": np.arange(0.1, 1.0, 0.5),\n",
      "\"elastic_net_regression__l1_ratio\": np.arange(0.0, 1.0, 0.1),\n",
      "\"elastic_net_regression__max_iter\": np.arange(500, 1000, 100),\n",
      "\"elastic_net_regression__fit_intercept\": [True],\n",
      "\"elastic_net_regression__precompute\": [False],\n",
      "\"elastic_net_regression__selection\": ['cyclic'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "elastic_net_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('elastic_net_regression', ElasticNet())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "elastic_net_regression_grid_search = GridSearchCV(estimator=elastic_net_regression_pipe, param_grid=elastic_net_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "elastic_net_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "elastic_net_regression_best_estimator = elastic_net_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "elastic_net_regression_search_results = pd.DataFrame(elastic_net_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "elastic_net_regression_predictions = pd.DataFrame(elastic_net_regression_best_estimator.predict(X_test))\n",
      "elastic_net_regression_r2_score = r2_score(y_test, elastic_net_regression_predictions.iloc[:,0])\n",
      "elastic_net_regression_mean_squared_error = mean_squared_error(y_test, elastic_net_regression_predictions.iloc[:,0])\n",
      "elastic_net_regression_explained_variance_score = explained_variance_score(y_test, elastic_net_regression_predictions.iloc[:,0])\n",
      "elastic_net_regression_performance_metrics = [['elastic_net_regression','r2_score', elastic_net_regression_r2_score], \n",
      "                                  ['elastic_net_regression','mean_squared_error',elastic_net_regression_mean_squared_error],\n",
      "                                  ['elastic_net_regression','explained_variance_score', elastic_net_regression_explained_variance_score]]\n",
      "elastic_net_regression_performance_metrics = pd.DataFrame(elastic_net_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "elastic_net_regression_actual_predicted_plot = px.scatter(x=y_test, y=elastic_net_regression_predictions.iloc[:,0])\n",
      "elastic_net_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "elastic_net_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Elastic Net Regression #####\n",
      "\n",
      "elastic_net_regression_performance_metrics\n",
      "elastic_net_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Elastic Net Regression #####\n",
      "\n",
      "##### Model Pipeline for Linear Regression #####\n",
      "\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "lin_reg_param_grid = {\n",
      "\"lin_reg__n_jobs\": np.arange(1, 10, 1),\n",
      "\"lin_reg__fit_intercept\": [True],\n",
      "\"lin_reg__normalize\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "lin_reg_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('lin_reg', LinearRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "lin_reg_grid_search = GridSearchCV(estimator=lin_reg_pipe, param_grid=lin_reg_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "lin_reg_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "lin_reg_best_estimator = lin_reg_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "lin_reg_search_results = pd.DataFrame(lin_reg_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "lin_reg_predictions = pd.DataFrame(lin_reg_best_estimator.predict(X_test))\n",
      "lin_reg_r2_score = r2_score(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_mean_squared_error = mean_squared_error(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_explained_variance_score = explained_variance_score(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_performance_metrics = [['lin_reg','r2_score', lin_reg_r2_score], \n",
      "                                  ['lin_reg','mean_squared_error',lin_reg_mean_squared_error],\n",
      "                                  ['lin_reg','explained_variance_score', lin_reg_explained_variance_score]]\n",
      "lin_reg_performance_metrics = pd.DataFrame(lin_reg_performance_metrics, columns=['model','metric', 'value'])\n",
      "lin_reg_actual_predicted_plot = px.scatter(x=y_test, y=lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "lin_reg_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Linear Regression #####\n",
      "\n",
      "lin_reg_performance_metrics\n",
      "lin_reg_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Linear Regression #####\n",
      "\n",
      "##### Model Pipeline for Lasso Regression #####\n",
      "\n",
      "from sklearn.linear_model import Lasso\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "lasso_regression_param_grid = {\n",
      "\"lasso_regression__alpha\": np.arange(10, 100, 10),\n",
      "\"lasso_regression__max_iter\": np.arange(100, 1000, 100),\n",
      "\"lasso_regression__fit_intercept\": [True],\n",
      "\"lasso_regression__precompute\": [False],\n",
      "\"lasso_regression__positive\": [True],\n",
      "\"lasso_regression__selection\": ['cyclic'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "lasso_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('lasso_regression', Lasso())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "lasso_regression_grid_search = GridSearchCV(estimator=lasso_regression_pipe, param_grid=lasso_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "lasso_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "lasso_regression_best_estimator = lasso_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "lasso_regression_search_results = pd.DataFrame(lasso_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "lasso_regression_predictions = pd.DataFrame(lasso_regression_best_estimator.predict(X_test))\n",
      "lasso_regression_r2_score = r2_score(y_test, lasso_regression_predictions.iloc[:,0])\n",
      "lasso_regression_mean_squared_error = mean_squared_error(y_test, lasso_regression_predictions.iloc[:,0])\n",
      "lasso_regression_explained_variance_score = explained_variance_score(y_test, lasso_regression_predictions.iloc[:,0])\n",
      "lasso_regression_performance_metrics = [['lasso_regression','r2_score', lasso_regression_r2_score], \n",
      "                                  ['lasso_regression','mean_squared_error',lasso_regression_mean_squared_error],\n",
      "                                  ['lasso_regression','explained_variance_score', lasso_regression_explained_variance_score]]\n",
      "lasso_regression_performance_metrics = pd.DataFrame(lasso_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "lasso_regression_actual_predicted_plot = px.scatter(x=y_test, y=lasso_regression_predictions.iloc[:,0])\n",
      "lasso_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "lasso_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Lasso Regression #####\n",
      "\n",
      "lasso_regression_performance_metrics\n",
      "lasso_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Lasso Regression #####\n",
      "\n",
      "##### Model Pipeline for Ridge Regression #####\n",
      "\n",
      "from sklearn.linear_model import Ridge \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "ridge_regression_param_grid = {\n",
      "\"ridge_regression__alpha\": np.arange(10, 100, 10),\n",
      "\"ridge_regression__max_iter\": np.arange(100, 1000, 100),\n",
      "\"ridge_regression__fit_intercept\": [True],\n",
      "\"ridge_regression__positive\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "ridge_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('ridge_regression', Ridge())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "ridge_regression_grid_search = GridSearchCV(estimator=ridge_regression_pipe, param_grid=ridge_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "ridge_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "ridge_regression_best_estimator = ridge_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "ridge_regression_search_results = pd.DataFrame(ridge_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "ridge_regression_predictions = pd.DataFrame(ridge_regression_best_estimator.predict(X_test))\n",
      "ridge_regression_r2_score = r2_score(y_test, ridge_regression_predictions.iloc[:,0])\n",
      "ridge_regression_mean_squared_error = mean_squared_error(y_test, ridge_regression_predictions.iloc[:,0])\n",
      "ridge_regression_explained_variance_score = explained_variance_score(y_test, ridge_regression_predictions.iloc[:,0])\n",
      "ridge_regression_performance_metrics = [['ridge_regression','r2_score', ridge_regression_r2_score], \n",
      "                                  ['ridge_regression','mean_squared_error',ridge_regression_mean_squared_error],\n",
      "                                  ['ridge_regression','explained_variance_score', ridge_regression_explained_variance_score]]\n",
      "ridge_regression_performance_metrics = pd.DataFrame(ridge_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "ridge_regression_actual_predicted_plot = px.scatter(x=y_test, y=ridge_regression_predictions.iloc[:,0])\n",
      "ridge_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "ridge_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Ridge Regression #####\n",
      "\n",
      "ridge_regression_performance_metrics\n",
      "ridge_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Ridge Regression #####\n",
      "\n",
      "##### Model Pipeline for SGD Regressor Regression #####\n",
      "\n",
      "from sklearn.linear_model import SGDRegressor\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "sgd_regressor_regression_param_grid = {\n",
      "\"sgd_regressor_regression__alpha\": np.arange(0.1, 1.0, 0.5),\n",
      "\"sgd_regressor_regression__l1_ratio\": np.arange(0.0, 1.0, 0.1),\n",
      "\"sgd_regressor_regression__max_iter\": np.arange(500, 1000, 500),\n",
      "\"sgd_regressor_regression__epsilon\": np.arange(0.001, 0.1, 0.05),\n",
      "\"sgd_regressor_regression__fit_intercept\": [True],\n",
      "\"sgd_regressor_regression__early_stopping\": [False],\n",
      "\"sgd_regressor_regression__warm_start\": [False],\n",
      "\"sgd_regressor_regression__shuffle\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "sgd_regressor_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('sgd_regressor_regression', SGDRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "sgd_regressor_regression_grid_search = GridSearchCV(estimator=sgd_regressor_regression_pipe, param_grid=sgd_regressor_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "sgd_regressor_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "sgd_regressor_regression_best_estimator = sgd_regressor_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "sgd_regressor_regression_search_results = pd.DataFrame(sgd_regressor_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "sgd_regressor_regression_predictions = pd.DataFrame(sgd_regressor_regression_best_estimator.predict(X_test))\n",
      "sgd_regressor_regression_r2_score = r2_score(y_test, sgd_regressor_regression_predictions.iloc[:,0])\n",
      "sgd_regressor_regression_mean_squared_error = mean_squared_error(y_test, sgd_regressor_regression_predictions.iloc[:,0])\n",
      "sgd_regressor_regression_explained_variance_score = explained_variance_score(y_test, sgd_regressor_regression_predictions.iloc[:,0])\n",
      "sgd_regressor_regression_performance_metrics = [['sgd_regressor_regression','r2_score', sgd_regressor_regression_r2_score], \n",
      "                                  ['sgd_regressor_regression','mean_squared_error',sgd_regressor_regression_mean_squared_error],\n",
      "                                  ['sgd_regressor_regression','explained_variance_score', sgd_regressor_regression_explained_variance_score]]\n",
      "sgd_regressor_regression_performance_metrics = pd.DataFrame(sgd_regressor_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "sgd_regressor_regression_actual_predicted_plot = px.scatter(x=y_test, y=sgd_regressor_regression_predictions.iloc[:,0])\n",
      "sgd_regressor_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "sgd_regressor_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics SGD Regressor Regression #####\n",
      "\n",
      "sgd_regressor_regression_performance_metrics\n",
      "sgd_regressor_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for SGD Regressor Regression #####\n",
      "\n",
      "##### Model Pipeline for Histogram Gradient Boost Regression #####\n",
      "\n",
      "from sklearn.ensemble import HistGradientBoostingRegressor\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "hist_gbt_regression_param_grid = {\n",
      "\"hist_gbt_regression__max_iter\": np.arange(10, 100, 5),\n",
      "\"hist_gbt_regression__max_leaf_nodes\": np.arange(2, 31, 6),\n",
      "\"hist_gbt_regression__min_samples_leaf\": np.arange(2, 20, 5),\n",
      "\"hist_gbt_regression__max_bins\": np.arange(25, 255, 25),\n",
      "\"hist_gbt_regression__early_stopping\": [False],\n",
      "\"hist_gbt_regression__warm_start\": [False],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "hist_gbt_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('hist_gbt_regression', HistoGBTRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "hist_gbt_regression_grid_search = GridSearchCV(estimator=hist_gbt_regression_pipe, param_grid=hist_gbt_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "hist_gbt_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "hist_gbt_regression_best_estimator = hist_gbt_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "hist_gbt_regression_search_results = pd.DataFrame(hist_gbt_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "hist_gbt_regression_predictions = pd.DataFrame(hist_gbt_regression_best_estimator.predict(X_test))\n",
      "hist_gbt_regression_r2_score = r2_score(y_test, hist_gbt_regression_predictions.iloc[:,0])\n",
      "hist_gbt_regression_mean_squared_error = mean_squared_error(y_test, hist_gbt_regression_predictions.iloc[:,0])\n",
      "hist_gbt_regression_explained_variance_score = explained_variance_score(y_test, hist_gbt_regression_predictions.iloc[:,0])\n",
      "hist_gbt_regression_performance_metrics = [['hist_gbt_regression','r2_score', hist_gbt_regression_r2_score], \n",
      "                                  ['hist_gbt_regression','mean_squared_error',hist_gbt_regression_mean_squared_error],\n",
      "                                  ['hist_gbt_regression','explained_variance_score', hist_gbt_regression_explained_variance_score]]\n",
      "hist_gbt_regression_performance_metrics = pd.DataFrame(hist_gbt_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "hist_gbt_regression_actual_predicted_plot = px.scatter(x=y_test, y=hist_gbt_regression_predictions.iloc[:,0])\n",
      "hist_gbt_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "hist_gbt_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Histogram Gradient Boost Regression #####\n",
      "\n",
      "hist_gbt_regression_performance_metrics\n",
      "hist_gbt_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Histogram Gradient Boost Regression #####\n",
      "\n",
      "##### Model Pipeline for Random Forest Regression #####\n",
      "\n",
      "from sklearn.ensemble import RandomForestRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "random_forest_regression_param_grid = {\n",
      "\"random_forest_regression__n_estimators\": np.arange(10, 100, 5),\n",
      "\"random_forest_regression__bootstrap\": [True],\n",
      "\"random_forest_regression__warm_start\": [False],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "random_forest_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('random_forest_regression', RandomForestRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "random_forest_regression_grid_search = GridSearchCV(estimator=random_forest_regression_pipe, param_grid=random_forest_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "random_forest_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "random_forest_regression_best_estimator = random_forest_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "random_forest_regression_search_results = pd.DataFrame(random_forest_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "random_forest_regression_predictions = pd.DataFrame(random_forest_regression_best_estimator.predict(X_test))\n",
      "random_forest_regression_r2_score = r2_score(y_test, random_forest_regression_predictions.iloc[:,0])\n",
      "random_forest_regression_mean_squared_error = mean_squared_error(y_test, random_forest_regression_predictions.iloc[:,0])\n",
      "random_forest_regression_explained_variance_score = explained_variance_score(y_test, random_forest_regression_predictions.iloc[:,0])\n",
      "random_forest_regression_performance_metrics = [['random_forest_regression','r2_score', random_forest_regression_r2_score], \n",
      "                                  ['random_forest_regression','mean_squared_error',random_forest_regression_mean_squared_error],\n",
      "                                  ['random_forest_regression','explained_variance_score', random_forest_regression_explained_variance_score]]\n",
      "random_forest_regression_performance_metrics = pd.DataFrame(random_forest_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "random_forest_regression_actual_predicted_plot = px.scatter(x=y_test, y=random_forest_regression_predictions.iloc[:,0])\n",
      "random_forest_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "random_forest_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Random Forest Regression #####\n",
      "\n",
      "random_forest_regression_performance_metrics\n",
      "random_forest_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Random Forest Regression #####\n",
      "\n",
      "##### Model Pipeline for AdaBoost Regression #####\n",
      "\n",
      "from sklearn.ensemble import AdaBoostRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "adaboost_regression_param_grid = {\n",
      "\"adaboost_regression__n_estimators\": np.arange(10, 50, 10),\n",
      "\"adaboost_regression__loss\": ['linear'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "adaboost_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('adaboost_regression', AdaBoostRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "adaboost_regression_grid_search = GridSearchCV(estimator=adaboost_regression_pipe, param_grid=adaboost_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "adaboost_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "adaboost_regression_best_estimator = adaboost_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "adaboost_regression_search_results = pd.DataFrame(adaboost_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "adaboost_regression_predictions = pd.DataFrame(adaboost_regression_best_estimator.predict(X_test))\n",
      "adaboost_regression_r2_score = r2_score(y_test, adaboost_regression_predictions.iloc[:,0])\n",
      "adaboost_regression_mean_squared_error = mean_squared_error(y_test, adaboost_regression_predictions.iloc[:,0])\n",
      "adaboost_regression_explained_variance_score = explained_variance_score(y_test, adaboost_regression_predictions.iloc[:,0])\n",
      "adaboost_regression_performance_metrics = [['adaboost_regression','r2_score', adaboost_regression_r2_score], \n",
      "                                  ['adaboost_regression','mean_squared_error',adaboost_regression_mean_squared_error],\n",
      "                                  ['adaboost_regression','explained_variance_score', adaboost_regression_explained_variance_score]]\n",
      "adaboost_regression_performance_metrics = pd.DataFrame(adaboost_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "adaboost_regression_actual_predicted_plot = px.scatter(x=y_test, y=adaboost_regression_predictions.iloc[:,0])\n",
      "adaboost_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "adaboost_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics AdaBoost Regression #####\n",
      "\n",
      "adaboost_regression_performance_metrics\n",
      "adaboost_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for AdaBoost Regression #####\n",
      "\n",
      "##### Model Pipeline for Poisson Regression #####\n",
      "\n",
      "from sklearn.linear_model import PoissonRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "poisson_regression_param_grid = {\n",
      "\"poisson_regression__alpha\": np.arange(0.1, 1.0, 0.005),\n",
      "\"poisson_regression__max_iter\": np.arange(100, 1000, 100),\n",
      "\"poisson_regression__fit_intercept\": [True],\n",
      "\"poisson_regression__solver\": ['lbfgs'],\n",
      "\"poisson_regression__warm_start\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "poisson_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('poisson_regression', PoissonRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "poisson_regression_grid_search = GridSearchCV(estimator=poisson_regression_pipe, param_grid=poisson_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "poisson_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "poisson_regression_best_estimator = poisson_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "poisson_regression_search_results = pd.DataFrame(poisson_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "poisson_regression_predictions = pd.DataFrame(poisson_regression_best_estimator.predict(X_test))\n",
      "poisson_regression_r2_score = r2_score(y_test, poisson_regression_predictions.iloc[:,0])\n",
      "poisson_regression_mean_squared_error = mean_squared_error(y_test, poisson_regression_predictions.iloc[:,0])\n",
      "poisson_regression_explained_variance_score = explained_variance_score(y_test, poisson_regression_predictions.iloc[:,0])\n",
      "poisson_regression_performance_metrics = [['poisson_regression','r2_score', poisson_regression_r2_score], \n",
      "                                  ['poisson_regression','mean_squared_error',poisson_regression_mean_squared_error],\n",
      "                                  ['poisson_regression','explained_variance_score', poisson_regression_explained_variance_score]]\n",
      "poisson_regression_performance_metrics = pd.DataFrame(poisson_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "poisson_regression_actual_predicted_plot = px.scatter(x=y_test, y=poisson_regression_predictions.iloc[:,0])\n",
      "poisson_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "poisson_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Poisson Regression #####\n",
      "\n",
      "poisson_regression_performance_metrics\n",
      "poisson_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Poisson Regression #####\n",
      "\n",
      "##### Model Pipeline for Decision Tree Regression #####\n",
      "\n",
      "from sklearn.tree import DecisionTreeRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "decision_tree_regression_param_grid = {\n",
      "\"decision_tree_regression__max_depth\": np.arange(1, 100, 10),\n",
      "\"decision_tree_regression__max_features\": [None],\n",
      "\"decision_tree_regression__splitter\": ['best'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "decision_tree_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('decision_tree_regression', DecisionTreeRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "decision_tree_regression_grid_search = GridSearchCV(estimator=decision_tree_regression_pipe, param_grid=decision_tree_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "decision_tree_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "decision_tree_regression_best_estimator = decision_tree_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "decision_tree_regression_search_results = pd.DataFrame(decision_tree_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "decision_tree_regression_predictions = pd.DataFrame(decision_tree_regression_best_estimator.predict(X_test))\n",
      "decision_tree_regression_r2_score = r2_score(y_test, decision_tree_regression_predictions.iloc[:,0])\n",
      "decision_tree_regression_mean_squared_error = mean_squared_error(y_test, decision_tree_regression_predictions.iloc[:,0])\n",
      "decision_tree_regression_explained_variance_score = explained_variance_score(y_test, decision_tree_regression_predictions.iloc[:,0])\n",
      "decision_tree_regression_performance_metrics = [['decision_tree_regression','r2_score', decision_tree_regression_r2_score], \n",
      "                                  ['decision_tree_regression','mean_squared_error',decision_tree_regression_mean_squared_error],\n",
      "                                  ['decision_tree_regression','explained_variance_score', decision_tree_regression_explained_variance_score]]\n",
      "decision_tree_regression_performance_metrics = pd.DataFrame(decision_tree_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "decision_tree_regression_actual_predicted_plot = px.scatter(x=y_test, y=decision_tree_regression_predictions.iloc[:,0])\n",
      "decision_tree_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "decision_tree_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Decision Tree Regression #####\n",
      "\n",
      "decision_tree_regression_performance_metrics\n",
      "decision_tree_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Decision Tree Regression #####\n",
      "\n",
      "##### Model Pipeline for GBT Regression #####\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "gbt_regression_param_grid = {\n",
      "\"gbt_regression__n_estimators\": np.arange(1, 100, 10),\n",
      "\"gbt_regression__max_depth\": np.arange(1, 3, 1),\n",
      "\"gbt_regression__alpha\": np.arange(0.1, 1.0, 0.5),\n",
      "\"gbt_regression__max_features\": [None],\n",
      "\"gbt_regression__warm_start\": [False],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gbt_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gbt_regression', GradientBoostingRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gbt_regression_grid_search = GridSearchCV(estimator=gbt_regression_pipe, param_grid=gbt_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "gbt_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gbt_regression_best_estimator = gbt_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gbt_regression_search_results = pd.DataFrame(gbt_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gbt_regression_predictions = pd.DataFrame(gbt_regression_best_estimator.predict(X_test))\n",
      "gbt_regression_r2_score = r2_score(y_test, gbt_regression_predictions.iloc[:,0])\n",
      "gbt_regression_mean_squared_error = mean_squared_error(y_test, gbt_regression_predictions.iloc[:,0])\n",
      "gbt_regression_explained_variance_score = explained_variance_score(y_test, gbt_regression_predictions.iloc[:,0])\n",
      "gbt_regression_performance_metrics = [['gbt_regression','r2_score', gbt_regression_r2_score], \n",
      "                                  ['gbt_regression','mean_squared_error',gbt_regression_mean_squared_error],\n",
      "                                  ['gbt_regression','explained_variance_score', gbt_regression_explained_variance_score]]\n",
      "gbt_regression_performance_metrics = pd.DataFrame(gbt_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "gbt_regression_actual_predicted_plot = px.scatter(x=y_test, y=gbt_regression_predictions.iloc[:,0])\n",
      "gbt_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "gbt_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics GBT Regression #####\n",
      "\n",
      "gbt_regression_performance_metrics\n",
      "gbt_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for GBT Regression #####\n",
      "\n",
      "##### Model Pipeline for ExtraTree Regression #####\n",
      "\n",
      "from sklearn.ensemble import ExtraTreesRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "extra_tree_regression_param_grid = {\n",
      "\"extra_tree_regression__n_estimators\": np.arange(10, 100, 10),\n",
      "\"extra_tree_regression__max_features\": [None],\n",
      "\"extra_tree_regression__warm_start\": [False],\n",
      "\"extra_tree_regression__bootstrap\": [False],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "extra_tree_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('extra_tree_regression', ExtraTreesRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "extra_tree_regression_grid_search = GridSearchCV(estimator=extra_tree_regression_pipe, param_grid=extra_tree_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "extra_tree_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "extra_tree_regression_best_estimator = extra_tree_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "extra_tree_regression_search_results = pd.DataFrame(extra_tree_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "extra_tree_regression_predictions = pd.DataFrame(extra_tree_regression_best_estimator.predict(X_test))\n",
      "extra_tree_regression_r2_score = r2_score(y_test, extra_tree_regression_predictions.iloc[:,0])\n",
      "extra_tree_regression_mean_squared_error = mean_squared_error(y_test, extra_tree_regression_predictions.iloc[:,0])\n",
      "extra_tree_regression_explained_variance_score = explained_variance_score(y_test, extra_tree_regression_predictions.iloc[:,0])\n",
      "extra_tree_regression_performance_metrics = [['extra_tree_regression','r2_score', extra_tree_regression_r2_score], \n",
      "                                  ['extra_tree_regression','mean_squared_error',extra_tree_regression_mean_squared_error],\n",
      "                                  ['extra_tree_regression','explained_variance_score', extra_tree_regression_explained_variance_score]]\n",
      "extra_tree_regression_performance_metrics = pd.DataFrame(extra_tree_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "extra_tree_regression_actual_predicted_plot = px.scatter(x=y_test, y=extra_tree_regression_predictions.iloc[:,0])\n",
      "extra_tree_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "extra_tree_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics ExtraTree Regression #####\n",
      "\n",
      "extra_tree_regression_performance_metrics\n",
      "extra_tree_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for ExtraTree Regression #####\n",
      "\n",
      "##### Model Pipeline for GPR Regression #####\n",
      "\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "gpr_regression_param_grid = {\n",
      "\"gpr_regression__optimizer\": [None],\n",
      "\"gpr_regression__normalize_y\": [False],\n",
      "\"gpr_regression__copy_X_train\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gpr_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gpr_regression', GaussianProcessRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gpr_regression_grid_search = GridSearchCV(estimator=gpr_regression_pipe, param_grid=gpr_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "gpr_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gpr_regression_best_estimator = gpr_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gpr_regression_search_results = pd.DataFrame(gpr_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gpr_regression_predictions = pd.DataFrame(gpr_regression_best_estimator.predict(X_test))\n",
      "gpr_regression_r2_score = r2_score(y_test, gpr_regression_predictions.iloc[:,0])\n",
      "gpr_regression_mean_squared_error = mean_squared_error(y_test, gpr_regression_predictions.iloc[:,0])\n",
      "gpr_regression_explained_variance_score = explained_variance_score(y_test, gpr_regression_predictions.iloc[:,0])\n",
      "gpr_regression_performance_metrics = [['gpr_regression','r2_score', gpr_regression_r2_score], \n",
      "                                  ['gpr_regression','mean_squared_error',gpr_regression_mean_squared_error],\n",
      "                                  ['gpr_regression','explained_variance_score', gpr_regression_explained_variance_score]]\n",
      "gpr_regression_performance_metrics = pd.DataFrame(gpr_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "gpr_regression_actual_predicted_plot = px.scatter(x=y_test, y=gpr_regression_predictions.iloc[:,0])\n",
      "gpr_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "gpr_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics GPR Regression #####\n",
      "\n",
      "gpr_regression_performance_metrics\n",
      "gpr_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for GPR Regression #####\n",
      "\n",
      "##### Model Pipeline for Bayesian ARD Regression #####\n",
      "\n",
      "from sklearn.linear_model import ARDRegression \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "bayesian_ard_regression_param_grid = {\n",
      "\"bayesian_ard_regression__n_iter\": np.arange(10, 300, 50),\n",
      "\"bayesian_ard_regression__fit_intercept\": [True],\n",
      "\"bayesian_ard_regression__compute_score\": [False],\n",
      "\"bayesian_ard_regression__copy_X\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "bayesian_ard_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('bayesian_ard_regression', ARDRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "bayesian_ard_regression_grid_search = GridSearchCV(estimator=bayesian_ard_regression_pipe, param_grid=bayesian_ard_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "bayesian_ard_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "bayesian_ard_regression_best_estimator = bayesian_ard_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "bayesian_ard_regression_search_results = pd.DataFrame(bayesian_ard_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "bayesian_ard_regression_predictions = pd.DataFrame(bayesian_ard_regression_best_estimator.predict(X_test))\n",
      "bayesian_ard_regression_r2_score = r2_score(y_test, bayesian_ard_regression_predictions.iloc[:,0])\n",
      "bayesian_ard_regression_mean_squared_error = mean_squared_error(y_test, bayesian_ard_regression_predictions.iloc[:,0])\n",
      "bayesian_ard_regression_explained_variance_score = explained_variance_score(y_test, bayesian_ard_regression_predictions.iloc[:,0])\n",
      "bayesian_ard_regression_performance_metrics = [['bayesian_ard_regression','r2_score', bayesian_ard_regression_r2_score], \n",
      "                                  ['bayesian_ard_regression','mean_squared_error',bayesian_ard_regression_mean_squared_error],\n",
      "                                  ['bayesian_ard_regression','explained_variance_score', bayesian_ard_regression_explained_variance_score]]\n",
      "bayesian_ard_regression_performance_metrics = pd.DataFrame(bayesian_ard_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "bayesian_ard_regression_actual_predicted_plot = px.scatter(x=y_test, y=bayesian_ard_regression_predictions.iloc[:,0])\n",
      "bayesian_ard_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "bayesian_ard_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Bayesian ARD Regression #####\n",
      "\n",
      "bayesian_ard_regression_performance_metrics\n",
      "bayesian_ard_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Bayesian ARD Regression #####\n",
      "\n",
      "##### Model Pipeline for Bayesian Ridge Regression #####\n",
      "\n",
      "from sklearn.linear_model import BayesianRidge \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "bayesian_ridge_regression_param_grid = {\n",
      "\"bayesian_ridge_regression__n_iter\": np.arange(10, 300, 50),\n",
      "\"bayesian_ridge_regression__fit_intercept\": [True],\n",
      "\"bayesian_ridge_regression__compute_score\": [False],\n",
      "\"bayesian_ridge_regression__copy_X\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "bayesian_ridge_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('bayesian_ridge_regression', BayesianRidge())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "bayesian_ridge_regression_grid_search = GridSearchCV(estimator=bayesian_ridge_regression_pipe, param_grid=bayesian_ridge_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "bayesian_ridge_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "bayesian_ridge_regression_best_estimator = bayesian_ridge_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "bayesian_ridge_regression_search_results = pd.DataFrame(bayesian_ridge_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "bayesian_ridge_regression_predictions = pd.DataFrame(bayesian_ridge_regression_best_estimator.predict(X_test))\n",
      "bayesian_ridge_regression_r2_score = r2_score(y_test, bayesian_ridge_regression_predictions.iloc[:,0])\n",
      "bayesian_ridge_regression_mean_squared_error = mean_squared_error(y_test, bayesian_ridge_regression_predictions.iloc[:,0])\n",
      "bayesian_ridge_regression_explained_variance_score = explained_variance_score(y_test, bayesian_ridge_regression_predictions.iloc[:,0])\n",
      "bayesian_ridge_regression_performance_metrics = [['bayesian_ridge_regression','r2_score', bayesian_ridge_regression_r2_score], \n",
      "                                  ['bayesian_ridge_regression','mean_squared_error',bayesian_ridge_regression_mean_squared_error],\n",
      "                                  ['bayesian_ridge_regression','explained_variance_score', bayesian_ridge_regression_explained_variance_score]]\n",
      "bayesian_ridge_regression_performance_metrics = pd.DataFrame(bayesian_ridge_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "bayesian_ridge_regression_actual_predicted_plot = px.scatter(x=y_test, y=bayesian_ridge_regression_predictions.iloc[:,0])\n",
      "bayesian_ridge_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "bayesian_ridge_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Bayesian Ridge Regression #####\n",
      "\n",
      "bayesian_ridge_regression_performance_metrics\n",
      "bayesian_ridge_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Bayesian Ridge Regression #####\n",
      "\n",
      "##### Model Pipeline for Quantile Regression #####\n",
      "\n",
      "from sklearn.linear_model import QuantileRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "quantile_regression_param_grid = {\n",
      "\"quantile_regression__quantile\": np.arange(0.0, 1.0, 0.5),\n",
      "\"quantile_regression__alpha\": np.arange(0.1, 1.0, 0.5),\n",
      "\"quantile_regression__solver\": ['interior-point'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "quantile_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('quantile_regression', QuantileRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "quantile_regression_grid_search = GridSearchCV(estimator=quantile_regression_pipe, param_grid=quantile_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "quantile_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "quantile_regression_best_estimator = quantile_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "quantile_regression_search_results = pd.DataFrame(quantile_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "quantile_regression_predictions = pd.DataFrame(quantile_regression_best_estimator.predict(X_test))\n",
      "quantile_regression_r2_score = r2_score(y_test, quantile_regression_predictions.iloc[:,0])\n",
      "quantile_regression_mean_squared_error = mean_squared_error(y_test, quantile_regression_predictions.iloc[:,0])\n",
      "quantile_regression_explained_variance_score = explained_variance_score(y_test, quantile_regression_predictions.iloc[:,0])\n",
      "quantile_regression_performance_metrics = [['quantile_regression','r2_score', quantile_regression_r2_score], \n",
      "                                  ['quantile_regression','mean_squared_error',quantile_regression_mean_squared_error],\n",
      "                                  ['quantile_regression','explained_variance_score', quantile_regression_explained_variance_score]]\n",
      "quantile_regression_performance_metrics = pd.DataFrame(quantile_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "quantile_regression_actual_predicted_plot = px.scatter(x=y_test, y=quantile_regression_predictions.iloc[:,0])\n",
      "quantile_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "quantile_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Quantile Regression #####\n",
      "\n",
      "quantile_regression_performance_metrics\n",
      "quantile_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Quantile Regression #####\n",
      "\n",
      "##### Model Pipeline for Huber Regression #####\n",
      "\n",
      "from sklearn.linear_model import HuberRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "huber_regression_param_grid = {\n",
      "\"huber_regression__max_iter\": np.arange(10, 100, 10),\n",
      "\"huber_regression__warm_start\": [False],\n",
      "\"huber_regression__fit_intercept\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "huber_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('huber_regression', HuberRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "huber_regression_grid_search = GridSearchCV(estimator=huber_regression_pipe, param_grid=huber_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "huber_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "huber_regression_best_estimator = huber_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "huber_regression_search_results = pd.DataFrame(huber_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "huber_regression_predictions = pd.DataFrame(huber_regression_best_estimator.predict(X_test))\n",
      "huber_regression_r2_score = r2_score(y_test, huber_regression_predictions.iloc[:,0])\n",
      "huber_regression_mean_squared_error = mean_squared_error(y_test, huber_regression_predictions.iloc[:,0])\n",
      "huber_regression_explained_variance_score = explained_variance_score(y_test, huber_regression_predictions.iloc[:,0])\n",
      "huber_regression_performance_metrics = [['huber_regression','r2_score', huber_regression_r2_score], \n",
      "                                  ['huber_regression','mean_squared_error',huber_regression_mean_squared_error],\n",
      "                                  ['huber_regression','explained_variance_score', huber_regression_explained_variance_score]]\n",
      "huber_regression_performance_metrics = pd.DataFrame(huber_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "huber_regression_actual_predicted_plot = px.scatter(x=y_test, y=huber_regression_predictions.iloc[:,0])\n",
      "huber_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "huber_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Huber Regression #####\n",
      "\n",
      "huber_regression_performance_metrics\n",
      "huber_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Huber Regression #####\n",
      "\n",
      "##### Model Pipeline for TheilSen Regression #####\n",
      "\n",
      "from sklearn.linear_model import TheilSenRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "theilsen_regression_param_grid = {\n",
      "\"theilsen_regression__max_iter\": np.arange(10, 300, 50),\n",
      "\"theilsen_regression__fit_intercept\": [True],\n",
      "\"theilsen_regression__copy_X\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "theilsen_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('theilsen_regression', TheilSenRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "theilsen_regression_grid_search = GridSearchCV(estimator=theilsen_regression_pipe, param_grid=theilsen_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "theilsen_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "theilsen_regression_best_estimator = theilsen_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "theilsen_regression_search_results = pd.DataFrame(theilsen_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "theilsen_regression_predictions = pd.DataFrame(theilsen_regression_best_estimator.predict(X_test))\n",
      "theilsen_regression_r2_score = r2_score(y_test, theilsen_regression_predictions.iloc[:,0])\n",
      "theilsen_regression_mean_squared_error = mean_squared_error(y_test, theilsen_regression_predictions.iloc[:,0])\n",
      "theilsen_regression_explained_variance_score = explained_variance_score(y_test, theilsen_regression_predictions.iloc[:,0])\n",
      "theilsen_regression_performance_metrics = [['theilsen_regression','r2_score', theilsen_regression_r2_score], \n",
      "                                  ['theilsen_regression','mean_squared_error',theilsen_regression_mean_squared_error],\n",
      "                                  ['theilsen_regression','explained_variance_score', theilsen_regression_explained_variance_score]]\n",
      "theilsen_regression_performance_metrics = pd.DataFrame(theilsen_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "theilsen_regression_actual_predicted_plot = px.scatter(x=y_test, y=theilsen_regression_predictions.iloc[:,0])\n",
      "theilsen_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "theilsen_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics TheilSen Regression #####\n",
      "\n",
      "theilsen_regression_performance_metrics\n",
      "theilsen_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for TheilSen Regression #####\n",
      "\n",
      "##### Model Pipeline for Passive Aggressive Regression #####\n",
      "\n",
      "from sklearn.linear_model import PassiveAggressiveRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "passiveaggressive_regression_param_grid = {\n",
      "\"passiveaggressive_regression__C\": np.arange(0.0, 1.0, 0.5),\n",
      "\"passiveaggressive_regression__max_iter\": np.arange(100, 1000, 100),\n",
      "\"passiveaggressive_regression__early_stopping\": [False],\n",
      "\"passiveaggressive_regression__warm_start\": [False],\n",
      "\"passiveaggressive_regression__early_stopping\": [False],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "passiveaggressive_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('passiveaggressive_regression', PassiveAggressiveRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "passiveaggressive_regression_grid_search = GridSearchCV(estimator=passiveaggressive_regression_pipe, param_grid=passiveaggressive_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "passiveaggressive_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "passiveaggressive_regression_best_estimator = passiveaggressive_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "passiveaggressive_regression_search_results = pd.DataFrame(passiveaggressive_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "passiveaggressive_regression_predictions = pd.DataFrame(passiveaggressive_regression_best_estimator.predict(X_test))\n",
      "passiveaggressive_regression_r2_score = r2_score(y_test, passiveaggressive_regression_predictions.iloc[:,0])\n",
      "passiveaggressive_regression_mean_squared_error = mean_squared_error(y_test, passiveaggressive_regression_predictions.iloc[:,0])\n",
      "passiveaggressive_regression_explained_variance_score = explained_variance_score(y_test, passiveaggressive_regression_predictions.iloc[:,0])\n",
      "passiveaggressive_regression_performance_metrics = [['passiveaggressive_regression','r2_score', passiveaggressive_regression_r2_score], \n",
      "                                  ['passiveaggressive_regression','mean_squared_error',passiveaggressive_regression_mean_squared_error],\n",
      "                                  ['passiveaggressive_regression','explained_variance_score', passiveaggressive_regression_explained_variance_score]]\n",
      "passiveaggressive_regression_performance_metrics = pd.DataFrame(passiveaggressive_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "passiveaggressive_regression_actual_predicted_plot = px.scatter(x=y_test, y=passiveaggressive_regression_predictions.iloc[:,0])\n",
      "passiveaggressive_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "passiveaggressive_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Passive Aggressive Regression #####\n",
      "\n",
      "passiveaggressive_regression_performance_metrics\n",
      "passiveaggressive_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Passive Aggressive Regression #####\n",
      "\n",
      "##### Model Pipeline for Gamma Regression #####\n",
      "\n",
      "from sklearn.linear_model import GammaRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "gamma_regression_param_grid = {\n",
      "\"gamma_regression__max_iter\": np.arange(10, 100, 10),\n",
      "\"gamma_regression__warm_start\": [False],\n",
      "\"gamma_regression__fit_intercept\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gamma_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gamma_regression', GammaRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gamma_regression_grid_search = GridSearchCV(estimator=gamma_regression_pipe, param_grid=gamma_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "gamma_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gamma_regression_best_estimator = gamma_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gamma_regression_search_results = pd.DataFrame(gamma_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gamma_regression_predictions = pd.DataFrame(gamma_regression_best_estimator.predict(X_test))\n",
      "gamma_regression_r2_score = r2_score(y_test, gamma_regression_predictions.iloc[:,0])\n",
      "gamma_regression_mean_squared_error = mean_squared_error(y_test, gamma_regression_predictions.iloc[:,0])\n",
      "gamma_regression_explained_variance_score = explained_variance_score(y_test, gamma_regression_predictions.iloc[:,0])\n",
      "gamma_regression_performance_metrics = [['gamma_regression','r2_score', gamma_regression_r2_score], \n",
      "                                  ['gamma_regression','mean_squared_error',gamma_regression_mean_squared_error],\n",
      "                                  ['gamma_regression','explained_variance_score', gamma_regression_explained_variance_score]]\n",
      "gamma_regression_performance_metrics = pd.DataFrame(gamma_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "gamma_regression_actual_predicted_plot = px.scatter(x=y_test, y=gamma_regression_predictions.iloc[:,0])\n",
      "gamma_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "gamma_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Gamma Regression #####\n",
      "\n",
      "gamma_regression_performance_metrics\n",
      "gamma_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Gamma Regression #####\n",
      "\n",
      "##### Model Pipeline for Tweedie Regression #####\n",
      "\n",
      "from sklearn.linear_model import TweedieRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "tweedie_regression_param_grid = {\n",
      "\"tweedie_regression__max_iter\": np.arange(10, 100, 10),\n",
      "\"tweedie_regression__power\": np.arange(0, 3, 1),\n",
      "\"tweedie_regression__warm_start\": [False],\n",
      "\"tweedie_regression__fit_intercept\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "tweedie_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('tweedie_regression', TweedieRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "tweedie_regression_grid_search = GridSearchCV(estimator=tweedie_regression_pipe, param_grid=tweedie_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "tweedie_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "tweedie_regression_best_estimator = tweedie_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "tweedie_regression_search_results = pd.DataFrame(tweedie_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "tweedie_regression_predictions = pd.DataFrame(tweedie_regression_best_estimator.predict(X_test))\n",
      "tweedie_regression_r2_score = r2_score(y_test, tweedie_regression_predictions.iloc[:,0])\n",
      "tweedie_regression_mean_squared_error = mean_squared_error(y_test, tweedie_regression_predictions.iloc[:,0])\n",
      "tweedie_regression_explained_variance_score = explained_variance_score(y_test, tweedie_regression_predictions.iloc[:,0])\n",
      "tweedie_regression_performance_metrics = [['tweedie_regression','r2_score', tweedie_regression_r2_score], \n",
      "                                  ['tweedie_regression','mean_squared_error',tweedie_regression_mean_squared_error],\n",
      "                                  ['tweedie_regression','explained_variance_score', tweedie_regression_explained_variance_score]]\n",
      "tweedie_regression_performance_metrics = pd.DataFrame(tweedie_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "tweedie_regression_actual_predicted_plot = px.scatter(x=y_test, y=tweedie_regression_predictions.iloc[:,0])\n",
      "tweedie_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "tweedie_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Tweedie Regression #####\n",
      "\n",
      "tweedie_regression_performance_metrics\n",
      "tweedie_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Tweedie Regression #####\n",
      "\n",
      "##### Model Pipeline for OMP Regression #####\n",
      "\n",
      "from sklearn.linear_model import OrthogonalMatchingPursuit \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "omp_regression_param_grid = {\n",
      "\"omp_regression__fit_intercept\": [True],\n",
      "\"omp_regression__normalize\": [False],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "omp_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('omp_regression', OrthogonalMatchingPursuit())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "omp_regression_grid_search = GridSearchCV(estimator=omp_regression_pipe, param_grid=omp_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "omp_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "omp_regression_best_estimator = omp_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "omp_regression_search_results = pd.DataFrame(omp_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "omp_regression_predictions = pd.DataFrame(omp_regression_best_estimator.predict(X_test))\n",
      "omp_regression_r2_score = r2_score(y_test, omp_regression_predictions.iloc[:,0])\n",
      "omp_regression_mean_squared_error = mean_squared_error(y_test, omp_regression_predictions.iloc[:,0])\n",
      "omp_regression_explained_variance_score = explained_variance_score(y_test, omp_regression_predictions.iloc[:,0])\n",
      "omp_regression_performance_metrics = [['omp_regression','r2_score', omp_regression_r2_score], \n",
      "                                  ['omp_regression','mean_squared_error',omp_regression_mean_squared_error],\n",
      "                                  ['omp_regression','explained_variance_score', omp_regression_explained_variance_score]]\n",
      "omp_regression_performance_metrics = pd.DataFrame(omp_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "omp_regression_actual_predicted_plot = px.scatter(x=y_test, y=omp_regression_predictions.iloc[:,0])\n",
      "omp_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "omp_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics OMP Regression #####\n",
      "\n",
      "omp_regression_performance_metrics\n",
      "omp_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for OMP Regression #####\n",
      "\n",
      "##### Model Pipeline for LassoLars Regression #####\n",
      "\n",
      "from sklearn.linear_model import LassoLars \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "lassolars_regression_param_grid = {\n",
      "\"lassolars_regression__alpha\": np.arange(0.0, 1.0, 0.5),\n",
      "\"lassolars_regression__max_iter\": np.arange(10, 500, 50),\n",
      "\"lassolars_regression__warm_start\": [False],\n",
      "\"lassolars_regression__fit_intercept\": [True],\n",
      "\"lassolars_regression__positive\": [False],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "lassolars_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('lassolars_regression', LassoLars())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "lassolars_regression_grid_search = GridSearchCV(estimator=lassolars_regression_pipe, param_grid=lassolars_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "lassolars_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "lassolars_regression_best_estimator = lassolars_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "lassolars_regression_search_results = pd.DataFrame(lassolars_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "lassolars_regression_predictions = pd.DataFrame(lassolars_regression_best_estimator.predict(X_test))\n",
      "lassolars_regression_r2_score = r2_score(y_test, lassolars_regression_predictions.iloc[:,0])\n",
      "lassolars_regression_mean_squared_error = mean_squared_error(y_test, lassolars_regression_predictions.iloc[:,0])\n",
      "lassolars_regression_explained_variance_score = explained_variance_score(y_test, lassolars_regression_predictions.iloc[:,0])\n",
      "lassolars_regression_performance_metrics = [['lassolars_regression','r2_score', lassolars_regression_r2_score], \n",
      "                                  ['lassolars_regression','mean_squared_error',lassolars_regression_mean_squared_error],\n",
      "                                  ['lassolars_regression','explained_variance_score', lassolars_regression_explained_variance_score]]\n",
      "lassolars_regression_performance_metrics = pd.DataFrame(lassolars_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "lassolars_regression_actual_predicted_plot = px.scatter(x=y_test, y=lassolars_regression_predictions.iloc[:,0])\n",
      "lassolars_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "lassolars_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics LassoLars Regression #####\n",
      "\n",
      "lassolars_regression_performance_metrics\n",
      "lassolars_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for LassoLars Regression #####\n",
      "\n",
      "##### Model Pipeline for RANSAC Regression #####\n",
      "\n",
      "from sklearn.linear_model import RANSACRegressor \n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "ransac_regression_param_grid = {\n",
      "\"ransac_regression__max_trials\": np.arange(10, 100, 10),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "ransac_regression_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('ransac_regression', RANSACRegressor())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "ransac_regression_grid_search = GridSearchCV(estimator=ransac_regression_pipe, param_grid=ransac_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "ransac_regression_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "ransac_regression_best_estimator = ransac_regression_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "ransac_regression_search_results = pd.DataFrame(ransac_regression_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "ransac_regression_predictions = pd.DataFrame(ransac_regression_best_estimator.predict(X_test))\n",
      "ransac_regression_r2_score = r2_score(y_test, ransac_regression_predictions.iloc[:,0])\n",
      "ransac_regression_mean_squared_error = mean_squared_error(y_test, ransac_regression_predictions.iloc[:,0])\n",
      "ransac_regression_explained_variance_score = explained_variance_score(y_test, ransac_regression_predictions.iloc[:,0])\n",
      "ransac_regression_performance_metrics = [['ransac_regression','r2_score', ransac_regression_r2_score], \n",
      "                                  ['ransac_regression','mean_squared_error',ransac_regression_mean_squared_error],\n",
      "                                  ['ransac_regression','explained_variance_score', ransac_regression_explained_variance_score]]\n",
      "ransac_regression_performance_metrics = pd.DataFrame(ransac_regression_performance_metrics, columns=['model','metric', 'value'])\n",
      "ransac_regression_actual_predicted_plot = px.scatter(x=y_test, y=ransac_regression_predictions.iloc[:,0])\n",
      "ransac_regression_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "ransac_regression_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics RANSAC Regression #####\n",
      "\n",
      "ransac_regression_performance_metrics\n",
      "ransac_regression_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for RANSAC Regression #####\n"
     ]
    }
   ],
   "source": [
    "reg_pypelines_all.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model files saved to ./code_output/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pypelines_all.code_to_file(path='./code_output/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression - selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_sel = SupervisedPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'regression'\n",
    "                            , models = ['Linear Regression','Elastic Net']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': {'numerical': [{'name': 'n_jobs',\n",
       "    'min': 1,\n",
       "    'max': 10,\n",
       "    'step': 1}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'normalize', 'selected': [True], 'values': [True, False]}]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pypelines_sel.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear Regression', 'Elastic Net']\n"
     ]
    }
   ],
   "source": [
    "reg_pypelines_sel.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "titanic = pd.read_csv(\"./titanic.csv\")\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "# check categorical columns for high cardinality\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        categorical_cols.remove(col)\n",
      "\n",
      "# check text columns for low cardinality\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        ('text', text_transformer, text_cols),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Linear Regression #####\n",
      "\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "lin_reg_param_grid = {\n",
      "\"lin_reg__n_jobs\": np.arange(1, 10, 1),\n",
      "\"lin_reg__fit_intercept\": [True],\n",
      "\"lin_reg__normalize\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "lin_reg_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('lin_reg', LinearRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "lin_reg_grid_search = GridSearchCV(estimator=lin_reg_pipe, param_grid=lin_reg_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=1)\n",
      "lin_reg_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "lin_reg_best_estimator = lin_reg_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "lin_reg_search_results = pd.DataFrame(lin_reg_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "lin_reg_predictions = pd.DataFrame(lin_reg_best_estimator.predict(X_test))\n",
      "lin_reg_r2_score = r2_score(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_mean_squared_error = mean_squared_error(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_explained_variance_score = explained_variance_score(y_test, lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_performance_metrics = [['lin_reg','r2_score', lin_reg_r2_score], \n",
      "                                  ['lin_reg','mean_squared_error',lin_reg_mean_squared_error],\n",
      "                                  ['lin_reg','explained_variance_score', lin_reg_explained_variance_score]]\n",
      "lin_reg_performance_metrics = pd.DataFrame(lin_reg_performance_metrics, columns=['model','metric', 'value'])\n",
      "lin_reg_actual_predicted_plot = px.scatter(x=y_test, y=lin_reg_predictions.iloc[:,0])\n",
      "lin_reg_actual_predicted_plot.add_shape(type=\"line\", line=dict(dash='dash'),x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max())\n",
      "lin_reg_actual_predicted_plot.update_layout(title=\"Actual vs Predicted\",xaxis_title=\"Actual\",yaxis_title=\"Predicted\")\n",
      "\n",
      "\n",
      "##### Model Metrics Linear Regression #####\n",
      "\n",
      "lin_reg_performance_metrics\n",
      "lin_reg_actual_predicted_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Linear Regression #####\n"
     ]
    }
   ],
   "source": [
    "reg_pypelines_sel.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_sel.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model files saved to ./code_output/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_pypelines_sel.code_to_file(path='./code_output/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification - all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pypelines_all = SupervisedPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'classification'\n",
    "#                            , models = ['Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': {'numerical': [{'name': 'max_depth',\n",
       "    'min': 2,\n",
       "    'max': 10,\n",
       "    'step': 1},\n",
       "   {'name': 'min_samples_split', 'min': 2, 'max': 10, 'step': 1},\n",
       "   {'name': 'min_samples_leaf', 'min': 1, 'max': 10, 'step': 1},\n",
       "   {'name': 'min_weight_fraction_leaf', 'min': 0.0, 'max': 0.5, 'step': 0.1},\n",
       "   {'name': 'max_leaf_nodes', 'min': 2, 'max': 10, 'step': 1},\n",
       "   {'name': 'min_impurity_decrease', 'min': 0.0, 'max': 0.5, 'step': 0.1},\n",
       "   {'name': 'min_impurity_split', 'min': 0.1, 'max': 0.5, 'step': 0.1}],\n",
       "  'categorical': [{'name': 'criterion',\n",
       "    'selected': ['gini'],\n",
       "    'values': ['gini', 'entropy']},\n",
       "   {'name': 'splitter', 'selected': ['best'], 'values': ['best', 'random']},\n",
       "   {'name': 'max_features',\n",
       "    'selected': ['auto'],\n",
       "    'values': ['auto', 'sqrt', 'log2']}]},\n",
       " 'Logistic Regression': {'numerical': [{'name': 'C',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'penalty',\n",
       "    'selected': ['l2'],\n",
       "    'values': ['l2', 'elasticnet', 'none']}]},\n",
       " 'Random Forest': {'numerical': [{'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 20},\n",
       "   {'name': 'max_depth', 'min': 2, 'max': 10, 'step': 2},\n",
       "   {'name': 'min_samples_split', 'min': 0.5, 'max': 1, 'step': 0.1},\n",
       "   {'name': 'min_samples_leaf', 'min': 1, 'max': 10, 'step': 2}],\n",
       "  'categorical': [{'name': 'criterion',\n",
       "    'selected': ['gini'],\n",
       "    'values': ['gini', 'entropy']},\n",
       "   {'name': 'max_features',\n",
       "    'selected': ['auto'],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'name': 'bootstrap', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'oob_score', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'class_weight',\n",
       "    'selected': ['balanced'],\n",
       "    'values': ['balanced', 'balanced_subsample']}]},\n",
       " 'SVC': {'numerical': [{'name': 'C', 'min': 0.1, 'max': 1, 'step': 0.1},\n",
       "   {'name': 'degree', 'min': 2, 'max': 5, 'step': 1}],\n",
       "  'categorical': [{'name': 'kernel',\n",
       "    'selected': ['linear'],\n",
       "    'values': ['linear', 'rbf', 'sigmoid']},\n",
       "   {'name': 'gamma', 'selected': ['scale'], 'values': ['scale', 'auto']}]},\n",
       " 'XGBoost': {'numerical': [{'name': 'learning_rate',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.1},\n",
       "   {'name': 'n_estimators', 'min': 100, 'max': 500, 'step': 50},\n",
       "   {'name': 'max_depth', 'min': 2, 'max': 10, 'step': 2},\n",
       "   {'name': 'gamma', 'min': 0.0, 'max': 0.5, 'step': 0.1},\n",
       "   {'name': 'subsample', 'min': 0.1, 'max': 1.0, 'step': 0.25},\n",
       "   {'name': 'colsample_bytree', 'min': 0.5, 'max': 1.0, 'step': 0.1},\n",
       "   {'name': 'reg_alpha', 'min': 0.0, 'max': 1.0, 'step': 0.1},\n",
       "   {'name': 'reg_lambda', 'min': 0.0, 'max': 1.0, 'step': 0.1}],\n",
       "  'categorical': [{'name': 'booster',\n",
       "    'selected': ['gbtree'],\n",
       "    'values': ['gbtree', 'gblinear', 'dart']},\n",
       "   {'name': 'eval_metric',\n",
       "    'selected': ['rmse'],\n",
       "    'values': ['rmse',\n",
       "     'mae',\n",
       "     'logloss',\n",
       "     'error',\n",
       "     'merror',\n",
       "     'mlogloss',\n",
       "     'auc']},\n",
       "   {'name': 'tree_method',\n",
       "    'selected': ['auto'],\n",
       "    'values': ['auto', 'exact', 'approx', 'hist', 'gpu_hist']},\n",
       "   {'name': 'grow_policy',\n",
       "    'selected': ['depthwise'],\n",
       "    'values': ['depthwise', 'lossguide']}]},\n",
       " 'MLP': {'numerical': [{'name': 'hidden_layer_sizes',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'name': 'batch_size', 'min': 64, 'max': 512, 'step': 128},\n",
       "   {'name': 'learning_rate', 'min': 0.001, 'max': 0.1, 'step': 0.05}],\n",
       "  'categorical': [{'name': 'learning_rate_init',\n",
       "    'selected': ['constant'],\n",
       "    'value': ['constant', 'invscaling', 'adaptive']},\n",
       "   {'name': 'solver', 'selected': ['adam'], 'value': ['lbfgs', 'sgd', 'adam']},\n",
       "   {'name': 'activation',\n",
       "    'selected': ['relu'],\n",
       "    'value': ['relu', 'identity', 'logistic', 'tanh']},\n",
       "   {'name': 'shuffle', 'selected': [True], 'value': [True, False]}]},\n",
       " 'Ridge Classifier': {'numerical': [{'name': 'alpha',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 10},\n",
       "   {'name': 'max_iter', 'min': 100, 'max': 1000, 'step': 100}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'positive', 'selected': [True], 'values': [True, False]}]},\n",
       " 'HistGBT Classifier': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.1},\n",
       "   {'name': 'l1_ratio', 'min': 0, 'max': 1, 'step': 0.1},\n",
       "   {'name': 'max_iter', 'min': 1000, 'max': 10000, 'step': 100}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'Perceptron Classifier': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.1},\n",
       "   {'name': 'l1_ratio', 'min': 0, 'max': 1, 'step': 0.1},\n",
       "   {'name': 'max_iter', 'min': 1000, 'max': 10000, 'step': 100}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'SGD Classifier': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.1},\n",
       "   {'name': 'max_iter', 'min': 1, 'max': 1000, 'step': 10}],\n",
       "  'categorical': [{'name': 'loss',\n",
       "    'selected': ['hinge'],\n",
       "    'values': ['hinge',\n",
       "     'log_loss',\n",
       "     'log',\n",
       "     'modified_huber',\n",
       "     'squared_hinge',\n",
       "     'perceptron',\n",
       "     'squared_error',\n",
       "     'huber',\n",
       "     'epsilon_insensitive',\n",
       "     'squared_epsilon_insensitive']},\n",
       "   {'name': 'penalty',\n",
       "    'selected': ['l2'],\n",
       "    'values': ['l2', 'l1', 'elasticnet']},\n",
       "   {'name': 'fit_intercept', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'shuffle', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'learning_rate',\n",
       "    'selected': ['optimal'],\n",
       "    'values': ['constant', 'optimal', 'invscaling', 'adaptive']},\n",
       "   {'name': 'average', 'selected': [True], 'values': [True, False]}]},\n",
       " 'GBT Classifier': {'numerical': [{'name': 'learning_rate',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.1},\n",
       "   {'name': 'n_estimators', 'min': 100, 'max': 10000, 'step': 100},\n",
       "   {'name': 'subsample', 'min': 0.1, 'max': 1, 'step': 0.1},\n",
       "   {'name': 'max_depth', 'min': 1, 'max': 10000, 'step': 100}],\n",
       "  'categorical': []},\n",
       " 'ADABoost Classifier': {'numerical': [{'name': 'learning_rate',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.1},\n",
       "   {'name': 'n_estimators', 'min': 100, 'max': 10000, 'step': 100}],\n",
       "  'categorical': [{'name': 'algorithm',\n",
       "    'selected': ['SAMME.R'],\n",
       "    'values': ['SAMME', 'SAMME.R']}]},\n",
       " 'ExtraTrees Classifier': {'numerical': [{'name': 'n_estimators',\n",
       "    'min': 100,\n",
       "    'max': 500,\n",
       "    'step': 50},\n",
       "   {'name': 'max_depth', 'min': 2, 'max': 10, 'step': 2},\n",
       "   {'name': 'max_samples', 'min': 0.1, 'max': 1.0, 'step': 0.1}],\n",
       "  'categorical': [{'name': 'criterion',\n",
       "    'selected': ['gini'],\n",
       "    'values': ['gini', 'entropy', 'log_loss']},\n",
       "   {'name': 'max_features',\n",
       "    'selected': ['log2'],\n",
       "    'values': ['sqrt', 'log2', None]}]},\n",
       " 'PassiveAggressive Classifier': {'numerical': [{'name': 'max_iter',\n",
       "    'min': 100,\n",
       "    'max': 1000,\n",
       "    'step': 100},\n",
       "   {'name': 'C', 'min': 0.1, 'max': 1, 'step': 0.1}],\n",
       "  'categorical': [{'name': 'fit_intercept',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'average', 'selected': [True], 'values': [True, False]}]},\n",
       " 'LDA Classifier': {'numerical': [],\n",
       "  'categorical': [{'name': 'solver',\n",
       "    'selected': ['svd'],\n",
       "    'values': ['svd', 'lsqr', 'eigen']}]},\n",
       " 'QDA Classifier': {'numerical': [],\n",
       "  'categorical': [{'name': 'store_covariance',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]}]},\n",
       " 'NuSVC Classifier': {'numerical': [{'name': 'nu',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.1},\n",
       "   {'name': 'degree', 'min': 2, 'max': 5, 'step': 1}],\n",
       "  'categorical': [{'name': 'kernel',\n",
       "    'selected': ['poly'],\n",
       "    'values': ['linear', 'rbf', 'sigmoid', 'poly', 'sigmoid']},\n",
       "   {'name': 'gamma', 'selected': ['scale'], 'values': ['scale', 'auto']}]},\n",
       " 'GaussianNB Classifier': {'numerical': [], 'categorical': []},\n",
       " 'MultinomialNB Classifier': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'fit_prior',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'force_alpha', 'selected': [True], 'values': [True, False]}]},\n",
       " 'ComplementNB Classifier': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'fit_prior',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'force_alpha', 'selected': [True], 'values': [True, False]}]},\n",
       " 'BernoulliNB Classifier': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'fit_prior',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'force_alpha', 'selected': [True], 'values': [True, False]}]},\n",
       " 'CategoricalNB Classifier': {'numerical': [{'name': 'alpha',\n",
       "    'min': 0,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'fit_prior',\n",
       "    'selected': [True],\n",
       "    'values': [True, False]},\n",
       "   {'name': 'force_alpha', 'selected': [True], 'values': [True, False]}]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_all.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Decision Tree', 'Logistic Regression', 'Random Forest', 'SVC', 'XGBoost', 'MLP', 'Ridge Classifier', 'HistGBT Classifier', 'Perceptron Classifier', 'SGD Classifier', 'GBT Classifier', 'ADABoost Classifier', 'ExtraTrees Classifier', 'PassiveAggressive Classifier', 'LDA Classifier', 'QDA Classifier', 'NuSVC Classifier', 'GaussianNB Classifier', 'MultinomialNB Classifier', 'ComplementNB Classifier', 'BernoulliNB Classifier', 'CategoricalNB Classifier']\n"
     ]
    }
   ],
   "source": [
    "clf_pypelines_all.model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "import plotly.express as px\n",
      "import plotly.graph_objects as go\n",
      "\n",
      "\n",
      "# target dataframe: titanic\n",
      "titanic = pd.read_csv(\"./titanic.csv\")\n",
      "target = \"Survived\"\n",
      "features = list(titanic.columns.drop(\"Survived\"))\n",
      "feature_df = titanic[features]\n",
      "\n",
      "# get numerical and categorical columns\n",
      "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
      "titanic[bool_cols] = feature_df[bool_cols].astype(int)\n",
      "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
      "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
      "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
      "# check categorical columns for high cardinality\n",
      "\n",
      "sample_size = np.min([10000, titanic.shape[0]])\n",
      "unique_theshold = np.min([100, sample_size/10])\n",
      "\n",
      "# check categorical columns for high cardinality\n",
      "for col in categorical_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() > unique_theshold:\n",
      "        categorical_cols.remove(col)\n",
      "\n",
      "# check text columns for low cardinality\n",
      "for col in text_cols:\n",
      "    if titanic[col].sample(sample_size).nunique() < unique_theshold:\n",
      "        categorical_cols.append(col)\n",
      "        text_cols.remove(col)\n",
      "\n",
      "# define numeric transformer steps\n",
      "numeric_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
      "        (\"scaler\", StandardScaler())]\n",
      ")\n",
      "\n",
      "# define categorical transformer steps\n",
      "categorical_transformer = Pipeline(\n",
      "    steps=[\n",
      "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
      "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
      "    ]\n",
      ")\n",
      "\n",
      "# define text transformer steps\n",
      "text_transformer = Pipeline(\n",
      "    steps=[\n",
      "        ('text', TfidfVectorizer())\n",
      "    ]\n",
      ")\n",
      "\n",
      "# create the preprocessing pipelines for both numeric and categorical data\n",
      "preprocessor = ColumnTransformer(\n",
      "    transformers=[\n",
      "        ('num', numeric_transformer , numerical_cols),\n",
      "        ('cat', categorical_transformer, categorical_cols),\n",
      "        ('text', text_transformer, text_cols),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# train test split\n",
      "X = titanic[features]\n",
      "y = titanic[target]\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "##### End of Data Processing Pipeline #####\n",
      "\n",
      "\n",
      "\n",
      "##### Model Pipeline for Decision Tree #####\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "dt_classifier_param_grid = {\n",
      "\"dt_classifier__max_depth\": np.arange(2, 10, 1),\n",
      "\"dt_classifier__min_samples_split\": np.arange(2, 10, 1),\n",
      "\"dt_classifier__min_samples_leaf\": np.arange(1, 10, 1),\n",
      "\"dt_classifier__min_weight_fraction_leaf\": np.arange(0.0, 0.5, 0.1),\n",
      "\"dt_classifier__max_leaf_nodes\": np.arange(2, 10, 1),\n",
      "\"dt_classifier__min_impurity_decrease\": np.arange(0.0, 0.5, 0.1),\n",
      "\"dt_classifier__min_impurity_split\": np.arange(0.1, 0.5, 0.1),\n",
      "\"dt_classifier__criterion\": ['gini'],\n",
      "\"dt_classifier__splitter\": ['best'],\n",
      "\"dt_classifier__max_features\": ['auto'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "dt_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('dt_classifier', DecisionTreeClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "dt_classifier_grid_search = GridSearchCV(estimator=dt_classifier_pipe, param_grid=dt_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "dt_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "dt_classifier_best_estimator = dt_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "dt_classifier_search_results = pd.DataFrame(dt_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "dt_classifier_predictions = pd.DataFrame(dt_classifier_best_estimator.predict(X_test))\n",
      "dt_classifier_predictions_prob = dt_classifier_best_estimator.predict_proba(X_test)\n",
      "dt_classifier_predictions_prob_df = pd.DataFrame()\n",
      "dt_classifier_predictions_prob_df[dt_classifier_grid_search.classes_[0]] = dt_classifier_predictions_prob[:,0]\n",
      "dt_classifier_predictions_prob_df[dt_classifier_grid_search.classes_[1]] = dt_classifier_predictions_prob[:,1] \n",
      "dt_classifier_accuracy = accuracy_score(y_test, dt_classifier_predictions.iloc[:,0])\n",
      "dt_classifier_f1_score = f1_score(y_test, dt_classifier_predictions.iloc[:,0])\n",
      "dt_classifier_precision = precision_score(y_test, dt_classifier_predictions.iloc[:,0])\n",
      "dt_classifier_recall = recall_score(y_test, dt_classifier_predictions.iloc[:,0])\n",
      "dt_classifier_roc_auc_score = roc_auc_score(y_test, dt_classifier_predictions_prob_df[dt_classifier_grid_search.classes_[1]])\n",
      "dt_classifier_performance_metrics = [['dt_classifier','accuracy',dt_classifier_accuracy], \n",
      "                                  ['dt_classifier','f1_score',dt_classifier_f1_score],\n",
      "                                  ['dt_classifier','precision', dt_classifier_precision],\n",
      "                                  ['dt_classifier','recall', dt_classifier_recall],\n",
      "                                  ['dt_classifier','roc_auc_score', dt_classifier_roc_auc_score]]\n",
      "dt_classifier_performance_metrics = pd.DataFrame(dt_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, dt_classifier_predictions_prob_df[dt_classifier_grid_search.classes_[1]])\n",
      "dt_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "dt_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "dt_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "dt_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Decision Tree #####\n",
      "\n",
      "dt_classifier_performance_metrics\n",
      "dt_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Decision Tree #####\n",
      "\n",
      "##### Model Pipeline for Logistic Regression #####\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "log_reg_param_grid = {\n",
      "\"log_reg__C\": np.arange(0.1, 1.0, 0.1),\n",
      "\"log_reg__penalty\": ['l2'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "log_reg_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('log_reg', LogisticRegression())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "log_reg_grid_search = GridSearchCV(estimator=log_reg_pipe, param_grid=log_reg_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "log_reg_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "log_reg_best_estimator = log_reg_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "log_reg_search_results = pd.DataFrame(log_reg_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "log_reg_predictions = pd.DataFrame(log_reg_best_estimator.predict(X_test))\n",
      "log_reg_predictions_prob = log_reg_best_estimator.predict_proba(X_test)\n",
      "log_reg_predictions_prob_df = pd.DataFrame()\n",
      "log_reg_predictions_prob_df[log_reg_grid_search.classes_[0]] = log_reg_predictions_prob[:,0]\n",
      "log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]] = log_reg_predictions_prob[:,1] \n",
      "log_reg_accuracy = accuracy_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_f1_score = f1_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_precision = precision_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_recall = recall_score(y_test, log_reg_predictions.iloc[:,0])\n",
      "log_reg_roc_auc_score = roc_auc_score(y_test, log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]])\n",
      "log_reg_performance_metrics = [['log_reg','accuracy',log_reg_accuracy], \n",
      "                                  ['log_reg','f1_score',log_reg_f1_score],\n",
      "                                  ['log_reg','precision', log_reg_precision],\n",
      "                                  ['log_reg','recall', log_reg_recall],\n",
      "                                  ['log_reg','roc_auc_score', log_reg_roc_auc_score]]\n",
      "log_reg_performance_metrics = pd.DataFrame(log_reg_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, log_reg_predictions_prob_df[log_reg_grid_search.classes_[1]])\n",
      "log_reg_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "log_reg_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "log_reg_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "log_reg_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Logistic Regression #####\n",
      "\n",
      "log_reg_performance_metrics\n",
      "log_reg_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Logistic Regression #####\n",
      "\n",
      "##### Model Pipeline for Random Forest #####\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "random_forest_classifier_param_grid = {\n",
      "\"random_forest_classifier__n_estimators\": np.arange(10, 100, 20),\n",
      "\"random_forest_classifier__max_depth\": np.arange(2, 10, 2),\n",
      "\"random_forest_classifier__min_samples_split\": np.arange(0.5, 1.0, 0.1),\n",
      "\"random_forest_classifier__min_samples_leaf\": np.arange(1, 10, 2),\n",
      "\"random_forest_classifier__criterion\": ['gini'],\n",
      "\"random_forest_classifier__max_features\": ['auto'],\n",
      "\"random_forest_classifier__bootstrap\": [True],\n",
      "\"random_forest_classifier__oob_score\": [True],\n",
      "\"random_forest_classifier__warm_start\": [False],\n",
      "\"random_forest_classifier__class_weight\": ['balanced'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "random_forest_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('random_forest_classifier', RandomForestClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "random_forest_classifier_grid_search = GridSearchCV(estimator=random_forest_classifier_pipe, param_grid=random_forest_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "random_forest_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "random_forest_classifier_best_estimator = random_forest_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "random_forest_classifier_search_results = pd.DataFrame(random_forest_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "random_forest_classifier_predictions = pd.DataFrame(random_forest_classifier_best_estimator.predict(X_test))\n",
      "random_forest_classifier_predictions_prob = random_forest_classifier_best_estimator.predict_proba(X_test)\n",
      "random_forest_classifier_predictions_prob_df = pd.DataFrame()\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[0]] = random_forest_classifier_predictions_prob[:,0]\n",
      "random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]] = random_forest_classifier_predictions_prob[:,1] \n",
      "random_forest_classifier_accuracy = accuracy_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_f1_score = f1_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_precision = precision_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_recall = recall_score(y_test, random_forest_classifier_predictions.iloc[:,0])\n",
      "random_forest_classifier_roc_auc_score = roc_auc_score(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_performance_metrics = [['random_forest_classifier','accuracy',random_forest_classifier_accuracy], \n",
      "                                  ['random_forest_classifier','f1_score',random_forest_classifier_f1_score],\n",
      "                                  ['random_forest_classifier','precision', random_forest_classifier_precision],\n",
      "                                  ['random_forest_classifier','recall', random_forest_classifier_recall],\n",
      "                                  ['random_forest_classifier','roc_auc_score', random_forest_classifier_roc_auc_score]]\n",
      "random_forest_classifier_performance_metrics = pd.DataFrame(random_forest_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, random_forest_classifier_predictions_prob_df[random_forest_classifier_grid_search.classes_[1]])\n",
      "random_forest_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "random_forest_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "random_forest_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Random Forest #####\n",
      "\n",
      "random_forest_classifier_performance_metrics\n",
      "random_forest_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Random Forest #####\n",
      "\n",
      "##### Model Pipeline for SVC #####\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "svc_classifier_param_grid = {\n",
      "\"svc_classifier__C\": np.arange(0.1, 1.0, 0.1),\n",
      "\"svc_classifier__degree\": np.arange(2, 5, 1),\n",
      "\"svc_classifier__kernel\": ['linear'],\n",
      "\"svc_classifier__gamma\": ['scale'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "svc_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('svc_classifier', SVC())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "svc_classifier_grid_search = GridSearchCV(estimator=svc_classifier_pipe, param_grid=svc_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "svc_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "svc_classifier_best_estimator = svc_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "svc_classifier_search_results = pd.DataFrame(svc_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "svc_classifier_predictions = pd.DataFrame(svc_classifier_best_estimator.predict(X_test))\n",
      "svc_classifier_predictions_prob = svc_classifier_best_estimator.predict_proba(X_test)\n",
      "svc_classifier_predictions_prob_df = pd.DataFrame()\n",
      "svc_classifier_predictions_prob_df[svc_classifier_grid_search.classes_[0]] = svc_classifier_predictions_prob[:,0]\n",
      "svc_classifier_predictions_prob_df[svc_classifier_grid_search.classes_[1]] = svc_classifier_predictions_prob[:,1] \n",
      "svc_classifier_accuracy = accuracy_score(y_test, svc_classifier_predictions.iloc[:,0])\n",
      "svc_classifier_f1_score = f1_score(y_test, svc_classifier_predictions.iloc[:,0])\n",
      "svc_classifier_precision = precision_score(y_test, svc_classifier_predictions.iloc[:,0])\n",
      "svc_classifier_recall = recall_score(y_test, svc_classifier_predictions.iloc[:,0])\n",
      "svc_classifier_roc_auc_score = roc_auc_score(y_test, svc_classifier_predictions_prob_df[svc_classifier_grid_search.classes_[1]])\n",
      "svc_classifier_performance_metrics = [['svc_classifier','accuracy',svc_classifier_accuracy], \n",
      "                                  ['svc_classifier','f1_score',svc_classifier_f1_score],\n",
      "                                  ['svc_classifier','precision', svc_classifier_precision],\n",
      "                                  ['svc_classifier','recall', svc_classifier_recall],\n",
      "                                  ['svc_classifier','roc_auc_score', svc_classifier_roc_auc_score]]\n",
      "svc_classifier_performance_metrics = pd.DataFrame(svc_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, svc_classifier_predictions_prob_df[svc_classifier_grid_search.classes_[1]])\n",
      "svc_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "svc_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "svc_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "svc_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics SVC #####\n",
      "\n",
      "svc_classifier_performance_metrics\n",
      "svc_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for SVC #####\n",
      "\n",
      "##### Model Pipeline for XGBoost #####\n",
      "\n",
      "from xgboost import XGBClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "xgboost_classifier_param_grid = {\n",
      "\"xgboost_classifier__learning_rate\": np.arange(0.1, 1.0, 0.1),\n",
      "\"xgboost_classifier__n_estimators\": np.arange(100, 500, 50),\n",
      "\"xgboost_classifier__max_depth\": np.arange(2, 10, 2),\n",
      "\"xgboost_classifier__gamma\": np.arange(0.0, 0.5, 0.1),\n",
      "\"xgboost_classifier__subsample\": np.arange(0.1, 1.0, 0.25),\n",
      "\"xgboost_classifier__colsample_bytree\": np.arange(0.5, 1.0, 0.1),\n",
      "\"xgboost_classifier__reg_alpha\": np.arange(0.0, 1.0, 0.1),\n",
      "\"xgboost_classifier__reg_lambda\": np.arange(0.0, 1.0, 0.1),\n",
      "\"xgboost_classifier__booster\": ['gbtree'],\n",
      "\"xgboost_classifier__eval_metric\": ['rmse'],\n",
      "\"xgboost_classifier__tree_method\": ['auto'],\n",
      "\"xgboost_classifier__grow_policy\": ['depthwise'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "xgboost_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('xgboost_classifier', XGBClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "xgboost_classifier_grid_search = GridSearchCV(estimator=xgboost_classifier_pipe, param_grid=xgboost_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "xgboost_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "xgboost_classifier_best_estimator = xgboost_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "xgboost_classifier_search_results = pd.DataFrame(xgboost_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "xgboost_classifier_predictions = pd.DataFrame(xgboost_classifier_best_estimator.predict(X_test))\n",
      "xgboost_classifier_predictions_prob = xgboost_classifier_best_estimator.predict_proba(X_test)\n",
      "xgboost_classifier_predictions_prob_df = pd.DataFrame()\n",
      "xgboost_classifier_predictions_prob_df[xgboost_classifier_grid_search.classes_[0]] = xgboost_classifier_predictions_prob[:,0]\n",
      "xgboost_classifier_predictions_prob_df[xgboost_classifier_grid_search.classes_[1]] = xgboost_classifier_predictions_prob[:,1] \n",
      "xgboost_classifier_accuracy = accuracy_score(y_test, xgboost_classifier_predictions.iloc[:,0])\n",
      "xgboost_classifier_f1_score = f1_score(y_test, xgboost_classifier_predictions.iloc[:,0])\n",
      "xgboost_classifier_precision = precision_score(y_test, xgboost_classifier_predictions.iloc[:,0])\n",
      "xgboost_classifier_recall = recall_score(y_test, xgboost_classifier_predictions.iloc[:,0])\n",
      "xgboost_classifier_roc_auc_score = roc_auc_score(y_test, xgboost_classifier_predictions_prob_df[xgboost_classifier_grid_search.classes_[1]])\n",
      "xgboost_classifier_performance_metrics = [['xgboost_classifier','accuracy',xgboost_classifier_accuracy], \n",
      "                                  ['xgboost_classifier','f1_score',xgboost_classifier_f1_score],\n",
      "                                  ['xgboost_classifier','precision', xgboost_classifier_precision],\n",
      "                                  ['xgboost_classifier','recall', xgboost_classifier_recall],\n",
      "                                  ['xgboost_classifier','roc_auc_score', xgboost_classifier_roc_auc_score]]\n",
      "xgboost_classifier_performance_metrics = pd.DataFrame(xgboost_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, xgboost_classifier_predictions_prob_df[xgboost_classifier_grid_search.classes_[1]])\n",
      "xgboost_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "xgboost_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "xgboost_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "xgboost_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics XGBoost #####\n",
      "\n",
      "xgboost_classifier_performance_metrics\n",
      "xgboost_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for XGBoost #####\n",
      "\n",
      "##### Model Pipeline for MLP #####\n",
      "\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "mlp_classifier_param_grid = {\n",
      "\"mlp_classifier__hidden_layer_sizes\": np.arange(10, 100, 10),\n",
      "\"mlp_classifier__batch_size\": np.arange(64, 512, 128),\n",
      "\"mlp_classifier__learning_rate\": np.arange(0.001, 0.1, 0.05),\n",
      "\"mlp_classifier__learning_rate_init\": ['constant'],\n",
      "\"mlp_classifier__solver\": ['adam'],\n",
      "\"mlp_classifier__activation\": ['relu'],\n",
      "\"mlp_classifier__shuffle\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "mlp_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('mlp_classifier', MLPClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "mlp_classifier_grid_search = GridSearchCV(estimator=mlp_classifier_pipe, param_grid=mlp_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "mlp_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "mlp_classifier_best_estimator = mlp_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "mlp_classifier_search_results = pd.DataFrame(mlp_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "mlp_classifier_predictions = pd.DataFrame(mlp_classifier_best_estimator.predict(X_test))\n",
      "mlp_classifier_predictions_prob = mlp_classifier_best_estimator.predict_proba(X_test)\n",
      "mlp_classifier_predictions_prob_df = pd.DataFrame()\n",
      "mlp_classifier_predictions_prob_df[mlp_classifier_grid_search.classes_[0]] = mlp_classifier_predictions_prob[:,0]\n",
      "mlp_classifier_predictions_prob_df[mlp_classifier_grid_search.classes_[1]] = mlp_classifier_predictions_prob[:,1] \n",
      "mlp_classifier_accuracy = accuracy_score(y_test, mlp_classifier_predictions.iloc[:,0])\n",
      "mlp_classifier_f1_score = f1_score(y_test, mlp_classifier_predictions.iloc[:,0])\n",
      "mlp_classifier_precision = precision_score(y_test, mlp_classifier_predictions.iloc[:,0])\n",
      "mlp_classifier_recall = recall_score(y_test, mlp_classifier_predictions.iloc[:,0])\n",
      "mlp_classifier_roc_auc_score = roc_auc_score(y_test, mlp_classifier_predictions_prob_df[mlp_classifier_grid_search.classes_[1]])\n",
      "mlp_classifier_performance_metrics = [['mlp_classifier','accuracy',mlp_classifier_accuracy], \n",
      "                                  ['mlp_classifier','f1_score',mlp_classifier_f1_score],\n",
      "                                  ['mlp_classifier','precision', mlp_classifier_precision],\n",
      "                                  ['mlp_classifier','recall', mlp_classifier_recall],\n",
      "                                  ['mlp_classifier','roc_auc_score', mlp_classifier_roc_auc_score]]\n",
      "mlp_classifier_performance_metrics = pd.DataFrame(mlp_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, mlp_classifier_predictions_prob_df[mlp_classifier_grid_search.classes_[1]])\n",
      "mlp_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "mlp_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "mlp_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "mlp_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics MLP #####\n",
      "\n",
      "mlp_classifier_performance_metrics\n",
      "mlp_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for MLP #####\n",
      "\n",
      "##### Model Pipeline for Ridge Classifier #####\n",
      "\n",
      "from sklearn.linear_model import RidgeClassifier \n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "ridge_classifer_param_grid = {\n",
      "\"ridge_classifer__alpha\": np.arange(10, 100, 10),\n",
      "\"ridge_classifer__max_iter\": np.arange(100, 1000, 100),\n",
      "\"ridge_classifer__fit_intercept\": [True],\n",
      "\"ridge_classifer__positive\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "ridge_classifer_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('ridge_classifer', RidgeClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "ridge_classifer_grid_search = GridSearchCV(estimator=ridge_classifer_pipe, param_grid=ridge_classifer_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "ridge_classifer_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "ridge_classifer_best_estimator = ridge_classifer_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "ridge_classifer_search_results = pd.DataFrame(ridge_classifer_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "ridge_classifer_predictions = pd.DataFrame(ridge_classifer_best_estimator.predict(X_test))\n",
      "ridge_classifer_predictions_prob = ridge_classifer_best_estimator.predict_proba(X_test)\n",
      "ridge_classifer_predictions_prob_df = pd.DataFrame()\n",
      "ridge_classifer_predictions_prob_df[ridge_classifer_grid_search.classes_[0]] = ridge_classifer_predictions_prob[:,0]\n",
      "ridge_classifer_predictions_prob_df[ridge_classifer_grid_search.classes_[1]] = ridge_classifer_predictions_prob[:,1] \n",
      "ridge_classifer_accuracy = accuracy_score(y_test, ridge_classifer_predictions.iloc[:,0])\n",
      "ridge_classifer_f1_score = f1_score(y_test, ridge_classifer_predictions.iloc[:,0])\n",
      "ridge_classifer_precision = precision_score(y_test, ridge_classifer_predictions.iloc[:,0])\n",
      "ridge_classifer_recall = recall_score(y_test, ridge_classifer_predictions.iloc[:,0])\n",
      "ridge_classifer_roc_auc_score = roc_auc_score(y_test, ridge_classifer_predictions_prob_df[ridge_classifer_grid_search.classes_[1]])\n",
      "ridge_classifer_performance_metrics = [['ridge_classifer','accuracy',ridge_classifer_accuracy], \n",
      "                                  ['ridge_classifer','f1_score',ridge_classifer_f1_score],\n",
      "                                  ['ridge_classifer','precision', ridge_classifer_precision],\n",
      "                                  ['ridge_classifer','recall', ridge_classifer_recall],\n",
      "                                  ['ridge_classifer','roc_auc_score', ridge_classifer_roc_auc_score]]\n",
      "ridge_classifer_performance_metrics = pd.DataFrame(ridge_classifer_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, ridge_classifer_predictions_prob_df[ridge_classifer_grid_search.classes_[1]])\n",
      "ridge_classifer_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "ridge_classifer_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "ridge_classifer_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "ridge_classifer_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Ridge Classifier #####\n",
      "\n",
      "ridge_classifer_performance_metrics\n",
      "ridge_classifer_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Ridge Classifier #####\n",
      "\n",
      "##### Model Pipeline for HistGBT Classifier #####\n",
      "\n",
      "from sklearn.ensemble import HistGradientBoostingClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "histgbt_classifier_param_grid = {\n",
      "\"histgbt_classifier__alpha\": np.arange(0.0, 1.0, 0.1),\n",
      "\"histgbt_classifier__l1_ratio\": np.arange(0.0, 1.0, 0.1),\n",
      "\"histgbt_classifier__max_iter\": np.arange(1000, 10000, 100),\n",
      "\"histgbt_classifier__fit_intercept\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "histgbt_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('histgbt_classifier', HistGradientBoostingClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "histgbt_classifier_grid_search = GridSearchCV(estimator=histgbt_classifier_pipe, param_grid=histgbt_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "histgbt_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "histgbt_classifier_best_estimator = histgbt_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "histgbt_classifier_search_results = pd.DataFrame(histgbt_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "histgbt_classifier_predictions = pd.DataFrame(histgbt_classifier_best_estimator.predict(X_test))\n",
      "histgbt_classifier_predictions_prob = histgbt_classifier_best_estimator.predict_proba(X_test)\n",
      "histgbt_classifier_predictions_prob_df = pd.DataFrame()\n",
      "histgbt_classifier_predictions_prob_df[histgbt_classifier_grid_search.classes_[0]] = histgbt_classifier_predictions_prob[:,0]\n",
      "histgbt_classifier_predictions_prob_df[histgbt_classifier_grid_search.classes_[1]] = histgbt_classifier_predictions_prob[:,1] \n",
      "histgbt_classifier_accuracy = accuracy_score(y_test, histgbt_classifier_predictions.iloc[:,0])\n",
      "histgbt_classifier_f1_score = f1_score(y_test, histgbt_classifier_predictions.iloc[:,0])\n",
      "histgbt_classifier_precision = precision_score(y_test, histgbt_classifier_predictions.iloc[:,0])\n",
      "histgbt_classifier_recall = recall_score(y_test, histgbt_classifier_predictions.iloc[:,0])\n",
      "histgbt_classifier_roc_auc_score = roc_auc_score(y_test, histgbt_classifier_predictions_prob_df[histgbt_classifier_grid_search.classes_[1]])\n",
      "histgbt_classifier_performance_metrics = [['histgbt_classifier','accuracy',histgbt_classifier_accuracy], \n",
      "                                  ['histgbt_classifier','f1_score',histgbt_classifier_f1_score],\n",
      "                                  ['histgbt_classifier','precision', histgbt_classifier_precision],\n",
      "                                  ['histgbt_classifier','recall', histgbt_classifier_recall],\n",
      "                                  ['histgbt_classifier','roc_auc_score', histgbt_classifier_roc_auc_score]]\n",
      "histgbt_classifier_performance_metrics = pd.DataFrame(histgbt_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, histgbt_classifier_predictions_prob_df[histgbt_classifier_grid_search.classes_[1]])\n",
      "histgbt_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "histgbt_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "histgbt_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "histgbt_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics HistGBT Classifier #####\n",
      "\n",
      "histgbt_classifier_performance_metrics\n",
      "histgbt_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for HistGBT Classifier #####\n",
      "\n",
      "##### Model Pipeline for Perceptron Classifier #####\n",
      "\n",
      "from sklearn.linear_model import Perceptron\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "perceptron_classifier_param_grid = {\n",
      "\"perceptron_classifier__alpha\": np.arange(0.0, 1.0, 0.1),\n",
      "\"perceptron_classifier__l1_ratio\": np.arange(0.0, 1.0, 0.1),\n",
      "\"perceptron_classifier__max_iter\": np.arange(1000, 10000, 100),\n",
      "\"perceptron_classifier__fit_intercept\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "perceptron_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('perceptron_classifier', Perceptron())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "perceptron_classifier_grid_search = GridSearchCV(estimator=perceptron_classifier_pipe, param_grid=perceptron_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "perceptron_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "perceptron_classifier_best_estimator = perceptron_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "perceptron_classifier_search_results = pd.DataFrame(perceptron_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "perceptron_classifier_predictions = pd.DataFrame(perceptron_classifier_best_estimator.predict(X_test))\n",
      "perceptron_classifier_predictions_prob = perceptron_classifier_best_estimator.predict_proba(X_test)\n",
      "perceptron_classifier_predictions_prob_df = pd.DataFrame()\n",
      "perceptron_classifier_predictions_prob_df[perceptron_classifier_grid_search.classes_[0]] = perceptron_classifier_predictions_prob[:,0]\n",
      "perceptron_classifier_predictions_prob_df[perceptron_classifier_grid_search.classes_[1]] = perceptron_classifier_predictions_prob[:,1] \n",
      "perceptron_classifier_accuracy = accuracy_score(y_test, perceptron_classifier_predictions.iloc[:,0])\n",
      "perceptron_classifier_f1_score = f1_score(y_test, perceptron_classifier_predictions.iloc[:,0])\n",
      "perceptron_classifier_precision = precision_score(y_test, perceptron_classifier_predictions.iloc[:,0])\n",
      "perceptron_classifier_recall = recall_score(y_test, perceptron_classifier_predictions.iloc[:,0])\n",
      "perceptron_classifier_roc_auc_score = roc_auc_score(y_test, perceptron_classifier_predictions_prob_df[perceptron_classifier_grid_search.classes_[1]])\n",
      "perceptron_classifier_performance_metrics = [['perceptron_classifier','accuracy',perceptron_classifier_accuracy], \n",
      "                                  ['perceptron_classifier','f1_score',perceptron_classifier_f1_score],\n",
      "                                  ['perceptron_classifier','precision', perceptron_classifier_precision],\n",
      "                                  ['perceptron_classifier','recall', perceptron_classifier_recall],\n",
      "                                  ['perceptron_classifier','roc_auc_score', perceptron_classifier_roc_auc_score]]\n",
      "perceptron_classifier_performance_metrics = pd.DataFrame(perceptron_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, perceptron_classifier_predictions_prob_df[perceptron_classifier_grid_search.classes_[1]])\n",
      "perceptron_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "perceptron_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "perceptron_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "perceptron_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics Perceptron Classifier #####\n",
      "\n",
      "perceptron_classifier_performance_metrics\n",
      "perceptron_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for Perceptron Classifier #####\n",
      "\n",
      "##### Model Pipeline for SGD Classifier #####\n",
      "\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "sgd_classifier_param_grid = {\n",
      "\"sgd_classifier__alpha\": np.arange(0.0, 1.0, 0.1),\n",
      "\"sgd_classifier__max_iter\": np.arange(1, 1000, 10),\n",
      "\"sgd_classifier__loss\": ['hinge'],\n",
      "\"sgd_classifier__penalty\": ['l2'],\n",
      "\"sgd_classifier__fit_intercept\": [True],\n",
      "\"sgd_classifier__shuffle\": [True],\n",
      "\"sgd_classifier__learning_rate\": ['optimal'],\n",
      "\"sgd_classifier__average\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "sgd_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('sgd_classifier', SGDClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "sgd_classifier_grid_search = GridSearchCV(estimator=sgd_classifier_pipe, param_grid=sgd_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "sgd_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "sgd_classifier_best_estimator = sgd_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "sgd_classifier_search_results = pd.DataFrame(sgd_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "sgd_classifier_predictions = pd.DataFrame(sgd_classifier_best_estimator.predict(X_test))\n",
      "sgd_classifier_predictions_prob = sgd_classifier_best_estimator.predict_proba(X_test)\n",
      "sgd_classifier_predictions_prob_df = pd.DataFrame()\n",
      "sgd_classifier_predictions_prob_df[sgd_classifier_grid_search.classes_[0]] = sgd_classifier_predictions_prob[:,0]\n",
      "sgd_classifier_predictions_prob_df[sgd_classifier_grid_search.classes_[1]] = sgd_classifier_predictions_prob[:,1] \n",
      "sgd_classifier_accuracy = accuracy_score(y_test, sgd_classifier_predictions.iloc[:,0])\n",
      "sgd_classifier_f1_score = f1_score(y_test, sgd_classifier_predictions.iloc[:,0])\n",
      "sgd_classifier_precision = precision_score(y_test, sgd_classifier_predictions.iloc[:,0])\n",
      "sgd_classifier_recall = recall_score(y_test, sgd_classifier_predictions.iloc[:,0])\n",
      "sgd_classifier_roc_auc_score = roc_auc_score(y_test, sgd_classifier_predictions_prob_df[sgd_classifier_grid_search.classes_[1]])\n",
      "sgd_classifier_performance_metrics = [['sgd_classifier','accuracy',sgd_classifier_accuracy], \n",
      "                                  ['sgd_classifier','f1_score',sgd_classifier_f1_score],\n",
      "                                  ['sgd_classifier','precision', sgd_classifier_precision],\n",
      "                                  ['sgd_classifier','recall', sgd_classifier_recall],\n",
      "                                  ['sgd_classifier','roc_auc_score', sgd_classifier_roc_auc_score]]\n",
      "sgd_classifier_performance_metrics = pd.DataFrame(sgd_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, sgd_classifier_predictions_prob_df[sgd_classifier_grid_search.classes_[1]])\n",
      "sgd_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "sgd_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "sgd_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "sgd_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics SGD Classifier #####\n",
      "\n",
      "sgd_classifier_performance_metrics\n",
      "sgd_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for SGD Classifier #####\n",
      "\n",
      "##### Model Pipeline for GBT Classifier #####\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "gbt_classifier_param_grid = {\n",
      "\"gbt_classifier__learning_rate\": np.arange(0.0, 1.0, 0.1),\n",
      "\"gbt_classifier__n_estimators\": np.arange(100, 10000, 100),\n",
      "\"gbt_classifier__subsample\": np.arange(0.1, 1.0, 0.1),\n",
      "\"gbt_classifier__max_depth\": np.arange(1, 10000, 100),\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gbt_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gbt_classifier', GradientBoostingClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gbt_classifier_grid_search = GridSearchCV(estimator=gbt_classifier_pipe, param_grid=gbt_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "gbt_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gbt_classifier_best_estimator = gbt_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gbt_classifier_search_results = pd.DataFrame(gbt_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gbt_classifier_predictions = pd.DataFrame(gbt_classifier_best_estimator.predict(X_test))\n",
      "gbt_classifier_predictions_prob = gbt_classifier_best_estimator.predict_proba(X_test)\n",
      "gbt_classifier_predictions_prob_df = pd.DataFrame()\n",
      "gbt_classifier_predictions_prob_df[gbt_classifier_grid_search.classes_[0]] = gbt_classifier_predictions_prob[:,0]\n",
      "gbt_classifier_predictions_prob_df[gbt_classifier_grid_search.classes_[1]] = gbt_classifier_predictions_prob[:,1] \n",
      "gbt_classifier_accuracy = accuracy_score(y_test, gbt_classifier_predictions.iloc[:,0])\n",
      "gbt_classifier_f1_score = f1_score(y_test, gbt_classifier_predictions.iloc[:,0])\n",
      "gbt_classifier_precision = precision_score(y_test, gbt_classifier_predictions.iloc[:,0])\n",
      "gbt_classifier_recall = recall_score(y_test, gbt_classifier_predictions.iloc[:,0])\n",
      "gbt_classifier_roc_auc_score = roc_auc_score(y_test, gbt_classifier_predictions_prob_df[gbt_classifier_grid_search.classes_[1]])\n",
      "gbt_classifier_performance_metrics = [['gbt_classifier','accuracy',gbt_classifier_accuracy], \n",
      "                                  ['gbt_classifier','f1_score',gbt_classifier_f1_score],\n",
      "                                  ['gbt_classifier','precision', gbt_classifier_precision],\n",
      "                                  ['gbt_classifier','recall', gbt_classifier_recall],\n",
      "                                  ['gbt_classifier','roc_auc_score', gbt_classifier_roc_auc_score]]\n",
      "gbt_classifier_performance_metrics = pd.DataFrame(gbt_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, gbt_classifier_predictions_prob_df[gbt_classifier_grid_search.classes_[1]])\n",
      "gbt_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "gbt_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "gbt_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "gbt_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics GBT Classifier #####\n",
      "\n",
      "gbt_classifier_performance_metrics\n",
      "gbt_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for GBT Classifier #####\n",
      "\n",
      "##### Model Pipeline for ADABoost Classifier #####\n",
      "\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "adaboost_classifier_param_grid = {\n",
      "\"adaboost_classifier__learning_rate\": np.arange(0.0, 1.0, 0.1),\n",
      "\"adaboost_classifier__n_estimators\": np.arange(100, 10000, 100),\n",
      "\"adaboost_classifier__algorithm\": ['SAMME.R'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "adaboost_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('adaboost_classifier', AdaBoostClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "adaboost_classifier_grid_search = GridSearchCV(estimator=adaboost_classifier_pipe, param_grid=adaboost_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "adaboost_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "adaboost_classifier_best_estimator = adaboost_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "adaboost_classifier_search_results = pd.DataFrame(adaboost_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "adaboost_classifier_predictions = pd.DataFrame(adaboost_classifier_best_estimator.predict(X_test))\n",
      "adaboost_classifier_predictions_prob = adaboost_classifier_best_estimator.predict_proba(X_test)\n",
      "adaboost_classifier_predictions_prob_df = pd.DataFrame()\n",
      "adaboost_classifier_predictions_prob_df[adaboost_classifier_grid_search.classes_[0]] = adaboost_classifier_predictions_prob[:,0]\n",
      "adaboost_classifier_predictions_prob_df[adaboost_classifier_grid_search.classes_[1]] = adaboost_classifier_predictions_prob[:,1] \n",
      "adaboost_classifier_accuracy = accuracy_score(y_test, adaboost_classifier_predictions.iloc[:,0])\n",
      "adaboost_classifier_f1_score = f1_score(y_test, adaboost_classifier_predictions.iloc[:,0])\n",
      "adaboost_classifier_precision = precision_score(y_test, adaboost_classifier_predictions.iloc[:,0])\n",
      "adaboost_classifier_recall = recall_score(y_test, adaboost_classifier_predictions.iloc[:,0])\n",
      "adaboost_classifier_roc_auc_score = roc_auc_score(y_test, adaboost_classifier_predictions_prob_df[adaboost_classifier_grid_search.classes_[1]])\n",
      "adaboost_classifier_performance_metrics = [['adaboost_classifier','accuracy',adaboost_classifier_accuracy], \n",
      "                                  ['adaboost_classifier','f1_score',adaboost_classifier_f1_score],\n",
      "                                  ['adaboost_classifier','precision', adaboost_classifier_precision],\n",
      "                                  ['adaboost_classifier','recall', adaboost_classifier_recall],\n",
      "                                  ['adaboost_classifier','roc_auc_score', adaboost_classifier_roc_auc_score]]\n",
      "adaboost_classifier_performance_metrics = pd.DataFrame(adaboost_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, adaboost_classifier_predictions_prob_df[adaboost_classifier_grid_search.classes_[1]])\n",
      "adaboost_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "adaboost_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "adaboost_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "adaboost_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics ADABoost Classifier #####\n",
      "\n",
      "adaboost_classifier_performance_metrics\n",
      "adaboost_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for ADABoost Classifier #####\n",
      "\n",
      "##### Model Pipeline for ExtraTrees Classifier #####\n",
      "\n",
      "from ensemble import ExtraTreesClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "extra_trees_classifier_param_grid = {\n",
      "\"extra_trees_classifier__n_estimators\": np.arange(100, 500, 50),\n",
      "\"extra_trees_classifier__max_depth\": np.arange(2, 10, 2),\n",
      "\"extra_trees_classifier__max_samples\": np.arange(0.1, 1.0, 0.1),\n",
      "\"extra_trees_classifier__criterion\": ['gini'],\n",
      "\"extra_trees_classifier__max_features\": ['log2'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "extra_trees_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('extra_trees_classifier', ExtraTreesClassifier())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "extra_trees_classifier_grid_search = GridSearchCV(estimator=extra_trees_classifier_pipe, param_grid=extra_trees_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "extra_trees_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "extra_trees_classifier_best_estimator = extra_trees_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "extra_trees_classifier_search_results = pd.DataFrame(extra_trees_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "extra_trees_classifier_predictions = pd.DataFrame(extra_trees_classifier_best_estimator.predict(X_test))\n",
      "extra_trees_classifier_predictions_prob = extra_trees_classifier_best_estimator.predict_proba(X_test)\n",
      "extra_trees_classifier_predictions_prob_df = pd.DataFrame()\n",
      "extra_trees_classifier_predictions_prob_df[extra_trees_classifier_grid_search.classes_[0]] = extra_trees_classifier_predictions_prob[:,0]\n",
      "extra_trees_classifier_predictions_prob_df[extra_trees_classifier_grid_search.classes_[1]] = extra_trees_classifier_predictions_prob[:,1] \n",
      "extra_trees_classifier_accuracy = accuracy_score(y_test, extra_trees_classifier_predictions.iloc[:,0])\n",
      "extra_trees_classifier_f1_score = f1_score(y_test, extra_trees_classifier_predictions.iloc[:,0])\n",
      "extra_trees_classifier_precision = precision_score(y_test, extra_trees_classifier_predictions.iloc[:,0])\n",
      "extra_trees_classifier_recall = recall_score(y_test, extra_trees_classifier_predictions.iloc[:,0])\n",
      "extra_trees_classifier_roc_auc_score = roc_auc_score(y_test, extra_trees_classifier_predictions_prob_df[extra_trees_classifier_grid_search.classes_[1]])\n",
      "extra_trees_classifier_performance_metrics = [['extra_trees_classifier','accuracy',extra_trees_classifier_accuracy], \n",
      "                                  ['extra_trees_classifier','f1_score',extra_trees_classifier_f1_score],\n",
      "                                  ['extra_trees_classifier','precision', extra_trees_classifier_precision],\n",
      "                                  ['extra_trees_classifier','recall', extra_trees_classifier_recall],\n",
      "                                  ['extra_trees_classifier','roc_auc_score', extra_trees_classifier_roc_auc_score]]\n",
      "extra_trees_classifier_performance_metrics = pd.DataFrame(extra_trees_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, extra_trees_classifier_predictions_prob_df[extra_trees_classifier_grid_search.classes_[1]])\n",
      "extra_trees_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "extra_trees_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "extra_trees_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "extra_trees_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics ExtraTrees Classifier #####\n",
      "\n",
      "extra_trees_classifier_performance_metrics\n",
      "extra_trees_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for ExtraTrees Classifier #####\n",
      "\n",
      "##### Model Pipeline for PassiveAggressive Classifier #####\n",
      "\n",
      "from linear_model import PassiveAggressiveClassifier\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "passive_aggressive_classifier_param_grid = {\n",
      "\"passive_aggressive_classifier__max_iter\": np.arange(100, 1000, 100),\n",
      "\"passive_aggressive_classifier__C\": np.arange(0.1, 1.0, 0.1),\n",
      "\"passive_aggressive_classifier__fit_intercept\": [True],\n",
      "\"passive_aggressive_classifier__average\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "passive_aggressive_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('passive_aggressive_classifier', PassiveAggressive())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "passive_aggressive_classifier_grid_search = GridSearchCV(estimator=passive_aggressive_classifier_pipe, param_grid=passive_aggressive_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "passive_aggressive_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "passive_aggressive_classifier_best_estimator = passive_aggressive_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "passive_aggressive_classifier_search_results = pd.DataFrame(passive_aggressive_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "passive_aggressive_classifier_predictions = pd.DataFrame(passive_aggressive_classifier_best_estimator.predict(X_test))\n",
      "passive_aggressive_classifier_predictions_prob = passive_aggressive_classifier_best_estimator.predict_proba(X_test)\n",
      "passive_aggressive_classifier_predictions_prob_df = pd.DataFrame()\n",
      "passive_aggressive_classifier_predictions_prob_df[passive_aggressive_classifier_grid_search.classes_[0]] = passive_aggressive_classifier_predictions_prob[:,0]\n",
      "passive_aggressive_classifier_predictions_prob_df[passive_aggressive_classifier_grid_search.classes_[1]] = passive_aggressive_classifier_predictions_prob[:,1] \n",
      "passive_aggressive_classifier_accuracy = accuracy_score(y_test, passive_aggressive_classifier_predictions.iloc[:,0])\n",
      "passive_aggressive_classifier_f1_score = f1_score(y_test, passive_aggressive_classifier_predictions.iloc[:,0])\n",
      "passive_aggressive_classifier_precision = precision_score(y_test, passive_aggressive_classifier_predictions.iloc[:,0])\n",
      "passive_aggressive_classifier_recall = recall_score(y_test, passive_aggressive_classifier_predictions.iloc[:,0])\n",
      "passive_aggressive_classifier_roc_auc_score = roc_auc_score(y_test, passive_aggressive_classifier_predictions_prob_df[passive_aggressive_classifier_grid_search.classes_[1]])\n",
      "passive_aggressive_classifier_performance_metrics = [['passive_aggressive_classifier','accuracy',passive_aggressive_classifier_accuracy], \n",
      "                                  ['passive_aggressive_classifier','f1_score',passive_aggressive_classifier_f1_score],\n",
      "                                  ['passive_aggressive_classifier','precision', passive_aggressive_classifier_precision],\n",
      "                                  ['passive_aggressive_classifier','recall', passive_aggressive_classifier_recall],\n",
      "                                  ['passive_aggressive_classifier','roc_auc_score', passive_aggressive_classifier_roc_auc_score]]\n",
      "passive_aggressive_classifier_performance_metrics = pd.DataFrame(passive_aggressive_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, passive_aggressive_classifier_predictions_prob_df[passive_aggressive_classifier_grid_search.classes_[1]])\n",
      "passive_aggressive_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "passive_aggressive_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "passive_aggressive_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "passive_aggressive_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics PassiveAggressive Classifier #####\n",
      "\n",
      "passive_aggressive_classifier_performance_metrics\n",
      "passive_aggressive_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for PassiveAggressive Classifier #####\n",
      "\n",
      "##### Model Pipeline for LDA Classifier #####\n",
      "\n",
      "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "lda_classifier_param_grid = {\n",
      "\"lda_classifier__solver\": ['svd'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "lda_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('lda_classifier', LinearDiscriminantAnalysis())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "lda_classifier_grid_search = GridSearchCV(estimator=lda_classifier_pipe, param_grid=lda_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "lda_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "lda_classifier_best_estimator = lda_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "lda_classifier_search_results = pd.DataFrame(lda_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "lda_classifier_predictions = pd.DataFrame(lda_classifier_best_estimator.predict(X_test))\n",
      "lda_classifier_predictions_prob = lda_classifier_best_estimator.predict_proba(X_test)\n",
      "lda_classifier_predictions_prob_df = pd.DataFrame()\n",
      "lda_classifier_predictions_prob_df[lda_classifier_grid_search.classes_[0]] = lda_classifier_predictions_prob[:,0]\n",
      "lda_classifier_predictions_prob_df[lda_classifier_grid_search.classes_[1]] = lda_classifier_predictions_prob[:,1] \n",
      "lda_classifier_accuracy = accuracy_score(y_test, lda_classifier_predictions.iloc[:,0])\n",
      "lda_classifier_f1_score = f1_score(y_test, lda_classifier_predictions.iloc[:,0])\n",
      "lda_classifier_precision = precision_score(y_test, lda_classifier_predictions.iloc[:,0])\n",
      "lda_classifier_recall = recall_score(y_test, lda_classifier_predictions.iloc[:,0])\n",
      "lda_classifier_roc_auc_score = roc_auc_score(y_test, lda_classifier_predictions_prob_df[lda_classifier_grid_search.classes_[1]])\n",
      "lda_classifier_performance_metrics = [['lda_classifier','accuracy',lda_classifier_accuracy], \n",
      "                                  ['lda_classifier','f1_score',lda_classifier_f1_score],\n",
      "                                  ['lda_classifier','precision', lda_classifier_precision],\n",
      "                                  ['lda_classifier','recall', lda_classifier_recall],\n",
      "                                  ['lda_classifier','roc_auc_score', lda_classifier_roc_auc_score]]\n",
      "lda_classifier_performance_metrics = pd.DataFrame(lda_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, lda_classifier_predictions_prob_df[lda_classifier_grid_search.classes_[1]])\n",
      "lda_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "lda_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "lda_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "lda_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics LDA Classifier #####\n",
      "\n",
      "lda_classifier_performance_metrics\n",
      "lda_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for LDA Classifier #####\n",
      "\n",
      "##### Model Pipeline for QDA Classifier #####\n",
      "\n",
      "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "qda_classifier_param_grid = {\n",
      "\"qda_classifier__store_covariance\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "qda_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('qda_classifier', QuadraticDiscriminantAnalysis())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "qda_classifier_grid_search = GridSearchCV(estimator=qda_classifier_pipe, param_grid=qda_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "qda_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "qda_classifier_best_estimator = qda_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "qda_classifier_search_results = pd.DataFrame(qda_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "qda_classifier_predictions = pd.DataFrame(qda_classifier_best_estimator.predict(X_test))\n",
      "qda_classifier_predictions_prob = qda_classifier_best_estimator.predict_proba(X_test)\n",
      "qda_classifier_predictions_prob_df = pd.DataFrame()\n",
      "qda_classifier_predictions_prob_df[qda_classifier_grid_search.classes_[0]] = qda_classifier_predictions_prob[:,0]\n",
      "qda_classifier_predictions_prob_df[qda_classifier_grid_search.classes_[1]] = qda_classifier_predictions_prob[:,1] \n",
      "qda_classifier_accuracy = accuracy_score(y_test, qda_classifier_predictions.iloc[:,0])\n",
      "qda_classifier_f1_score = f1_score(y_test, qda_classifier_predictions.iloc[:,0])\n",
      "qda_classifier_precision = precision_score(y_test, qda_classifier_predictions.iloc[:,0])\n",
      "qda_classifier_recall = recall_score(y_test, qda_classifier_predictions.iloc[:,0])\n",
      "qda_classifier_roc_auc_score = roc_auc_score(y_test, qda_classifier_predictions_prob_df[qda_classifier_grid_search.classes_[1]])\n",
      "qda_classifier_performance_metrics = [['qda_classifier','accuracy',qda_classifier_accuracy], \n",
      "                                  ['qda_classifier','f1_score',qda_classifier_f1_score],\n",
      "                                  ['qda_classifier','precision', qda_classifier_precision],\n",
      "                                  ['qda_classifier','recall', qda_classifier_recall],\n",
      "                                  ['qda_classifier','roc_auc_score', qda_classifier_roc_auc_score]]\n",
      "qda_classifier_performance_metrics = pd.DataFrame(qda_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, qda_classifier_predictions_prob_df[qda_classifier_grid_search.classes_[1]])\n",
      "qda_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "qda_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "qda_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "qda_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics QDA Classifier #####\n",
      "\n",
      "qda_classifier_performance_metrics\n",
      "qda_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for QDA Classifier #####\n",
      "\n",
      "##### Model Pipeline for NuSVC Classifier #####\n",
      "\n",
      "from sklearn.svm import NuSVC\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "nusvc_classifier_param_grid = {\n",
      "\"nusvc_classifier__nu\": np.arange(0.1, 1.0, 0.1),\n",
      "\"nusvc_classifier__degree\": np.arange(2, 5, 1),\n",
      "\"nusvc_classifier__kernel\": ['poly'],\n",
      "\"nusvc_classifier__gamma\": ['scale'],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "nusvc_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('nusvc_classifier', NuSVC())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "nusvc_classifier_grid_search = GridSearchCV(estimator=nusvc_classifier_pipe, param_grid=nusvc_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "nusvc_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "nusvc_classifier_best_estimator = nusvc_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "nusvc_classifier_search_results = pd.DataFrame(nusvc_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "nusvc_classifier_predictions = pd.DataFrame(nusvc_classifier_best_estimator.predict(X_test))\n",
      "nusvc_classifier_predictions_prob = nusvc_classifier_best_estimator.predict_proba(X_test)\n",
      "nusvc_classifier_predictions_prob_df = pd.DataFrame()\n",
      "nusvc_classifier_predictions_prob_df[nusvc_classifier_grid_search.classes_[0]] = nusvc_classifier_predictions_prob[:,0]\n",
      "nusvc_classifier_predictions_prob_df[nusvc_classifier_grid_search.classes_[1]] = nusvc_classifier_predictions_prob[:,1] \n",
      "nusvc_classifier_accuracy = accuracy_score(y_test, nusvc_classifier_predictions.iloc[:,0])\n",
      "nusvc_classifier_f1_score = f1_score(y_test, nusvc_classifier_predictions.iloc[:,0])\n",
      "nusvc_classifier_precision = precision_score(y_test, nusvc_classifier_predictions.iloc[:,0])\n",
      "nusvc_classifier_recall = recall_score(y_test, nusvc_classifier_predictions.iloc[:,0])\n",
      "nusvc_classifier_roc_auc_score = roc_auc_score(y_test, nusvc_classifier_predictions_prob_df[nusvc_classifier_grid_search.classes_[1]])\n",
      "nusvc_classifier_performance_metrics = [['nusvc_classifier','accuracy',nusvc_classifier_accuracy], \n",
      "                                  ['nusvc_classifier','f1_score',nusvc_classifier_f1_score],\n",
      "                                  ['nusvc_classifier','precision', nusvc_classifier_precision],\n",
      "                                  ['nusvc_classifier','recall', nusvc_classifier_recall],\n",
      "                                  ['nusvc_classifier','roc_auc_score', nusvc_classifier_roc_auc_score]]\n",
      "nusvc_classifier_performance_metrics = pd.DataFrame(nusvc_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, nusvc_classifier_predictions_prob_df[nusvc_classifier_grid_search.classes_[1]])\n",
      "nusvc_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "nusvc_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "nusvc_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "nusvc_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics NuSVC Classifier #####\n",
      "\n",
      "nusvc_classifier_performance_metrics\n",
      "nusvc_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for NuSVC Classifier #####\n",
      "\n",
      "##### Model Pipeline for GaussianNB Classifier #####\n",
      "\n",
      "from naive_bayes import GaussianNB\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "gaussian_nb_classifier_param_grid = {\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "gaussian_nb_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('gaussian_nb_classifier', GaussianNB())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "gaussian_nb_classifier_grid_search = GridSearchCV(estimator=gaussian_nb_classifier_pipe, param_grid=gaussian_nb_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "gaussian_nb_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "gaussian_nb_classifier_best_estimator = gaussian_nb_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "gaussian_nb_classifier_search_results = pd.DataFrame(gaussian_nb_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "gaussian_nb_classifier_predictions = pd.DataFrame(gaussian_nb_classifier_best_estimator.predict(X_test))\n",
      "gaussian_nb_classifier_predictions_prob = gaussian_nb_classifier_best_estimator.predict_proba(X_test)\n",
      "gaussian_nb_classifier_predictions_prob_df = pd.DataFrame()\n",
      "gaussian_nb_classifier_predictions_prob_df[gaussian_nb_classifier_grid_search.classes_[0]] = gaussian_nb_classifier_predictions_prob[:,0]\n",
      "gaussian_nb_classifier_predictions_prob_df[gaussian_nb_classifier_grid_search.classes_[1]] = gaussian_nb_classifier_predictions_prob[:,1] \n",
      "gaussian_nb_classifier_accuracy = accuracy_score(y_test, gaussian_nb_classifier_predictions.iloc[:,0])\n",
      "gaussian_nb_classifier_f1_score = f1_score(y_test, gaussian_nb_classifier_predictions.iloc[:,0])\n",
      "gaussian_nb_classifier_precision = precision_score(y_test, gaussian_nb_classifier_predictions.iloc[:,0])\n",
      "gaussian_nb_classifier_recall = recall_score(y_test, gaussian_nb_classifier_predictions.iloc[:,0])\n",
      "gaussian_nb_classifier_roc_auc_score = roc_auc_score(y_test, gaussian_nb_classifier_predictions_prob_df[gaussian_nb_classifier_grid_search.classes_[1]])\n",
      "gaussian_nb_classifier_performance_metrics = [['gaussian_nb_classifier','accuracy',gaussian_nb_classifier_accuracy], \n",
      "                                  ['gaussian_nb_classifier','f1_score',gaussian_nb_classifier_f1_score],\n",
      "                                  ['gaussian_nb_classifier','precision', gaussian_nb_classifier_precision],\n",
      "                                  ['gaussian_nb_classifier','recall', gaussian_nb_classifier_recall],\n",
      "                                  ['gaussian_nb_classifier','roc_auc_score', gaussian_nb_classifier_roc_auc_score]]\n",
      "gaussian_nb_classifier_performance_metrics = pd.DataFrame(gaussian_nb_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, gaussian_nb_classifier_predictions_prob_df[gaussian_nb_classifier_grid_search.classes_[1]])\n",
      "gaussian_nb_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "gaussian_nb_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "gaussian_nb_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "gaussian_nb_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics GaussianNB Classifier #####\n",
      "\n",
      "gaussian_nb_classifier_performance_metrics\n",
      "gaussian_nb_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for GaussianNB Classifier #####\n",
      "\n",
      "##### Model Pipeline for MultinomialNB Classifier #####\n",
      "\n",
      "from naive_bayes import MultinomialNB\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "multinomial_nb_classifier_param_grid = {\n",
      "\"multinomial_nb_classifier__alpha\": np.arange(0.0, 1.0, 0.1),\n",
      "\"multinomial_nb_classifier__fit_prior\": [True],\n",
      "\"multinomial_nb_classifier__force_alpha\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "multinomial_nb_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('multinomial_nb_classifier', MultinomialNB())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "multinomial_nb_classifier_grid_search = GridSearchCV(estimator=multinomial_nb_classifier_pipe, param_grid=multinomial_nb_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "multinomial_nb_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "multinomial_nb_classifier_best_estimator = multinomial_nb_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "multinomial_nb_classifier_search_results = pd.DataFrame(multinomial_nb_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "multinomial_nb_classifier_predictions = pd.DataFrame(multinomial_nb_classifier_best_estimator.predict(X_test))\n",
      "multinomial_nb_classifier_predictions_prob = multinomial_nb_classifier_best_estimator.predict_proba(X_test)\n",
      "multinomial_nb_classifier_predictions_prob_df = pd.DataFrame()\n",
      "multinomial_nb_classifier_predictions_prob_df[multinomial_nb_classifier_grid_search.classes_[0]] = multinomial_nb_classifier_predictions_prob[:,0]\n",
      "multinomial_nb_classifier_predictions_prob_df[multinomial_nb_classifier_grid_search.classes_[1]] = multinomial_nb_classifier_predictions_prob[:,1] \n",
      "multinomial_nb_classifier_accuracy = accuracy_score(y_test, multinomial_nb_classifier_predictions.iloc[:,0])\n",
      "multinomial_nb_classifier_f1_score = f1_score(y_test, multinomial_nb_classifier_predictions.iloc[:,0])\n",
      "multinomial_nb_classifier_precision = precision_score(y_test, multinomial_nb_classifier_predictions.iloc[:,0])\n",
      "multinomial_nb_classifier_recall = recall_score(y_test, multinomial_nb_classifier_predictions.iloc[:,0])\n",
      "multinomial_nb_classifier_roc_auc_score = roc_auc_score(y_test, multinomial_nb_classifier_predictions_prob_df[multinomial_nb_classifier_grid_search.classes_[1]])\n",
      "multinomial_nb_classifier_performance_metrics = [['multinomial_nb_classifier','accuracy',multinomial_nb_classifier_accuracy], \n",
      "                                  ['multinomial_nb_classifier','f1_score',multinomial_nb_classifier_f1_score],\n",
      "                                  ['multinomial_nb_classifier','precision', multinomial_nb_classifier_precision],\n",
      "                                  ['multinomial_nb_classifier','recall', multinomial_nb_classifier_recall],\n",
      "                                  ['multinomial_nb_classifier','roc_auc_score', multinomial_nb_classifier_roc_auc_score]]\n",
      "multinomial_nb_classifier_performance_metrics = pd.DataFrame(multinomial_nb_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, multinomial_nb_classifier_predictions_prob_df[multinomial_nb_classifier_grid_search.classes_[1]])\n",
      "multinomial_nb_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "multinomial_nb_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "multinomial_nb_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "multinomial_nb_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics MultinomialNB Classifier #####\n",
      "\n",
      "multinomial_nb_classifier_performance_metrics\n",
      "multinomial_nb_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for MultinomialNB Classifier #####\n",
      "\n",
      "##### Model Pipeline for ComplementNB Classifier #####\n",
      "\n",
      "from naive_bayes import ComplementNB\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "complement_nb_classifier_param_grid = {\n",
      "\"complement_nb_classifier__alpha\": np.arange(0.0, 1.0, 0.1),\n",
      "\"complement_nb_classifier__fit_prior\": [True],\n",
      "\"complement_nb_classifier__force_alpha\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "complement_nb_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('complement_nb_classifier', ComplementNB())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "complement_nb_classifier_grid_search = GridSearchCV(estimator=complement_nb_classifier_pipe, param_grid=complement_nb_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "complement_nb_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "complement_nb_classifier_best_estimator = complement_nb_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "complement_nb_classifier_search_results = pd.DataFrame(complement_nb_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "complement_nb_classifier_predictions = pd.DataFrame(complement_nb_classifier_best_estimator.predict(X_test))\n",
      "complement_nb_classifier_predictions_prob = complement_nb_classifier_best_estimator.predict_proba(X_test)\n",
      "complement_nb_classifier_predictions_prob_df = pd.DataFrame()\n",
      "complement_nb_classifier_predictions_prob_df[complement_nb_classifier_grid_search.classes_[0]] = complement_nb_classifier_predictions_prob[:,0]\n",
      "complement_nb_classifier_predictions_prob_df[complement_nb_classifier_grid_search.classes_[1]] = complement_nb_classifier_predictions_prob[:,1] \n",
      "complement_nb_classifier_accuracy = accuracy_score(y_test, complement_nb_classifier_predictions.iloc[:,0])\n",
      "complement_nb_classifier_f1_score = f1_score(y_test, complement_nb_classifier_predictions.iloc[:,0])\n",
      "complement_nb_classifier_precision = precision_score(y_test, complement_nb_classifier_predictions.iloc[:,0])\n",
      "complement_nb_classifier_recall = recall_score(y_test, complement_nb_classifier_predictions.iloc[:,0])\n",
      "complement_nb_classifier_roc_auc_score = roc_auc_score(y_test, complement_nb_classifier_predictions_prob_df[complement_nb_classifier_grid_search.classes_[1]])\n",
      "complement_nb_classifier_performance_metrics = [['complement_nb_classifier','accuracy',complement_nb_classifier_accuracy], \n",
      "                                  ['complement_nb_classifier','f1_score',complement_nb_classifier_f1_score],\n",
      "                                  ['complement_nb_classifier','precision', complement_nb_classifier_precision],\n",
      "                                  ['complement_nb_classifier','recall', complement_nb_classifier_recall],\n",
      "                                  ['complement_nb_classifier','roc_auc_score', complement_nb_classifier_roc_auc_score]]\n",
      "complement_nb_classifier_performance_metrics = pd.DataFrame(complement_nb_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, complement_nb_classifier_predictions_prob_df[complement_nb_classifier_grid_search.classes_[1]])\n",
      "complement_nb_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "complement_nb_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "complement_nb_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "complement_nb_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics ComplementNB Classifier #####\n",
      "\n",
      "complement_nb_classifier_performance_metrics\n",
      "complement_nb_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for ComplementNB Classifier #####\n",
      "\n",
      "##### Model Pipeline for BernoulliNB Classifier #####\n",
      "\n",
      "from naive_bayes import BernoulliNB\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "bernoulli_nb_classifier_param_grid = {\n",
      "\"bernoulli_nb_classifier__alpha\": np.arange(0.0, 1.0, 0.1),\n",
      "\"bernoulli_nb_classifier__fit_prior\": [True],\n",
      "\"bernoulli_nb_classifier__force_alpha\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "bernoulli_nb_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('bernoulli_nb_classifier', BernoulliNB())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "bernoulli_nb_classifier_grid_search = GridSearchCV(estimator=bernoulli_nb_classifier_pipe, param_grid=bernoulli_nb_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "bernoulli_nb_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "bernoulli_nb_classifier_best_estimator = bernoulli_nb_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "bernoulli_nb_classifier_search_results = pd.DataFrame(bernoulli_nb_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "bernoulli_nb_classifier_predictions = pd.DataFrame(bernoulli_nb_classifier_best_estimator.predict(X_test))\n",
      "bernoulli_nb_classifier_predictions_prob = bernoulli_nb_classifier_best_estimator.predict_proba(X_test)\n",
      "bernoulli_nb_classifier_predictions_prob_df = pd.DataFrame()\n",
      "bernoulli_nb_classifier_predictions_prob_df[bernoulli_nb_classifier_grid_search.classes_[0]] = bernoulli_nb_classifier_predictions_prob[:,0]\n",
      "bernoulli_nb_classifier_predictions_prob_df[bernoulli_nb_classifier_grid_search.classes_[1]] = bernoulli_nb_classifier_predictions_prob[:,1] \n",
      "bernoulli_nb_classifier_accuracy = accuracy_score(y_test, bernoulli_nb_classifier_predictions.iloc[:,0])\n",
      "bernoulli_nb_classifier_f1_score = f1_score(y_test, bernoulli_nb_classifier_predictions.iloc[:,0])\n",
      "bernoulli_nb_classifier_precision = precision_score(y_test, bernoulli_nb_classifier_predictions.iloc[:,0])\n",
      "bernoulli_nb_classifier_recall = recall_score(y_test, bernoulli_nb_classifier_predictions.iloc[:,0])\n",
      "bernoulli_nb_classifier_roc_auc_score = roc_auc_score(y_test, bernoulli_nb_classifier_predictions_prob_df[bernoulli_nb_classifier_grid_search.classes_[1]])\n",
      "bernoulli_nb_classifier_performance_metrics = [['bernoulli_nb_classifier','accuracy',bernoulli_nb_classifier_accuracy], \n",
      "                                  ['bernoulli_nb_classifier','f1_score',bernoulli_nb_classifier_f1_score],\n",
      "                                  ['bernoulli_nb_classifier','precision', bernoulli_nb_classifier_precision],\n",
      "                                  ['bernoulli_nb_classifier','recall', bernoulli_nb_classifier_recall],\n",
      "                                  ['bernoulli_nb_classifier','roc_auc_score', bernoulli_nb_classifier_roc_auc_score]]\n",
      "bernoulli_nb_classifier_performance_metrics = pd.DataFrame(bernoulli_nb_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, bernoulli_nb_classifier_predictions_prob_df[bernoulli_nb_classifier_grid_search.classes_[1]])\n",
      "bernoulli_nb_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "bernoulli_nb_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "bernoulli_nb_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "bernoulli_nb_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics BernoulliNB Classifier #####\n",
      "\n",
      "bernoulli_nb_classifier_performance_metrics\n",
      "bernoulli_nb_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for BernoulliNB Classifier #####\n",
      "\n",
      "##### Model Pipeline for CategoricalNB Classifier #####\n",
      "\n",
      "from naive_bayes import CategoricalNB\n",
      "from sklearn.metrics import accuracy_score,make_scorer,f1_score,precision_score,recall_score,roc_auc_score,roc_curve,auc\n",
      "import plotly.express as px\n",
      "bernoulli_nb_classifier_param_grid = {\n",
      "\"bernoulli_nb_classifier__alpha\": np.arange(0.0, 1.0, 0.1),\n",
      "\"bernoulli_nb_classifier__fit_prior\": [True],\n",
      "\"bernoulli_nb_classifier__force_alpha\": [True],\n",
      "}\n",
      "\n",
      "\n",
      "# Create the pipeline\n",
      "bernoulli_nb_classifier_pipe = Pipeline([\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('bernoulli_nb_classifier', CategoricalNB())\n",
      "])\n",
      "\n",
      "# Create the grid search\n",
      "bernoulli_nb_classifier_grid_search = GridSearchCV(estimator=bernoulli_nb_classifier_pipe, param_grid=bernoulli_nb_classifier_param_grid, cv=5, scoring=make_scorer(accuracy_score), verbose=1)\n",
      "bernoulli_nb_classifier_grid_search.fit(X_train, y_train)\n",
      "\n",
      "# Get the best hyperparameters\n",
      "bernoulli_nb_classifier_best_estimator = bernoulli_nb_classifier_grid_search.best_estimator_\n",
      "\n",
      "# Store results as a dataframe  \n",
      "bernoulli_nb_classifier_search_results = pd.DataFrame(bernoulli_nb_classifier_grid_search.cv_results_)\n",
      "\n",
      "# Model metrics\n",
      "\n",
      "bernoulli_nb_classifier_predictions = pd.DataFrame(bernoulli_nb_classifier_best_estimator.predict(X_test))\n",
      "bernoulli_nb_classifier_predictions_prob = bernoulli_nb_classifier_best_estimator.predict_proba(X_test)\n",
      "bernoulli_nb_classifier_predictions_prob_df = pd.DataFrame()\n",
      "bernoulli_nb_classifier_predictions_prob_df[bernoulli_nb_classifier_grid_search.classes_[0]] = bernoulli_nb_classifier_predictions_prob[:,0]\n",
      "bernoulli_nb_classifier_predictions_prob_df[bernoulli_nb_classifier_grid_search.classes_[1]] = bernoulli_nb_classifier_predictions_prob[:,1] \n",
      "bernoulli_nb_classifier_accuracy = accuracy_score(y_test, bernoulli_nb_classifier_predictions.iloc[:,0])\n",
      "bernoulli_nb_classifier_f1_score = f1_score(y_test, bernoulli_nb_classifier_predictions.iloc[:,0])\n",
      "bernoulli_nb_classifier_precision = precision_score(y_test, bernoulli_nb_classifier_predictions.iloc[:,0])\n",
      "bernoulli_nb_classifier_recall = recall_score(y_test, bernoulli_nb_classifier_predictions.iloc[:,0])\n",
      "bernoulli_nb_classifier_roc_auc_score = roc_auc_score(y_test, bernoulli_nb_classifier_predictions_prob_df[bernoulli_nb_classifier_grid_search.classes_[1]])\n",
      "bernoulli_nb_classifier_performance_metrics = [['bernoulli_nb_classifier','accuracy',bernoulli_nb_classifier_accuracy], \n",
      "                                  ['bernoulli_nb_classifier','f1_score',bernoulli_nb_classifier_f1_score],\n",
      "                                  ['bernoulli_nb_classifier','precision', bernoulli_nb_classifier_precision],\n",
      "                                  ['bernoulli_nb_classifier','recall', bernoulli_nb_classifier_recall],\n",
      "                                  ['bernoulli_nb_classifier','roc_auc_score', bernoulli_nb_classifier_roc_auc_score]]\n",
      "bernoulli_nb_classifier_performance_metrics = pd.DataFrame(bernoulli_nb_classifier_performance_metrics, columns=['model','metric', 'value'])\n",
      "fpr, tpr, thresholds = roc_curve(y_test, bernoulli_nb_classifier_predictions_prob_df[bernoulli_nb_classifier_grid_search.classes_[1]])\n",
      "bernoulli_nb_classifier_roc_auc_plot = px.area(\n",
      "    x=fpr, y=tpr,\n",
      "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
      "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
      "    width=700, height=500\n",
      ")\n",
      "bernoulli_nb_classifier_roc_auc_plot.add_shape(\n",
      "    type='line', line=dict(dash='dash'),\n",
      "    x0=0, x1=1, y0=0, y1=1\n",
      ")\n",
      "bernoulli_nb_classifier_roc_auc_plot.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
      "bernoulli_nb_classifier_roc_auc_plot.update_xaxes(constrain='domain')\n",
      "\n",
      "\n",
      "##### Model Metrics CategoricalNB Classifier #####\n",
      "\n",
      "bernoulli_nb_classifier_performance_metrics\n",
      "bernoulli_nb_classifier_roc_auc_plot.show()\n",
      "\n",
      "##### End of Model Pipeline for CategoricalNB Classifier #####\n"
     ]
    }
   ],
   "source": [
    "clf_pypelines_all.get_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model files saved to ./code_output/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_all.code_to_file(path='./code_output/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification - selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf_pypelines_sel = SupervisedPipeline(data = \"titanic\",target = 'Survived'\n",
    "                            , model_type = 'classification'\n",
    "                            , models = ['Logistic Regression','Random Forest']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'numerical': [{'name': 'C',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'penalty',\n",
       "    'selected': ['l2'],\n",
       "    'values': ['l2', 'elasticnet', 'none']}]},\n",
       " 'Random Forest': {'numerical': [{'name': 'n_estimators',\n",
       "    'min': 10,\n",
       "    'max': 100,\n",
       "    'step': 20},\n",
       "   {'name': 'max_depth', 'min': 2, 'max': 10, 'step': 2},\n",
       "   {'name': 'min_samples_split', 'min': 0.5, 'max': 1, 'step': 0.1},\n",
       "   {'name': 'min_samples_leaf', 'min': 1, 'max': 10, 'step': 2}],\n",
       "  'categorical': [{'name': 'criterion',\n",
       "    'selected': ['gini'],\n",
       "    'values': ['gini', 'entropy']},\n",
       "   {'name': 'max_features',\n",
       "    'selected': ['auto'],\n",
       "    'values': ['auto', 'sqrt', 'log2']},\n",
       "   {'name': 'bootstrap', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'oob_score', 'selected': [True], 'values': [True, False]},\n",
       "   {'name': 'warm_start', 'selected': [False], 'values': [True, False]},\n",
       "   {'name': 'class_weight',\n",
       "    'selected': ['balanced'],\n",
       "    'values': ['balanced', 'balanced_subsample']}]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_sel.get_hyperparameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Logistic Regression', 'Random Forest']\n"
     ]
    }
   ],
   "source": [
    "clf_pypelines_sel.model_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pypelines_sel.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model files saved to ./code_output/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_sel.code_to_file(path='./code_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'numerical': [{'name': 'C',\n",
       "    'min': 0.1,\n",
       "    'max': 1,\n",
       "    'step': 0.1}],\n",
       "  'categorical': [{'name': 'penalty',\n",
       "    'selected': ['l2'],\n",
       "    'values': ['l2', 'elasticnet', 'none']}]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pypelines_sel.grid_search_for_model('Logistic Regression')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
