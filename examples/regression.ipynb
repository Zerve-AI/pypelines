{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the respository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Zerve-AI/pypelines.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing the pypeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder = ''\n",
    "os.chdir(f'{folder}/pypelines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIST OF MODELS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS FOR REGRESSION PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypelines.supervised_pipeline as pipe\n",
    "from pypelines import utils\n",
    "\n",
    "\n",
    "utils.list_supported_models(model_type='regression')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypelines.supervised_pipeline as pipe\n",
    "from pypelines import utils\n",
    "import pandas as pd\n",
    "housing = pd.read_csv(\"pypelines/datasets/regression/housing.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SINGLE REGRESSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Load and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reg_pypelines_all = pipe.SupervisedPipeline(data = housing,target = 'median_house_value',predictions_data=housing\n",
    "                            , model_type = 'regression'\n",
    "                            , models = ['Random Forest Regression']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_all.get_hyperparameters()\n",
    "reg_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_pypelines_all.model_grid_search_settings(model_name='Random Forest Regression'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = {\n",
    "    'numerical': [\n",
    "        {'search': True, 'name': 'n_estimators', 'min': 50, 'max': 150, 'step': 35},\n",
    "        {'search': True, 'name': 'max_depth', 'min': 5, 'max': 50, 'step': 10},\n",
    "        {'search': True, 'name': 'min_samples_leaf', 'min': 1, 'max': 50, 'step': 20}\n",
    "    ],\n",
    "    'categorical': [\n",
    "        {'search': False, 'name': 'bootstrap', 'selected': [True], 'values': [True, False]},\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(reg_pypelines_all.set_model_grid_search_settings(hyperparam_dict=hyperparameter, model_name='Random Forest Regression'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tranining code generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training code for single regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# target dataframe: housing\n",
    "target = \"median_house_value\"\n",
    "features = list(housing.columns.drop(\"median_house_value\"))\n",
    "feature_df = housing[features]\n",
    "\n",
    "prediction_df = housing\n",
    "\n",
    "# get numerical and categorical columns\n",
    "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
    "housing[bool_cols] = feature_df[bool_cols].astype(int)\n",
    "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
    "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
    "\n",
    "\n",
    "sample_size = np.min([10000, housing.shape[0]])\n",
    "unique_theshold = np.min([100, sample_size/10])\n",
    "\n",
    "# check categorical columns for high cardinality and make it text column\n",
    "for col in categorical_cols:\n",
    "    if housing[col].sample(sample_size).nunique() > unique_theshold:\n",
    "        text_cols.append(col)\n",
    "        categorical_cols.remove(col)\n",
    "        \n",
    "\n",
    "# check text columns for low cardinality and make it categorical columns\n",
    "for col in text_cols:\n",
    "    if housing[col].sample(sample_size).nunique() < unique_theshold:\n",
    "        categorical_cols.append(col)\n",
    "        text_cols.remove(col)\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)\n",
    "print(text_cols)\n",
    "\n",
    "# define numeric transformer steps\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"scaler\", MinMaxScaler())]\n",
    ")\n",
    "\n",
    "# define categorical transformer steps\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define text transformer steps\n",
    "text_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('text', TfidfVectorizer())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create the preprocessing pipelines for both numeric and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', numeric_transformer , numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "        *[(f'text_{t_col}', text_transformer, t_col) for t_col in text_cols]]\n",
    ")\n",
    "\n",
    "# train test split\n",
    "X = housing[features]\n",
    "y = housing[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_comparison_list = []\n",
    "\n",
    "##### End of Data Processing Pipeline #####\n",
    "\n",
    "\n",
    "##### Model Pipeline for Random Forest Regression #####\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "random_forest_regression_param_grid = {\n",
    "\"random_forest_regression__n_estimators\": np.arange(50, 150, 35),\n",
    "\"random_forest_regression__max_depth\": np.arange(5, 50, 10),\n",
    "\"random_forest_regression__min_samples_leaf\": np.arange(1, 50, 20),\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "random_forest_regression_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('random_forest_regression', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "random_forest_regression_grid_search = GridSearchCV(estimator=random_forest_regression_pipe, param_grid=random_forest_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "random_forest_regression_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "random_forest_regression_best_estimator = random_forest_regression_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "random_forest_regression_search_results = pd.DataFrame(random_forest_regression_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "random_forest_regression_predictions = random_forest_regression_best_estimator.predict(X_test)\n",
    "random_forest_regression_predictions_df = pd.DataFrame(random_forest_regression_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "random_forest_regression_r2_score = r2_score(y_test, random_forest_regression_predictions_df.iloc[:,0])\n",
    "random_forest_regression_mean_squared_error = mean_squared_error(y_test, random_forest_regression_predictions_df.iloc[:,0])\n",
    "random_forest_regression_explained_variance_score = explained_variance_score(y_test, random_forest_regression_predictions_df.iloc[:,0])\n",
    "random_forest_regression_performance_metrics = [['random_forest_regression','r2_score', random_forest_regression_r2_score], \n",
    "                                  ['random_forest_regression','mean_squared_error',random_forest_regression_mean_squared_error],\n",
    "                                  ['random_forest_regression','explained_variance_score', random_forest_regression_explained_variance_score]]\n",
    "random_forest_regression_performance_metrics = pd.DataFrame(random_forest_regression_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "random_forest_regression_actual_predicted_plot, random_forest_regression_actual_predicted_plot_ax = plt.subplots()\n",
    "random_forest_regression_actual_predicted_plot = random_forest_regression_actual_predicted_plot_ax.scatter(x=y_test, y=random_forest_regression_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "random_forest_regression_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "random_forest_regression_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "random_forest_regression_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "random_forest_regression_actual_predicted_plot_ax.set_title(f'random_forest_regression Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "random_forest_regression_deciles = np.percentile(random_forest_regression_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "random_forest_regression_mean_actual = []\n",
    "random_forest_regression_mean_predicted = []\n",
    "for i in range(len(random_forest_regression_deciles) - 1):\n",
    "    mask = (random_forest_regression_predictions >= random_forest_regression_deciles[i]) & (random_forest_regression_predictions < random_forest_regression_deciles[i + 1])\n",
    "    random_forest_regression_mean_actual.append(np.mean(y_test[mask]))\n",
    "    random_forest_regression_mean_predicted.append(np.mean(random_forest_regression_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "random_forest_regression_lift_plot, random_forest_regression_lift_plot_ax = plt.subplots()\n",
    "random_forest_regression_lift_plot_ax.bar(np.arange(len(random_forest_regression_mean_actual)), random_forest_regression_mean_actual, label='Actual')\n",
    "random_forest_regression_lift_plot_ax.plot(np.arange(len(random_forest_regression_mean_predicted)), random_forest_regression_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "random_forest_regression_lift_plot_ax.set_xlabel('Deciles')\n",
    "random_forest_regression_lift_plot_ax.set_ylabel('Mean')\n",
    "random_forest_regression_lift_plot_ax.set_title(f'random_forest_regression Decile Analysis Chart')\n",
    "random_forest_regression_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(random_forest_regression_performance_metrics)##### End of Model Pipeline for Random Forest Regression #####\n",
    "##### Model Comparison #####\n",
    "\n",
    "table = pd.concat(model_comparison_list)\n",
    "table = table.sort_values(by=['value'], ascending=False)\n",
    "table = table[table['metric'] == 'r2_score']\n",
    "print(table)\n",
    "print(f\"The best model is {table['model'].iloc[0]} with {table['value'].iloc[0]} as {table['metric'].iloc[0]}\")\n",
    "\n",
    "\n",
    "# Predict test data using the best model\n",
    "test_predictions = eval(table['model'].iloc[0]+\"_best_estimator\").predict(prediction_df)\n",
    "print('Predictions from best model are stored in test_predictions')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg_pypelines_all = pipe.SupervisedPipeline(data = housing,target = 'median_house_value',predictions_data=housing\n",
    "                            , model_type = 'regression'\n",
    "                            , models = ['Linear Regression', 'AdaBoost Regression']\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_all.get_hyperparameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tranining code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training code for multiple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# target dataframe: housing\n",
    "target = \"median_house_value\"\n",
    "features = list(housing.columns.drop(\"median_house_value\"))\n",
    "feature_df = housing[features]\n",
    "\n",
    "prediction_df = housing\n",
    "\n",
    "# get numerical and categorical columns\n",
    "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
    "housing[bool_cols] = feature_df[bool_cols].astype(int)\n",
    "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
    "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
    "\n",
    "\n",
    "sample_size = np.min([10000, housing.shape[0]])\n",
    "unique_theshold = np.min([100, sample_size/10])\n",
    "\n",
    "# check categorical columns for high cardinality and make it text column\n",
    "for col in categorical_cols:\n",
    "    if housing[col].sample(sample_size).nunique() > unique_theshold:\n",
    "        text_cols.append(col)\n",
    "        categorical_cols.remove(col)\n",
    "        \n",
    "\n",
    "# check text columns for low cardinality and make it categorical columns\n",
    "for col in text_cols:\n",
    "    if housing[col].sample(sample_size).nunique() < unique_theshold:\n",
    "        categorical_cols.append(col)\n",
    "        text_cols.remove(col)\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)\n",
    "print(text_cols)\n",
    "\n",
    "# define numeric transformer steps\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"scaler\", MinMaxScaler())]\n",
    ")\n",
    "\n",
    "# define categorical transformer steps\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define text transformer steps\n",
    "text_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('text', TfidfVectorizer())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create the preprocessing pipelines for both numeric and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', numeric_transformer , numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "        *[(f'text_{t_col}', text_transformer, t_col) for t_col in text_cols]]\n",
    ")\n",
    "\n",
    "# train test split\n",
    "X = housing[features]\n",
    "y = housing[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_comparison_list = []\n",
    "\n",
    "##### End of Data Processing Pipeline #####\n",
    "\n",
    "\n",
    "##### Model Pipeline for Linear Regression #####\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "lin_reg_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "lin_reg_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lin_reg', LinearRegression())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "lin_reg_grid_search = GridSearchCV(estimator=lin_reg_pipe, param_grid=lin_reg_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "lin_reg_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "lin_reg_best_estimator = lin_reg_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "lin_reg_search_results = pd.DataFrame(lin_reg_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "lin_reg_predictions = lin_reg_best_estimator.predict(X_test)\n",
    "lin_reg_predictions_df = pd.DataFrame(lin_reg_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "lin_reg_r2_score = r2_score(y_test, lin_reg_predictions_df.iloc[:,0])\n",
    "lin_reg_mean_squared_error = mean_squared_error(y_test, lin_reg_predictions_df.iloc[:,0])\n",
    "lin_reg_explained_variance_score = explained_variance_score(y_test, lin_reg_predictions_df.iloc[:,0])\n",
    "lin_reg_performance_metrics = [['lin_reg','r2_score', lin_reg_r2_score], \n",
    "                                  ['lin_reg','mean_squared_error',lin_reg_mean_squared_error],\n",
    "                                  ['lin_reg','explained_variance_score', lin_reg_explained_variance_score]]\n",
    "lin_reg_performance_metrics = pd.DataFrame(lin_reg_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "lin_reg_actual_predicted_plot, lin_reg_actual_predicted_plot_ax = plt.subplots()\n",
    "lin_reg_actual_predicted_plot = lin_reg_actual_predicted_plot_ax.scatter(x=y_test, y=lin_reg_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "lin_reg_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "lin_reg_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "lin_reg_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "lin_reg_actual_predicted_plot_ax.set_title(f'lin_reg Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "lin_reg_deciles = np.percentile(lin_reg_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "lin_reg_mean_actual = []\n",
    "lin_reg_mean_predicted = []\n",
    "for i in range(len(lin_reg_deciles) - 1):\n",
    "    mask = (lin_reg_predictions >= lin_reg_deciles[i]) & (lin_reg_predictions < lin_reg_deciles[i + 1])\n",
    "    lin_reg_mean_actual.append(np.mean(y_test[mask]))\n",
    "    lin_reg_mean_predicted.append(np.mean(lin_reg_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "lin_reg_lift_plot, lin_reg_lift_plot_ax = plt.subplots()\n",
    "lin_reg_lift_plot_ax.bar(np.arange(len(lin_reg_mean_actual)), lin_reg_mean_actual, label='Actual')\n",
    "lin_reg_lift_plot_ax.plot(np.arange(len(lin_reg_mean_predicted)), lin_reg_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "lin_reg_lift_plot_ax.set_xlabel('Deciles')\n",
    "lin_reg_lift_plot_ax.set_ylabel('Mean')\n",
    "lin_reg_lift_plot_ax.set_title(f'lin_reg Decile Analysis Chart')\n",
    "lin_reg_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(lin_reg_performance_metrics)##### End of Model Pipeline for Linear Regression #####\n",
    "##### Model Pipeline for AdaBoost Regression #####\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor \n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "adaboost_regression_param_grid = {\n",
    "\"adaboost_regression__n_estimators\": np.arange(10, 100, 20),\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "adaboost_regression_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('adaboost_regression', AdaBoostRegressor())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "adaboost_regression_grid_search = GridSearchCV(estimator=adaboost_regression_pipe, param_grid=adaboost_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "adaboost_regression_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "adaboost_regression_best_estimator = adaboost_regression_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "adaboost_regression_search_results = pd.DataFrame(adaboost_regression_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "adaboost_regression_predictions = adaboost_regression_best_estimator.predict(X_test)\n",
    "adaboost_regression_predictions_df = pd.DataFrame(adaboost_regression_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "adaboost_regression_r2_score = r2_score(y_test, adaboost_regression_predictions_df.iloc[:,0])\n",
    "adaboost_regression_mean_squared_error = mean_squared_error(y_test, adaboost_regression_predictions_df.iloc[:,0])\n",
    "adaboost_regression_explained_variance_score = explained_variance_score(y_test, adaboost_regression_predictions_df.iloc[:,0])\n",
    "adaboost_regression_performance_metrics = [['adaboost_regression','r2_score', adaboost_regression_r2_score], \n",
    "                                  ['adaboost_regression','mean_squared_error',adaboost_regression_mean_squared_error],\n",
    "                                  ['adaboost_regression','explained_variance_score', adaboost_regression_explained_variance_score]]\n",
    "adaboost_regression_performance_metrics = pd.DataFrame(adaboost_regression_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "adaboost_regression_actual_predicted_plot, adaboost_regression_actual_predicted_plot_ax = plt.subplots()\n",
    "adaboost_regression_actual_predicted_plot = adaboost_regression_actual_predicted_plot_ax.scatter(x=y_test, y=adaboost_regression_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "adaboost_regression_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "adaboost_regression_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "adaboost_regression_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "adaboost_regression_actual_predicted_plot_ax.set_title(f'adaboost_regression Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "adaboost_regression_deciles = np.percentile(adaboost_regression_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "adaboost_regression_mean_actual = []\n",
    "adaboost_regression_mean_predicted = []\n",
    "for i in range(len(adaboost_regression_deciles) - 1):\n",
    "    mask = (adaboost_regression_predictions >= adaboost_regression_deciles[i]) & (adaboost_regression_predictions < adaboost_regression_deciles[i + 1])\n",
    "    adaboost_regression_mean_actual.append(np.mean(y_test[mask]))\n",
    "    adaboost_regression_mean_predicted.append(np.mean(adaboost_regression_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "adaboost_regression_lift_plot, adaboost_regression_lift_plot_ax = plt.subplots()\n",
    "adaboost_regression_lift_plot_ax.bar(np.arange(len(adaboost_regression_mean_actual)), adaboost_regression_mean_actual, label='Actual')\n",
    "adaboost_regression_lift_plot_ax.plot(np.arange(len(adaboost_regression_mean_predicted)), adaboost_regression_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "adaboost_regression_lift_plot_ax.set_xlabel('Deciles')\n",
    "adaboost_regression_lift_plot_ax.set_ylabel('Mean')\n",
    "adaboost_regression_lift_plot_ax.set_title(f'adaboost_regression Decile Analysis Chart')\n",
    "adaboost_regression_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(adaboost_regression_performance_metrics)##### End of Model Pipeline for AdaBoost Regression #####\n",
    "##### Model Comparison #####\n",
    "\n",
    "table = pd.concat(model_comparison_list)\n",
    "table = table.sort_values(by=['value'], ascending=False)\n",
    "table = table[table['metric'] == 'r2_score']\n",
    "print(table)\n",
    "print(f\"The best model is {table['model'].iloc[0]} with {table['value'].iloc[0]} as {table['metric'].iloc[0]}\")\n",
    "\n",
    "\n",
    "# Predict test data using the best model\n",
    "test_predictions = eval(table['model'].iloc[0]+\"_best_estimator\").predict(prediction_df)\n",
    "print('Predictions from best model are stored in test_predictions')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION MODEL - DEFAULT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_all = pipe.SupervisedPipeline(data = housing,target = 'median_house_value',predictions_data=housing\n",
    "                            , model_type = 'regression'\n",
    "                            , nfolds = 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_all.get_hyperparameters()\n",
    "reg_pypelines_all.model_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tranining code generation for regression default run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# target dataframe: housing\n",
    "target = \"median_house_value\"\n",
    "features = list(housing.columns.drop(\"median_house_value\"))\n",
    "feature_df = housing[features]\n",
    "\n",
    "prediction_df = housing\n",
    "\n",
    "# get numerical and categorical columns\n",
    "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
    "housing[bool_cols] = feature_df[bool_cols].astype(int)\n",
    "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
    "text_cols = feature_df.select_dtypes(include=['string']).columns.tolist()\n",
    "\n",
    "\n",
    "sample_size = np.min([10000, housing.shape[0]])\n",
    "unique_theshold = np.min([100, sample_size/10])\n",
    "\n",
    "# check categorical columns for high cardinality and make it text column\n",
    "for col in categorical_cols:\n",
    "    if housing[col].sample(sample_size).nunique() > unique_theshold:\n",
    "        text_cols.append(col)\n",
    "        categorical_cols.remove(col)\n",
    "        \n",
    "\n",
    "# check text columns for low cardinality and make it categorical columns\n",
    "for col in text_cols:\n",
    "    if housing[col].sample(sample_size).nunique() < unique_theshold:\n",
    "        categorical_cols.append(col)\n",
    "        text_cols.remove(col)\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)\n",
    "print(text_cols)\n",
    "\n",
    "# define numeric transformer steps\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"scaler\", MinMaxScaler())]\n",
    ")\n",
    "\n",
    "# define categorical transformer steps\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define text transformer steps\n",
    "text_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('text', TfidfVectorizer())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create the preprocessing pipelines for both numeric and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', numeric_transformer , numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "        *[(f'text_{t_col}', text_transformer, t_col) for t_col in text_cols]]\n",
    ")\n",
    "\n",
    "# train test split\n",
    "X = housing[features]\n",
    "y = housing[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_comparison_list = []\n",
    "\n",
    "##### End of Data Processing Pipeline #####\n",
    "\n",
    "\n",
    "##### Model Pipeline for Elastic Net Regression #####\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "elastic_net_regression_param_grid = {\n",
    "\"elastic_net_regression__alpha\": np.arange(0.1, 2.0, 0.5),\n",
    "\"elastic_net_regression__l1_ratio\": np.arange(0.1, 1.0, 0.3),\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "elastic_net_regression_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('elastic_net_regression', ElasticNet())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "elastic_net_regression_grid_search = GridSearchCV(estimator=elastic_net_regression_pipe, param_grid=elastic_net_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "elastic_net_regression_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "elastic_net_regression_best_estimator = elastic_net_regression_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "elastic_net_regression_search_results = pd.DataFrame(elastic_net_regression_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "elastic_net_regression_predictions = elastic_net_regression_best_estimator.predict(X_test)\n",
    "elastic_net_regression_predictions_df = pd.DataFrame(elastic_net_regression_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "elastic_net_regression_r2_score = r2_score(y_test, elastic_net_regression_predictions_df.iloc[:,0])\n",
    "elastic_net_regression_mean_squared_error = mean_squared_error(y_test, elastic_net_regression_predictions_df.iloc[:,0])\n",
    "elastic_net_regression_explained_variance_score = explained_variance_score(y_test, elastic_net_regression_predictions_df.iloc[:,0])\n",
    "elastic_net_regression_performance_metrics = [['elastic_net_regression','r2_score', elastic_net_regression_r2_score], \n",
    "                                  ['elastic_net_regression','mean_squared_error',elastic_net_regression_mean_squared_error],\n",
    "                                  ['elastic_net_regression','explained_variance_score', elastic_net_regression_explained_variance_score]]\n",
    "elastic_net_regression_performance_metrics = pd.DataFrame(elastic_net_regression_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "elastic_net_regression_actual_predicted_plot, elastic_net_regression_actual_predicted_plot_ax = plt.subplots()\n",
    "elastic_net_regression_actual_predicted_plot = elastic_net_regression_actual_predicted_plot_ax.scatter(x=y_test, y=elastic_net_regression_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "elastic_net_regression_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "elastic_net_regression_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "elastic_net_regression_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "elastic_net_regression_actual_predicted_plot_ax.set_title(f'elastic_net_regression Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "elastic_net_regression_deciles = np.percentile(elastic_net_regression_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "elastic_net_regression_mean_actual = []\n",
    "elastic_net_regression_mean_predicted = []\n",
    "for i in range(len(elastic_net_regression_deciles) - 1):\n",
    "    mask = (elastic_net_regression_predictions >= elastic_net_regression_deciles[i]) & (elastic_net_regression_predictions < elastic_net_regression_deciles[i + 1])\n",
    "    elastic_net_regression_mean_actual.append(np.mean(y_test[mask]))\n",
    "    elastic_net_regression_mean_predicted.append(np.mean(elastic_net_regression_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "elastic_net_regression_lift_plot, elastic_net_regression_lift_plot_ax = plt.subplots()\n",
    "elastic_net_regression_lift_plot_ax.bar(np.arange(len(elastic_net_regression_mean_actual)), elastic_net_regression_mean_actual, label='Actual')\n",
    "elastic_net_regression_lift_plot_ax.plot(np.arange(len(elastic_net_regression_mean_predicted)), elastic_net_regression_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "elastic_net_regression_lift_plot_ax.set_xlabel('Deciles')\n",
    "elastic_net_regression_lift_plot_ax.set_ylabel('Mean')\n",
    "elastic_net_regression_lift_plot_ax.set_title(f'elastic_net_regression Decile Analysis Chart')\n",
    "elastic_net_regression_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(elastic_net_regression_performance_metrics)##### End of Model Pipeline for Elastic Net Regression #####\n",
    "##### Model Pipeline for Linear Regression #####\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "lin_reg_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "lin_reg_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lin_reg', LinearRegression())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "lin_reg_grid_search = GridSearchCV(estimator=lin_reg_pipe, param_grid=lin_reg_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "lin_reg_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "lin_reg_best_estimator = lin_reg_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "lin_reg_search_results = pd.DataFrame(lin_reg_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "lin_reg_predictions = lin_reg_best_estimator.predict(X_test)\n",
    "lin_reg_predictions_df = pd.DataFrame(lin_reg_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "lin_reg_r2_score = r2_score(y_test, lin_reg_predictions_df.iloc[:,0])\n",
    "lin_reg_mean_squared_error = mean_squared_error(y_test, lin_reg_predictions_df.iloc[:,0])\n",
    "lin_reg_explained_variance_score = explained_variance_score(y_test, lin_reg_predictions_df.iloc[:,0])\n",
    "lin_reg_performance_metrics = [['lin_reg','r2_score', lin_reg_r2_score], \n",
    "                                  ['lin_reg','mean_squared_error',lin_reg_mean_squared_error],\n",
    "                                  ['lin_reg','explained_variance_score', lin_reg_explained_variance_score]]\n",
    "lin_reg_performance_metrics = pd.DataFrame(lin_reg_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "lin_reg_actual_predicted_plot, lin_reg_actual_predicted_plot_ax = plt.subplots()\n",
    "lin_reg_actual_predicted_plot = lin_reg_actual_predicted_plot_ax.scatter(x=y_test, y=lin_reg_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "lin_reg_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "lin_reg_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "lin_reg_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "lin_reg_actual_predicted_plot_ax.set_title(f'lin_reg Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "lin_reg_deciles = np.percentile(lin_reg_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "lin_reg_mean_actual = []\n",
    "lin_reg_mean_predicted = []\n",
    "for i in range(len(lin_reg_deciles) - 1):\n",
    "    mask = (lin_reg_predictions >= lin_reg_deciles[i]) & (lin_reg_predictions < lin_reg_deciles[i + 1])\n",
    "    lin_reg_mean_actual.append(np.mean(y_test[mask]))\n",
    "    lin_reg_mean_predicted.append(np.mean(lin_reg_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "lin_reg_lift_plot, lin_reg_lift_plot_ax = plt.subplots()\n",
    "lin_reg_lift_plot_ax.bar(np.arange(len(lin_reg_mean_actual)), lin_reg_mean_actual, label='Actual')\n",
    "lin_reg_lift_plot_ax.plot(np.arange(len(lin_reg_mean_predicted)), lin_reg_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "lin_reg_lift_plot_ax.set_xlabel('Deciles')\n",
    "lin_reg_lift_plot_ax.set_ylabel('Mean')\n",
    "lin_reg_lift_plot_ax.set_title(f'lin_reg Decile Analysis Chart')\n",
    "lin_reg_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(lin_reg_performance_metrics)##### End of Model Pipeline for Linear Regression #####\n",
    "##### Model Pipeline for Lasso Regression #####\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "lasso_regression_param_grid = {\n",
    "\"lasso_regression__alpha\": np.arange(0.0, 2.0, 0.5),\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "lasso_regression_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lasso_regression', Lasso())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "lasso_regression_grid_search = GridSearchCV(estimator=lasso_regression_pipe, param_grid=lasso_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "lasso_regression_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "lasso_regression_best_estimator = lasso_regression_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "lasso_regression_search_results = pd.DataFrame(lasso_regression_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "lasso_regression_predictions = lasso_regression_best_estimator.predict(X_test)\n",
    "lasso_regression_predictions_df = pd.DataFrame(lasso_regression_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "lasso_regression_r2_score = r2_score(y_test, lasso_regression_predictions_df.iloc[:,0])\n",
    "lasso_regression_mean_squared_error = mean_squared_error(y_test, lasso_regression_predictions_df.iloc[:,0])\n",
    "lasso_regression_explained_variance_score = explained_variance_score(y_test, lasso_regression_predictions_df.iloc[:,0])\n",
    "lasso_regression_performance_metrics = [['lasso_regression','r2_score', lasso_regression_r2_score], \n",
    "                                  ['lasso_regression','mean_squared_error',lasso_regression_mean_squared_error],\n",
    "                                  ['lasso_regression','explained_variance_score', lasso_regression_explained_variance_score]]\n",
    "lasso_regression_performance_metrics = pd.DataFrame(lasso_regression_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "lasso_regression_actual_predicted_plot, lasso_regression_actual_predicted_plot_ax = plt.subplots()\n",
    "lasso_regression_actual_predicted_plot = lasso_regression_actual_predicted_plot_ax.scatter(x=y_test, y=lasso_regression_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "lasso_regression_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "lasso_regression_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "lasso_regression_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "lasso_regression_actual_predicted_plot_ax.set_title(f'lasso_regression Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "lasso_regression_deciles = np.percentile(lasso_regression_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "lasso_regression_mean_actual = []\n",
    "lasso_regression_mean_predicted = []\n",
    "for i in range(len(lasso_regression_deciles) - 1):\n",
    "    mask = (lasso_regression_predictions >= lasso_regression_deciles[i]) & (lasso_regression_predictions < lasso_regression_deciles[i + 1])\n",
    "    lasso_regression_mean_actual.append(np.mean(y_test[mask]))\n",
    "    lasso_regression_mean_predicted.append(np.mean(lasso_regression_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "lasso_regression_lift_plot, lasso_regression_lift_plot_ax = plt.subplots()\n",
    "lasso_regression_lift_plot_ax.bar(np.arange(len(lasso_regression_mean_actual)), lasso_regression_mean_actual, label='Actual')\n",
    "lasso_regression_lift_plot_ax.plot(np.arange(len(lasso_regression_mean_predicted)), lasso_regression_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "lasso_regression_lift_plot_ax.set_xlabel('Deciles')\n",
    "lasso_regression_lift_plot_ax.set_ylabel('Mean')\n",
    "lasso_regression_lift_plot_ax.set_title(f'lasso_regression Decile Analysis Chart')\n",
    "lasso_regression_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(lasso_regression_performance_metrics)##### End of Model Pipeline for Lasso Regression #####\n",
    "##### Model Pipeline for Ridge Regression #####\n",
    "\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "ridge_regression_param_grid = {\n",
    "\"ridge_regression__alpha\": np.arange(0.1, 2.0, 0.5),\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "ridge_regression_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('ridge_regression', Ridge())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "ridge_regression_grid_search = GridSearchCV(estimator=ridge_regression_pipe, param_grid=ridge_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "ridge_regression_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "ridge_regression_best_estimator = ridge_regression_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "ridge_regression_search_results = pd.DataFrame(ridge_regression_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "ridge_regression_predictions = ridge_regression_best_estimator.predict(X_test)\n",
    "ridge_regression_predictions_df = pd.DataFrame(ridge_regression_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "ridge_regression_r2_score = r2_score(y_test, ridge_regression_predictions_df.iloc[:,0])\n",
    "ridge_regression_mean_squared_error = mean_squared_error(y_test, ridge_regression_predictions_df.iloc[:,0])\n",
    "ridge_regression_explained_variance_score = explained_variance_score(y_test, ridge_regression_predictions_df.iloc[:,0])\n",
    "ridge_regression_performance_metrics = [['ridge_regression','r2_score', ridge_regression_r2_score], \n",
    "                                  ['ridge_regression','mean_squared_error',ridge_regression_mean_squared_error],\n",
    "                                  ['ridge_regression','explained_variance_score', ridge_regression_explained_variance_score]]\n",
    "ridge_regression_performance_metrics = pd.DataFrame(ridge_regression_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "ridge_regression_actual_predicted_plot, ridge_regression_actual_predicted_plot_ax = plt.subplots()\n",
    "ridge_regression_actual_predicted_plot = ridge_regression_actual_predicted_plot_ax.scatter(x=y_test, y=ridge_regression_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "ridge_regression_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "ridge_regression_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "ridge_regression_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "ridge_regression_actual_predicted_plot_ax.set_title(f'ridge_regression Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "ridge_regression_deciles = np.percentile(ridge_regression_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "ridge_regression_mean_actual = []\n",
    "ridge_regression_mean_predicted = []\n",
    "for i in range(len(ridge_regression_deciles) - 1):\n",
    "    mask = (ridge_regression_predictions >= ridge_regression_deciles[i]) & (ridge_regression_predictions < ridge_regression_deciles[i + 1])\n",
    "    ridge_regression_mean_actual.append(np.mean(y_test[mask]))\n",
    "    ridge_regression_mean_predicted.append(np.mean(ridge_regression_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "ridge_regression_lift_plot, ridge_regression_lift_plot_ax = plt.subplots()\n",
    "ridge_regression_lift_plot_ax.bar(np.arange(len(ridge_regression_mean_actual)), ridge_regression_mean_actual, label='Actual')\n",
    "ridge_regression_lift_plot_ax.plot(np.arange(len(ridge_regression_mean_predicted)), ridge_regression_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "ridge_regression_lift_plot_ax.set_xlabel('Deciles')\n",
    "ridge_regression_lift_plot_ax.set_ylabel('Mean')\n",
    "ridge_regression_lift_plot_ax.set_title(f'ridge_regression Decile Analysis Chart')\n",
    "ridge_regression_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(ridge_regression_performance_metrics)##### End of Model Pipeline for Ridge Regression #####\n",
    "##### Model Pipeline for Random Forest Regression #####\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "random_forest_regression_param_grid = {\n",
    "\"random_forest_regression__n_estimators\": np.arange(50, 150, 35),\n",
    "\"random_forest_regression__max_depth\": np.arange(5, 50, 10),\n",
    "\"random_forest_regression__min_samples_leaf\": np.arange(1, 50, 20),\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "random_forest_regression_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('random_forest_regression', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "random_forest_regression_grid_search = GridSearchCV(estimator=random_forest_regression_pipe, param_grid=random_forest_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "random_forest_regression_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "random_forest_regression_best_estimator = random_forest_regression_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "random_forest_regression_search_results = pd.DataFrame(random_forest_regression_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "random_forest_regression_predictions = random_forest_regression_best_estimator.predict(X_test)\n",
    "random_forest_regression_predictions_df = pd.DataFrame(random_forest_regression_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "random_forest_regression_r2_score = r2_score(y_test, random_forest_regression_predictions_df.iloc[:,0])\n",
    "random_forest_regression_mean_squared_error = mean_squared_error(y_test, random_forest_regression_predictions_df.iloc[:,0])\n",
    "random_forest_regression_explained_variance_score = explained_variance_score(y_test, random_forest_regression_predictions_df.iloc[:,0])\n",
    "random_forest_regression_performance_metrics = [['random_forest_regression','r2_score', random_forest_regression_r2_score], \n",
    "                                  ['random_forest_regression','mean_squared_error',random_forest_regression_mean_squared_error],\n",
    "                                  ['random_forest_regression','explained_variance_score', random_forest_regression_explained_variance_score]]\n",
    "random_forest_regression_performance_metrics = pd.DataFrame(random_forest_regression_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "random_forest_regression_actual_predicted_plot, random_forest_regression_actual_predicted_plot_ax = plt.subplots()\n",
    "random_forest_regression_actual_predicted_plot = random_forest_regression_actual_predicted_plot_ax.scatter(x=y_test, y=random_forest_regression_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "random_forest_regression_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "random_forest_regression_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "random_forest_regression_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "random_forest_regression_actual_predicted_plot_ax.set_title(f'random_forest_regression Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "random_forest_regression_deciles = np.percentile(random_forest_regression_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "random_forest_regression_mean_actual = []\n",
    "random_forest_regression_mean_predicted = []\n",
    "for i in range(len(random_forest_regression_deciles) - 1):\n",
    "    mask = (random_forest_regression_predictions >= random_forest_regression_deciles[i]) & (random_forest_regression_predictions < random_forest_regression_deciles[i + 1])\n",
    "    random_forest_regression_mean_actual.append(np.mean(y_test[mask]))\n",
    "    random_forest_regression_mean_predicted.append(np.mean(random_forest_regression_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "random_forest_regression_lift_plot, random_forest_regression_lift_plot_ax = plt.subplots()\n",
    "random_forest_regression_lift_plot_ax.bar(np.arange(len(random_forest_regression_mean_actual)), random_forest_regression_mean_actual, label='Actual')\n",
    "random_forest_regression_lift_plot_ax.plot(np.arange(len(random_forest_regression_mean_predicted)), random_forest_regression_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "random_forest_regression_lift_plot_ax.set_xlabel('Deciles')\n",
    "random_forest_regression_lift_plot_ax.set_ylabel('Mean')\n",
    "random_forest_regression_lift_plot_ax.set_title(f'random_forest_regression Decile Analysis Chart')\n",
    "random_forest_regression_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(random_forest_regression_performance_metrics)##### End of Model Pipeline for Random Forest Regression #####\n",
    "##### Model Pipeline for Decision Tree Regression #####\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "decision_tree_regression_param_grid = {\n",
    "\"decision_tree_regression__max_depth\": np.arange(1, 10, 3),\n",
    "\"decision_tree_regression__max_features\": ['auto'],\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "decision_tree_regression_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('decision_tree_regression', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "decision_tree_regression_grid_search = GridSearchCV(estimator=decision_tree_regression_pipe, param_grid=decision_tree_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "decision_tree_regression_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "decision_tree_regression_best_estimator = decision_tree_regression_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "decision_tree_regression_search_results = pd.DataFrame(decision_tree_regression_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "decision_tree_regression_predictions = decision_tree_regression_best_estimator.predict(X_test)\n",
    "decision_tree_regression_predictions_df = pd.DataFrame(decision_tree_regression_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "decision_tree_regression_r2_score = r2_score(y_test, decision_tree_regression_predictions_df.iloc[:,0])\n",
    "decision_tree_regression_mean_squared_error = mean_squared_error(y_test, decision_tree_regression_predictions_df.iloc[:,0])\n",
    "decision_tree_regression_explained_variance_score = explained_variance_score(y_test, decision_tree_regression_predictions_df.iloc[:,0])\n",
    "decision_tree_regression_performance_metrics = [['decision_tree_regression','r2_score', decision_tree_regression_r2_score], \n",
    "                                  ['decision_tree_regression','mean_squared_error',decision_tree_regression_mean_squared_error],\n",
    "                                  ['decision_tree_regression','explained_variance_score', decision_tree_regression_explained_variance_score]]\n",
    "decision_tree_regression_performance_metrics = pd.DataFrame(decision_tree_regression_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "decision_tree_regression_actual_predicted_plot, decision_tree_regression_actual_predicted_plot_ax = plt.subplots()\n",
    "decision_tree_regression_actual_predicted_plot = decision_tree_regression_actual_predicted_plot_ax.scatter(x=y_test, y=decision_tree_regression_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "decision_tree_regression_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "decision_tree_regression_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "decision_tree_regression_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "decision_tree_regression_actual_predicted_plot_ax.set_title(f'decision_tree_regression Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "decision_tree_regression_deciles = np.percentile(decision_tree_regression_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "decision_tree_regression_mean_actual = []\n",
    "decision_tree_regression_mean_predicted = []\n",
    "for i in range(len(decision_tree_regression_deciles) - 1):\n",
    "    mask = (decision_tree_regression_predictions >= decision_tree_regression_deciles[i]) & (decision_tree_regression_predictions < decision_tree_regression_deciles[i + 1])\n",
    "    decision_tree_regression_mean_actual.append(np.mean(y_test[mask]))\n",
    "    decision_tree_regression_mean_predicted.append(np.mean(decision_tree_regression_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "decision_tree_regression_lift_plot, decision_tree_regression_lift_plot_ax = plt.subplots()\n",
    "decision_tree_regression_lift_plot_ax.bar(np.arange(len(decision_tree_regression_mean_actual)), decision_tree_regression_mean_actual, label='Actual')\n",
    "decision_tree_regression_lift_plot_ax.plot(np.arange(len(decision_tree_regression_mean_predicted)), decision_tree_regression_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "decision_tree_regression_lift_plot_ax.set_xlabel('Deciles')\n",
    "decision_tree_regression_lift_plot_ax.set_ylabel('Mean')\n",
    "decision_tree_regression_lift_plot_ax.set_title(f'decision_tree_regression Decile Analysis Chart')\n",
    "decision_tree_regression_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(decision_tree_regression_performance_metrics)##### End of Model Pipeline for Decision Tree Regression #####\n",
    "##### Model Pipeline for GBT Regression #####\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score,explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "gbt_regression_param_grid = {\n",
    "\"gbt_regression__n_estimators\": np.arange(25, 200, 50),\n",
    "\"gbt_regression__max_depth\": np.arange(1, 10, 3),\n",
    "\"gbt_regression__alpha\": np.arange(0.1, 1.0, 0.5),\n",
    "}\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "gbt_regression_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gbt_regression', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "# Create the grid search\n",
    "gbt_regression_grid_search = GridSearchCV(estimator=gbt_regression_pipe, param_grid=gbt_regression_param_grid, cv=5, scoring=make_scorer(mean_squared_error), verbose=3)\n",
    "gbt_regression_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "gbt_regression_best_estimator = gbt_regression_grid_search.best_estimator_\n",
    "\n",
    "# Store results as a dataframe  \n",
    "gbt_regression_search_results = pd.DataFrame(gbt_regression_grid_search.cv_results_)\n",
    "\n",
    "# Model metrics\n",
    "\n",
    "# Generate Predictions\n",
    "gbt_regression_predictions = gbt_regression_best_estimator.predict(X_test)\n",
    "gbt_regression_predictions_df = pd.DataFrame(gbt_regression_best_estimator.predict(X_test))x`\n",
    "\n",
    "# Generate Model Metrics\n",
    "gbt_regression_r2_score = r2_score(y_test, gbt_regression_predictions_df.iloc[:,0])\n",
    "gbt_regression_mean_squared_error = mean_squared_error(y_test, gbt_regression_predictions_df.iloc[:,0])\n",
    "gbt_regression_explained_variance_score = explained_variance_score(y_test, gbt_regression_predictions_df.iloc[:,0])\n",
    "gbt_regression_performance_metrics = [['gbt_regression','r2_score', gbt_regression_r2_score], \n",
    "                                  ['gbt_regression','mean_squared_error',gbt_regression_mean_squared_error],\n",
    "                                  ['gbt_regression','explained_variance_score', gbt_regression_explained_variance_score]]\n",
    "gbt_regression_performance_metrics = pd.DataFrame(gbt_regression_performance_metrics, columns=['model','metric', 'value'])\n",
    "\n",
    "# Generate Actual vs Predicted Plot\n",
    "gbt_regression_actual_predicted_plot, gbt_regression_actual_predicted_plot_ax = plt.subplots()\n",
    "gbt_regression_actual_predicted_plot = gbt_regression_actual_predicted_plot_ax.scatter(x=y_test, y=gbt_regression_predictions_df.iloc[:,0], alpha=0.5)\n",
    "# Add diagonal line\n",
    "gbt_regression_actual_predicted_plot_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', alpha=0.5)\n",
    "# Set axis labels and title\n",
    "gbt_regression_actual_predicted_plot_ax.set_xlabel('Actual')\n",
    "gbt_regression_actual_predicted_plot_ax.set_ylabel('Predicted')\n",
    "gbt_regression_actual_predicted_plot_ax.set_title(f'gbt_regression Actual vs. Predicted')\n",
    "plt.show(block=False)\n",
    "\n",
    "# Generate Decile Lift Chart\n",
    "# Calculate the deciles based on the residuals\n",
    "gbt_regression_deciles = np.percentile(gbt_regression_predictions, np.arange(0, 100, 10))\n",
    "# Calculate the mean actual and predicted values for each decile\n",
    "gbt_regression_mean_actual = []\n",
    "gbt_regression_mean_predicted = []\n",
    "for i in range(len(gbt_regression_deciles) - 1):\n",
    "    mask = (gbt_regression_predictions >= gbt_regression_deciles[i]) & (gbt_regression_predictions < gbt_regression_deciles[i + 1])\n",
    "    gbt_regression_mean_actual.append(np.mean(y_test[mask]))\n",
    "    gbt_regression_mean_predicted.append(np.mean(gbt_regression_predictions[mask]))\n",
    "\n",
    "# Create a bar chart of the mean actual and predicted values for each decile\n",
    "gbt_regression_lift_plot, gbt_regression_lift_plot_ax = plt.subplots()\n",
    "gbt_regression_lift_plot_ax.bar(np.arange(len(gbt_regression_mean_actual)), gbt_regression_mean_actual, label='Actual')\n",
    "gbt_regression_lift_plot_ax.plot(np.arange(len(gbt_regression_mean_predicted)), gbt_regression_mean_predicted, color='red', linewidth=2, label='Predicted')\n",
    "gbt_regression_lift_plot_ax.set_xlabel('Deciles')\n",
    "gbt_regression_lift_plot_ax.set_ylabel('Mean')\n",
    "gbt_regression_lift_plot_ax.set_title(f'gbt_regression Decile Analysis Chart')\n",
    "gbt_regression_lift_plot_ax.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "model_comparison_list.append(gbt_regression_performance_metrics)##### End of Model Pipeline for GBT Regression #####\n",
    "##### Model Comparison #####\n",
    "\n",
    "table = pd.concat(model_comparison_list)\n",
    "table = table.sort_values(by=['value'], ascending=False)\n",
    "table = table[table['metric'] == 'r2_score']\n",
    "print(table)\n",
    "print(f\"The best model is {table['model'].iloc[0]} with {table['value'].iloc[0]} as {table['metric'].iloc[0]}\")\n",
    "\n",
    "\n",
    "# Predict test data using the best model\n",
    "test_predictions = eval(table['model'].iloc[0]+\"_best_estimator\").predict(prediction_df)\n",
    "print('Predictions from best model are stored in test_predictions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canvas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
