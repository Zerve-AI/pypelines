{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the respository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Zerve-AI/pypelines.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing the pypeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder = ''\n",
    "os.chdir(f'{folder}/pypelines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIST OF MODELS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS FOR ANOMALY DETECTION PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypelines.anomaly_detection_pipeline as pipe \n",
    "from pypelines import utils\n",
    "\n",
    "utils.list_supported_models(model_type='anomalydetection')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOMALY DETECTION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SINGLE ANOMALY DETECTION MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypelines.anomaly_detection_pipeline as pipe \n",
    "from pypelines import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Load and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vehicle_claims = pd.read_csv(\"pypelines/datasets/anomaly_detection/vehicle_claims.csv\")\n",
    "\n",
    "ad_pypelines_all = pipe.AnomalyDetectionPipeline(data = vehicle_claims,\n",
    "                                                 predictions_data= vehicle_claims\n",
    "                                                ,models = ['LUNAR']\n",
    "                                               , nfolds = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tranining code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ad_pypelines_all.model_grid_search_settings(model_name='LUNAR'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = {\n",
    "    'numerical': [\n",
    "        {'search': False, 'val_size': 'contamination', 'min': 0, 'max': 1, 'step': 0.1},\n",
    "    ],\n",
    "    'categorical': [\n",
    "        {'search': False, 'name': 'model_type', 'selected': ['WEIGHT'], 'values': ['WEIGHT', 'SCORE']}\n",
    "        \n",
    "    ]\n",
    "}\n",
    "\n",
    "print(ad_pypelines_all.set_model_grid_search_settings(hyperparam_dict=hyperparameter, model_name='LUNAR'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training code for single anomaly detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyod.models import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler,OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# target dataframe: vehicle_claims\n",
    "# target = \"\"\n",
    "features = list(vehicle_claims.columns)\n",
    "feature_df = vehicle_claims[features]\n",
    "\n",
    "prediction_df = vehicle_claims\n",
    "\n",
    "# get numerical and categorical columns\n",
    "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
    "vehicle_claims[bool_cols] = feature_df[bool_cols].astype(int)\n",
    "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)\n",
    "\n",
    "# define numeric transformer steps\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"scaler\", MinMaxScaler())]\n",
    ")\n",
    "\n",
    "# define categorical transformer steps\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OrdinalEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create the preprocessing pipelines for both numeric and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', numeric_transformer , numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)]\n",
    ")\n",
    "\n",
    "# train test split\n",
    "x_train = vehicle_claims[features]\n",
    "\n",
    "x_train_preprocessed = preprocessor.fit_transform(x_train)\n",
    "y_train_preprocessed = preprocessor.fit_transform(prediction_df)\n",
    "\n",
    "model_comparison_list = []\n",
    "\n",
    "##### End of Data Processing Pipeline #####\n",
    "\n",
    "\n",
    "##### Model Pipeline for LUNAR #####\n",
    "\n",
    "from pyod.models.lunar import LUNAR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "LUNAR_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "LUNAR_model = LUNAR()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "LUNAR_grid_search = GridSearchCV(LUNAR_model,\n",
    "                                      LUNAR_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "LUNAR_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "LUNAR_best_estimator = LUNAR_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "LUNAR_y_train_pred = LUNAR_best_estimator.labels_ \n",
    "LUNAR_y_train_scores = LUNAR_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "LUNAR_y_test_pred = LUNAR_best_estimator.predict(y_train_preprocessed)\n",
    "LUNAR_y_test_pred_proba = LUNAR_best_estimator.predict_proba(y_train_preprocessed) \n",
    "LUNAR_y_test_scores = LUNAR_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for LUNAR #####\n",
    "##### Model Comparison #####\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTIPLE ANOMALY DETECTION MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_pypelines_all = pipe.AnomalyDetectionPipeline(data = vehicle_claims,\n",
    "                                                 predictions_data= vehicle_claims\n",
    "                                              , models = ['R Graph','Principal Component Analysis']\n",
    "                                               , nfolds = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tranining code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training code for multiple anomaly detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyod.models import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler,OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# target dataframe: vehicle_claims\n",
    "# target = \"\"\n",
    "features = list(vehicle_claims.columns)\n",
    "feature_df = vehicle_claims[features]\n",
    "\n",
    "prediction_df = vehicle_claims\n",
    "\n",
    "# get numerical and categorical columns\n",
    "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
    "vehicle_claims[bool_cols] = feature_df[bool_cols].astype(int)\n",
    "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)\n",
    "\n",
    "# define numeric transformer steps\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"scaler\", MinMaxScaler())]\n",
    ")\n",
    "\n",
    "# define categorical transformer steps\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OrdinalEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create the preprocessing pipelines for both numeric and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', numeric_transformer , numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)]\n",
    ")\n",
    "\n",
    "# train test split\n",
    "x_train = vehicle_claims[features]\n",
    "\n",
    "x_train_preprocessed = preprocessor.fit_transform(x_train)\n",
    "y_train_preprocessed = preprocessor.fit_transform(prediction_df)\n",
    "\n",
    "model_comparison_list = []\n",
    "\n",
    "##### End of Data Processing Pipeline #####\n",
    "\n",
    "\n",
    "##### Model Pipeline for Principal Component Analysis #####\n",
    "\n",
    "from pyod.models.pca import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "PCA_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "\"svd_solver\": ['auto'],\n",
    "}\n",
    "\n",
    "\n",
    "PCA_model = PCA()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "PCA_grid_search = GridSearchCV(PCA_model,\n",
    "                                      PCA_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "PCA_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "PCA_best_estimator = PCA_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "PCA_y_train_pred = PCA_best_estimator.labels_ \n",
    "PCA_y_train_scores = PCA_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "PCA_y_test_pred = PCA_best_estimator.predict(y_train_preprocessed)\n",
    "PCA_y_test_pred_proba = PCA_best_estimator.predict_proba(y_train_preprocessed) \n",
    "PCA_y_test_scores = PCA_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Principal Component Analysis #####\n",
    "##### Model Pipeline for R Graph #####\n",
    "\n",
    "from pyod.models.rgraph import RGraph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "RGraph_param_grid = {\n",
    "\"maxiter_lasso\": np.arange(100, 1000, 1000),\n",
    "\"transition_steps\": np.arange(10, 20, 15),\n",
    "\"verbose\": [1],\n",
    "}\n",
    "\n",
    "\n",
    "RGraph_model = RGraph()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "RGraph_grid_search = GridSearchCV(RGraph_model,\n",
    "                                      RGraph_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "RGraph_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "RGraph_best_estimator = RGraph_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "RGraph_y_train_pred = RGraph_best_estimator.labels_ \n",
    "RGraph_y_train_scores = RGraph_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "RGraph_y_test_pred = RGraph_best_estimator.predict(y_train_preprocessed)\n",
    "RGraph_y_test_pred_proba = RGraph_best_estimator.predict_proba(y_train_preprocessed) \n",
    "RGraph_y_test_scores = RGraph_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for R Graph #####\n",
    "##### Model Comparison #####\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOMALY DETECTION - DEFAULT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_pypelines_all = pipe.AnomalyDetectionPipeline(data = vehicle_claims,\n",
    "                                                 predictions_data= vehicle_claims,\n",
    "                                               nfolds = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tranining code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_pypelines_all.code_to_clipboard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tranining code generation for anomaly detection default run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyod.models import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler,OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# target dataframe: vehicle_claims\n",
    "# target = \"\"\n",
    "features = list(vehicle_claims.columns)\n",
    "feature_df = vehicle_claims[features]\n",
    "\n",
    "prediction_df = vehicle_claims\n",
    "\n",
    "# get numerical and categorical columns\n",
    "bool_cols = feature_df.select_dtypes(include=['bool']).columns.tolist()\n",
    "vehicle_claims[bool_cols] = feature_df[bool_cols].astype(int)\n",
    "numerical_cols = feature_df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "categorical_cols = feature_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(numerical_cols)\n",
    "print(categorical_cols)\n",
    "\n",
    "# define numeric transformer steps\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"scaler\", MinMaxScaler())]\n",
    ")\n",
    "\n",
    "# define categorical transformer steps\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OrdinalEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create the preprocessing pipelines for both numeric and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', numeric_transformer , numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)]\n",
    ")\n",
    "\n",
    "# train test split\n",
    "x_train = vehicle_claims[features]\n",
    "\n",
    "x_train_preprocessed = preprocessor.fit_transform(x_train)\n",
    "y_train_preprocessed = preprocessor.fit_transform(prediction_df)\n",
    "\n",
    "model_comparison_list = []\n",
    "\n",
    "##### End of Data Processing Pipeline #####\n",
    "\n",
    "\n",
    "##### Model Pipeline for ABOD Anomaly Detection #####\n",
    "\n",
    "from pyod.models.abod import ABOD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "ABOD_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "ABOD_model = ABOD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "ABOD_grid_search = GridSearchCV(ABOD_model,\n",
    "                                      ABOD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "ABOD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "ABOD_best_estimator = ABOD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "ABOD_y_train_pred = ABOD_best_estimator.labels_ \n",
    "ABOD_y_train_scores = ABOD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "ABOD_y_test_pred = ABOD_best_estimator.predict(y_train_preprocessed)\n",
    "ABOD_y_test_pred_proba = ABOD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "ABOD_y_test_scores = ABOD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for ABOD Anomaly Detection #####\n",
    "##### Model Pipeline for ALAD Anomaly Detection #####\n",
    "\n",
    "from pyod.models.alad import ALAD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "ALAD_param_grid = {\n",
    "\"epochs\": np.arange(100, 1000, 100),\n",
    "\"batch_size\": np.arange(100, 1000, 100),\n",
    "\"dropout_rate\": np.arange(0.01, 1.0, 0.2),\n",
    "\"activation_hidden_gen\": ['relu'],\n",
    "\"activation_hidden_disc\": ['relu'],\n",
    "}\n",
    "\n",
    "\n",
    "ALAD_model = ALAD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "ALAD_grid_search = GridSearchCV(ALAD_model,\n",
    "                                      ALAD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "ALAD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "ALAD_best_estimator = ALAD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "ALAD_y_train_pred = ALAD_best_estimator.labels_ \n",
    "ALAD_y_train_scores = ALAD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "ALAD_y_test_pred = ALAD_best_estimator.predict(y_train_preprocessed)\n",
    "ALAD_y_test_pred_proba = ALAD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "ALAD_y_test_scores = ALAD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for ALAD Anomaly Detection #####\n",
    "##### Model Pipeline for AnoGAN Anomaly Detection #####\n",
    "\n",
    "from pyod.models.anogan import AnoGAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "AnoGAN_param_grid = {\n",
    "\"epochs\": np.arange(100, 1000, 100),\n",
    "\"batch_size\": np.arange(100, 1000, 100),\n",
    "\"dropout_rate\": np.arange(0.01, 1.0, 0.2),\n",
    "\"output_activation\": ['relu'],\n",
    "\"activation_hidden\": ['tanh'],\n",
    "}\n",
    "\n",
    "\n",
    "AnoGAN_model = AnoGAN()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "AnoGAN_grid_search = GridSearchCV(AnoGAN_model,\n",
    "                                      AnoGAN_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "AnoGAN_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "AnoGAN_best_estimator = AnoGAN_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "AnoGAN_y_train_pred = AnoGAN_best_estimator.labels_ \n",
    "AnoGAN_y_train_scores = AnoGAN_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "AnoGAN_y_test_pred = AnoGAN_best_estimator.predict(y_train_preprocessed)\n",
    "AnoGAN_y_test_pred_proba = AnoGAN_best_estimator.predict_proba(y_train_preprocessed) \n",
    "AnoGAN_y_test_scores = AnoGAN_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for AnoGAN Anomaly Detection #####\n",
    "##### Model Pipeline for Clustering Based Local Outlier Factor #####\n",
    "\n",
    "from pyod.models.cblof import CBLOF\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "CBLOF_param_grid = {\n",
    "\"n_clusters\": np.arange(2, 20, 2),\n",
    "\"alpha\": np.arange(0.5, 1.0, 0.1),\n",
    "\"beta\": np.arange(1.1, 100.0, 20.0),\n",
    "}\n",
    "\n",
    "\n",
    "CBLOF_model = CBLOF()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "CBLOF_grid_search = GridSearchCV(CBLOF_model,\n",
    "                                      CBLOF_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "CBLOF_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "CBLOF_best_estimator = CBLOF_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "CBLOF_y_train_pred = CBLOF_best_estimator.labels_ \n",
    "CBLOF_y_train_scores = CBLOF_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "CBLOF_y_test_pred = CBLOF_best_estimator.predict(y_train_preprocessed)\n",
    "CBLOF_y_test_pred_proba = CBLOF_best_estimator.predict_proba(y_train_preprocessed) \n",
    "CBLOF_y_test_scores = CBLOF_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Clustering Based Local Outlier Factor #####\n",
    "##### Model Pipeline for Connectivity-Based Outlier Factor #####\n",
    "\n",
    "from pyod.models.cof import COF\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "COF_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "COF_model = COF()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "COF_grid_search = GridSearchCV(COF_model,\n",
    "                                      COF_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "COF_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "COF_best_estimator = COF_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "COF_y_train_pred = COF_best_estimator.labels_ \n",
    "COF_y_train_scores = COF_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "COF_y_test_pred = COF_best_estimator.predict(y_train_preprocessed)\n",
    "COF_y_test_pred_proba = COF_best_estimator.predict_proba(y_train_preprocessed) \n",
    "COF_y_test_scores = COF_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Connectivity-Based Outlier Factor #####\n",
    "##### Model Pipeline for Cooks Distance Outlier Factor #####\n",
    "\n",
    "from pyod.models.cd import CD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "CD_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "CD_model = CD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "CD_grid_search = GridSearchCV(CD_model,\n",
    "                                      CD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "CD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "CD_best_estimator = CD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "CD_y_train_pred = CD_best_estimator.labels_ \n",
    "CD_y_train_scores = CD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "CD_y_test_pred = CD_best_estimator.predict(y_train_preprocessed)\n",
    "CD_y_test_pred_proba = CD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "CD_y_test_scores = CD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Cooks Distance Outlier Factor #####\n",
    "##### Model Pipeline for Copula Based Outlier Detector #####\n",
    "\n",
    "from pyod.models.copod import COPOD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "COPOD_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "COPOD_model = COPOD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "COPOD_grid_search = GridSearchCV(COPOD_model,\n",
    "                                      COPOD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "COPOD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "COPOD_best_estimator = COPOD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "COPOD_y_train_pred = COPOD_best_estimator.labels_ \n",
    "COPOD_y_train_scores = COPOD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "COPOD_y_test_pred = COPOD_best_estimator.predict(y_train_preprocessed)\n",
    "COPOD_y_test_pred_proba = COPOD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "COPOD_y_test_scores = COPOD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Copula Based Outlier Detector #####\n",
    "##### Model Pipeline for Deep One-Class Classification #####\n",
    "\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "DeepSVDD_param_grid = {\n",
    "\"epochs\": np.arange(100, 1000, 100),\n",
    "\"batch_size\": np.arange(100, 1000, 100),\n",
    "\"dropout_rate\": np.arange(0.01, 1.0, 0.2),\n",
    "\"hidden_activation\": ['relu'],\n",
    "\"output_activation\": ['sigmoid'],\n",
    "}\n",
    "\n",
    "\n",
    "DeepSVDD_model = DeepSVDD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "DeepSVDD_grid_search = GridSearchCV(DeepSVDD_model,\n",
    "                                      DeepSVDD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "DeepSVDD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "DeepSVDD_best_estimator = DeepSVDD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "DeepSVDD_y_train_pred = DeepSVDD_best_estimator.labels_ \n",
    "DeepSVDD_y_train_scores = DeepSVDD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "DeepSVDD_y_test_pred = DeepSVDD_best_estimator.predict(y_train_preprocessed)\n",
    "DeepSVDD_y_test_pred_proba = DeepSVDD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "DeepSVDD_y_test_scores = DeepSVDD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Deep One-Class Classification #####\n",
    "##### Model Pipeline for Empirical Cumulative Distribution #####\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "ECOD_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "ECOD_model = ECOD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "ECOD_grid_search = GridSearchCV(ECOD_model,\n",
    "                                      ECOD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "ECOD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "ECOD_best_estimator = ECOD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "ECOD_y_train_pred = ECOD_best_estimator.labels_ \n",
    "ECOD_y_train_scores = ECOD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "ECOD_y_test_pred = ECOD_best_estimator.predict(y_train_preprocessed)\n",
    "ECOD_y_test_pred_proba = ECOD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "ECOD_y_test_scores = ECOD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Empirical Cumulative Distribution #####\n",
    "##### Model Pipeline for Gaussian Mixture Model #####\n",
    "\n",
    "from pyod.models.gmm import GMM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "GMM_param_grid = {\n",
    "\"covariance_type\": ['full'],\n",
    "}\n",
    "\n",
    "\n",
    "GMM_model = GMM()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "GMM_grid_search = GridSearchCV(GMM_model,\n",
    "                                      GMM_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "GMM_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "GMM_best_estimator = GMM_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "GMM_y_train_pred = GMM_best_estimator.labels_ \n",
    "GMM_y_train_scores = GMM_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "GMM_y_test_pred = GMM_best_estimator.predict(y_train_preprocessed)\n",
    "GMM_y_test_pred_proba = GMM_best_estimator.predict_proba(y_train_preprocessed) \n",
    "GMM_y_test_scores = GMM_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Gaussian Mixture Model #####\n",
    "##### Model Pipeline for Principal Component Analysis #####\n",
    "\n",
    "from pyod.models.pca import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "PCA_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "\"svd_solver\": ['auto'],\n",
    "}\n",
    "\n",
    "\n",
    "PCA_model = PCA()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "PCA_grid_search = GridSearchCV(PCA_model,\n",
    "                                      PCA_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "PCA_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "PCA_best_estimator = PCA_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "PCA_y_train_pred = PCA_best_estimator.labels_ \n",
    "PCA_y_train_scores = PCA_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "PCA_y_test_pred = PCA_best_estimator.predict(y_train_preprocessed)\n",
    "PCA_y_test_pred_proba = PCA_best_estimator.predict_proba(y_train_preprocessed) \n",
    "PCA_y_test_scores = PCA_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Principal Component Analysis #####\n",
    "##### Model Pipeline for R Graph #####\n",
    "\n",
    "from pyod.models.rgraph import RGraph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "RGraph_param_grid = {\n",
    "\"maxiter_lasso\": np.arange(100, 1000, 1000),\n",
    "\"transition_steps\": np.arange(10, 20, 15),\n",
    "\"verbose\": [1],\n",
    "}\n",
    "\n",
    "\n",
    "RGraph_model = RGraph()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "RGraph_grid_search = GridSearchCV(RGraph_model,\n",
    "                                      RGraph_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "RGraph_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "RGraph_best_estimator = RGraph_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "RGraph_y_train_pred = RGraph_best_estimator.labels_ \n",
    "RGraph_y_train_scores = RGraph_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "RGraph_y_test_pred = RGraph_best_estimator.predict(y_train_preprocessed)\n",
    "RGraph_y_test_pred_proba = RGraph_best_estimator.predict_proba(y_train_preprocessed) \n",
    "RGraph_y_test_scores = RGraph_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for R Graph #####\n",
    "##### Model Pipeline for Outlier detection based on Sampling #####\n",
    "\n",
    "from pyod.models.sampling import Sampling\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "Sampling_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "\"subset_size\": np.arange(10, 20, 15),\n",
    "\"metric\": ['minkowski'],\n",
    "}\n",
    "\n",
    "\n",
    "Sampling_model = Sampling()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "Sampling_grid_search = GridSearchCV(Sampling_model,\n",
    "                                      Sampling_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "Sampling_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "Sampling_best_estimator = Sampling_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "Sampling_y_train_pred = Sampling_best_estimator.labels_ \n",
    "Sampling_y_train_scores = Sampling_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "Sampling_y_test_pred = Sampling_best_estimator.predict(y_train_preprocessed)\n",
    "Sampling_y_test_pred_proba = Sampling_best_estimator.predict_proba(y_train_preprocessed) \n",
    "Sampling_y_test_scores = Sampling_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Outlier detection based on Sampling #####\n",
    "##### Model Pipeline for SUOD #####\n",
    "\n",
    "from pyod.models.suod import SUOD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "SUOD_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "\"target_dim_frac\": np.arange(0.0, 1.0, 0.5),\n",
    "\"jl_method\": ['basic'],\n",
    "}\n",
    "\n",
    "\n",
    "SUOD_model = SUOD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "SUOD_grid_search = GridSearchCV(SUOD_model,\n",
    "                                      SUOD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "SUOD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "SUOD_best_estimator = SUOD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "SUOD_y_train_pred = SUOD_best_estimator.labels_ \n",
    "SUOD_y_train_scores = SUOD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "SUOD_y_test_pred = SUOD_best_estimator.predict(y_train_preprocessed)\n",
    "SUOD_y_test_pred_proba = SUOD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "SUOD_y_test_scores = SUOD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for SUOD #####\n",
    "##### Model Pipeline for Rotation-based Outlier Detector #####\n",
    "\n",
    "from pyod.models.rod import ROD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "ROD_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "ROD_model = ROD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "ROD_grid_search = GridSearchCV(ROD_model,\n",
    "                                      ROD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "ROD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "ROD_best_estimator = ROD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "ROD_y_train_pred = ROD_best_estimator.labels_ \n",
    "ROD_y_train_scores = ROD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "ROD_y_test_pred = ROD_best_estimator.predict(y_train_preprocessed)\n",
    "ROD_y_test_pred_proba = ROD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "ROD_y_test_scores = ROD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Rotation-based Outlier Detector #####\n",
    "##### Model Pipeline for Stochastic Outlier Selection #####\n",
    "\n",
    "from pyod.models.sos import SOS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "SOS_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "\"metric\": ['euclidean'],\n",
    "}\n",
    "\n",
    "\n",
    "SOS_model = SOS()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "SOS_grid_search = GridSearchCV(SOS_model,\n",
    "                                      SOS_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "SOS_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "SOS_best_estimator = SOS_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "SOS_y_train_pred = SOS_best_estimator.labels_ \n",
    "SOS_y_train_scores = SOS_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "SOS_y_test_pred = SOS_best_estimator.predict(y_train_preprocessed)\n",
    "SOS_y_test_pred_proba = SOS_best_estimator.predict_proba(y_train_preprocessed) \n",
    "SOS_y_test_scores = SOS_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Stochastic Outlier Selection #####\n",
    "##### Model Pipeline for Quasi-Monte Carlo Discrepancy outlier detection #####\n",
    "\n",
    "from pyod.models.qmcd import QMCD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "QMCD_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "}\n",
    "\n",
    "\n",
    "QMCD_model = QMCD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "QMCD_grid_search = GridSearchCV(QMCD_model,\n",
    "                                      QMCD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "QMCD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "QMCD_best_estimator = QMCD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "QMCD_y_train_pred = QMCD_best_estimator.labels_ \n",
    "QMCD_y_train_scores = QMCD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "QMCD_y_test_pred = QMCD_best_estimator.predict(y_train_preprocessed)\n",
    "QMCD_y_test_pred_proba = QMCD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "QMCD_y_test_scores = QMCD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Quasi-Monte Carlo Discrepancy outlier detection #####\n",
    "##### Model Pipeline for Single-Objective Generative Adversarial Active Learning #####\n",
    "\n",
    "from pyod.models.so_gaal import SO_GAAL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "SO_GAAL_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "\"stop_epochs\": np.arange(10, 20, 15),\n",
    "}\n",
    "\n",
    "\n",
    "SO_GAAL_model = SO_GAAL()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "SO_GAAL_grid_search = GridSearchCV(SO_GAAL_model,\n",
    "                                      SO_GAAL_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "SO_GAAL_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "SO_GAAL_best_estimator = SO_GAAL_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "SO_GAAL_y_train_pred = SO_GAAL_best_estimator.labels_ \n",
    "SO_GAAL_y_train_scores = SO_GAAL_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "SO_GAAL_y_test_pred = SO_GAAL_best_estimator.predict(y_train_preprocessed)\n",
    "SO_GAAL_y_test_pred_proba = SO_GAAL_best_estimator.predict_proba(y_train_preprocessed) \n",
    "SO_GAAL_y_test_scores = SO_GAAL_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for Single-Objective Generative Adversarial Active Learning #####\n",
    "##### Model Pipeline for One-class SVM detector #####\n",
    "\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "OCSVM_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "\"kernel\": ['rbf'],\n",
    "}\n",
    "\n",
    "\n",
    "OCSVM_model = OCSVM()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "OCSVM_grid_search = GridSearchCV(OCSVM_model,\n",
    "                                      OCSVM_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "OCSVM_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "OCSVM_best_estimator = OCSVM_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "OCSVM_y_train_pred = OCSVM_best_estimator.labels_ \n",
    "OCSVM_y_train_scores = OCSVM_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "OCSVM_y_test_pred = OCSVM_best_estimator.predict(y_train_preprocessed)\n",
    "OCSVM_y_test_pred_proba = OCSVM_best_estimator.predict_proba(y_train_preprocessed) \n",
    "OCSVM_y_test_scores = OCSVM_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for One-class SVM detector #####\n",
    "##### Model Pipeline for MO_GAAL #####\n",
    "\n",
    "from pyod.models.mo_gaal import MO_GAAL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "MO_GAAL_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "}\n",
    "\n",
    "\n",
    "MO_GAAL_model = MO_GAAL()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "MO_GAAL_grid_search = GridSearchCV(MO_GAAL_model,\n",
    "                                      MO_GAAL_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "MO_GAAL_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "MO_GAAL_best_estimator = MO_GAAL_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "MO_GAAL_y_train_pred = MO_GAAL_best_estimator.labels_ \n",
    "MO_GAAL_y_train_scores = MO_GAAL_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "MO_GAAL_y_test_pred = MO_GAAL_best_estimator.predict(y_train_preprocessed)\n",
    "MO_GAAL_y_test_pred_proba = MO_GAAL_best_estimator.predict_proba(y_train_preprocessed) \n",
    "MO_GAAL_y_test_scores = MO_GAAL_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for MO_GAAL #####\n",
    "##### Model Pipeline for MCD #####\n",
    "\n",
    "from pyod.models.mcd import MCD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "MCD_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "\"store_precision\": [True],\n",
    "}\n",
    "\n",
    "\n",
    "MCD_model = MCD()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "MCD_grid_search = GridSearchCV(MCD_model,\n",
    "                                      MCD_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "MCD_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "MCD_best_estimator = MCD_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "MCD_y_train_pred = MCD_best_estimator.labels_ \n",
    "MCD_y_train_scores = MCD_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "MCD_y_test_pred = MCD_best_estimator.predict(y_train_preprocessed)\n",
    "MCD_y_test_pred_proba = MCD_best_estimator.predict_proba(y_train_preprocessed) \n",
    "MCD_y_test_scores = MCD_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for MCD #####\n",
    "##### Model Pipeline for LUNAR #####\n",
    "\n",
    "from pyod.models.lunar import LUNAR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "LUNAR_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "LUNAR_model = LUNAR()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "LUNAR_grid_search = GridSearchCV(LUNAR_model,\n",
    "                                      LUNAR_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "LUNAR_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "LUNAR_best_estimator = LUNAR_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "LUNAR_y_train_pred = LUNAR_best_estimator.labels_ \n",
    "LUNAR_y_train_scores = LUNAR_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "LUNAR_y_test_pred = LUNAR_best_estimator.predict(y_train_preprocessed)\n",
    "LUNAR_y_test_pred_proba = LUNAR_best_estimator.predict_proba(y_train_preprocessed) \n",
    "LUNAR_y_test_scores = LUNAR_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for LUNAR #####\n",
    "##### Model Pipeline for LOF #####\n",
    "\n",
    "from pyod.models.lof import LOF\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "LOF_param_grid = {\n",
    "\"contamination\": np.arange(0.1, 0.5, 0.05),\n",
    "\"algorithm\": ['auto'],\n",
    "}\n",
    "\n",
    "\n",
    "LOF_model = LOF()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "LOF_grid_search = GridSearchCV(LOF_model,\n",
    "                                      LOF_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "LOF_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "LOF_best_estimator = LOF_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "LOF_y_train_pred = LOF_best_estimator.labels_ \n",
    "LOF_y_train_scores = LOF_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "LOF_y_test_pred = LOF_best_estimator.predict(y_train_preprocessed)\n",
    "LOF_y_test_pred_proba = LOF_best_estimator.predict_proba(y_train_preprocessed) \n",
    "LOF_y_test_scores = LOF_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for LOF #####\n",
    "##### Model Pipeline for LODA #####\n",
    "\n",
    "from pyod.models.loda import LODA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scorer_f(estimator, X_test):   #dummy scorer for unsupervised model gridsearch\n",
    "      return 1\n",
    "\n",
    "\n",
    "LODA_param_grid = {\n",
    "}\n",
    "\n",
    "\n",
    "LODA_model = LODA()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "LODA_grid_search = GridSearchCV(LODA_model,\n",
    "                                      LODA_param_grid, \n",
    "                                      scoring=scorer_f, \n",
    "                                      verbose=3)\n",
    "LODA_grid_search.fit(x_train_preprocessed)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "LODA_best_estimator = LODA_grid_search.best_estimator_\n",
    "\n",
    "# get the prediction labels and outlier scores of the training data\n",
    "LODA_y_train_pred = LODA_best_estimator.labels_ \n",
    "LODA_y_train_scores = LODA_best_estimator.decision_scores_\n",
    "\n",
    "# get the prediction on the test data\n",
    "LODA_y_test_pred = LODA_best_estimator.predict(y_train_preprocessed)\n",
    "LODA_y_test_pred_proba = LODA_best_estimator.predict_proba(y_train_preprocessed) \n",
    "LODA_y_test_scores = LODA_best_estimator.decision_function(y_train_preprocessed) \n",
    "##### End of Model Pipeline for LODA #####\n",
    "##### Model Comparison #####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canvas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
